{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGwn_hKA5q5a"
      },
      "source": [
        "### Problem #1: Binary Classification via soft-margin SVM on CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXsVC78X5q5c"
      },
      "source": [
        "##### a) Load CIFAR10 dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o5xSZIFZ5q5c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSRL1zSo5q5d",
        "outputId": "8b789d3e-714e-41e8-c2e0-b9d1486b4fa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0O-EnGx5q5d"
      },
      "source": [
        "##### b) Visualize at least one image for each class. You may need to look into how dataset is implemented in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0BL6cs8d5q5e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "18_tfDEf5q5e",
        "outputId": "a3ba298e-6142-4d1e-dde9-026da12d0ded"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels_map = {\n",
        "    0: \"airplane\",\n",
        "    1: \"automobile\",\n",
        "    2: \"bird\",\n",
        "    3: \"cat\",\n",
        "    4: \"deer\",\n",
        "    5: \"dog\",\n",
        "    6: \"frog\",\n",
        "    7: \"horse\",\n",
        "    8: \"ship\",\n",
        "    9: \"truck\",\n",
        "}\n",
        "figure = plt.figure(figsize=(10, 5))\n",
        "cols, rows = 5, 2\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(trainset), size=(1,)).item()\n",
        "    img, label = trainset[sample_idx]\n",
        "    while label != i-1:\n",
        "        sample_idx = torch.randint(len(trainset), size=(1,)).item()\n",
        "        img, label = trainset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNWISllc5q5e"
      },
      "source": [
        "##### c) Split the trainset into training set and validation set with 90% : 10% ratio. Implement dataloaders for CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J5gl4a2S5q5e"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d-I_Wj5s5q5e"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, dataset, classes):\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "\n",
        "        for data, target in dataset:\n",
        "            if target in classes:\n",
        "                self.data.append(data)\n",
        "                label = 1 if target==classes[0] else -1\n",
        "                self.targets.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], torch.tensor(self.targets[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UI_QnmBaTkXT"
      },
      "outputs": [],
      "source": [
        "def Select_Class(trainset, testset, classes=[3, 5], batch=64):\n",
        "    custom_trainset = CustomImageDataset(trainset, classes)\n",
        "    custom_testset = CustomImageDataset(testset, classes)\n",
        "\n",
        "    val_ratio = 0.1\n",
        "    train_size = len(custom_trainset)\n",
        "\n",
        "    split = int(val_ratio * train_size)\n",
        "\n",
        "    train_dataset, val_dataset = random_split(custom_trainset, [train_size-split, split])\n",
        "\n",
        "    custom_train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
        "    custom_val_dataloader = DataLoader(val_dataset, batch_size=batch, shuffle=True)\n",
        "    custom_test_dataloader = DataLoader(custom_testset, batch_size=batch, shuffle=True)\n",
        "\n",
        "    return custom_train_dataloader, custom_val_dataloader, custom_test_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHwgwF675q5e"
      },
      "source": [
        "##### d) Choose any two classes. Then, make a SVM classifier (implement a loss function yourself. Do not use PyTorch implementations of loss functions.) and its training/validation/evaluation code to perform binary classification between those two classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZGehgo75q5f"
      },
      "source": [
        "1. Using \"cuda\" device for fast processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwp1t26P5q5f",
        "outputId": "96ead270-3211-4753-cd0a-904d554eec85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SbkvKGI5q5f"
      },
      "source": [
        "2. Convert the multi-class dataset into a binary classification dataset. Then, execute the dataset with a mini-batch size of 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W142SBT5q5g",
        "outputId": "b915fef6-3280-4098-b3c0-c82d9d9cf24b"
      },
      "outputs": [],
      "source": [
        "train_dataloader_, val_dataloader_, test_dataloader_ = Select_Class(trainset, testset, [6, 7], 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTXdWlkP5q5f"
      },
      "source": [
        "3. Implement Soft-margin SVM for binary dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wFnIGuQ55q5f"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HuQlFJHu5q5f"
      },
      "outputs": [],
      "source": [
        "class SVC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SVC, self).__init__()\n",
        "        self.linear = nn.Linear(3*32*32, 1)\n",
        "        self.C = 1\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = self.linear(X)\n",
        "        return Y\n",
        "\n",
        "    def hinge_loss(self, Y, y):\n",
        "        return torch.clamp(1-y*Y, min=0)\n",
        "\n",
        "    def fit(self, train_dataloader, optimethod=\"SGD\",learning_rate=0.01, epochs=10, gamma=1):\n",
        "        self.C = gamma\n",
        "        total_loss = 0\n",
        "        n_iter, n_loss = [], []\n",
        "\n",
        "        if optimethod:\n",
        "            assert optimethod in [\"SGD\", \"Adam\"], \"You should pick optimizer one of \\\"SGD\\\" or \\\"Adam\\\"\"\n",
        "            if optimethod == \"SGD\":\n",
        "                optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
        "            elif optimethod == \"Adam\":\n",
        "                optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        print(f'Start training SVM model with [epoch: {epochs}, learning_rate: {learning_rate}, optimizer: {optimethod}, gamma: {gamma}]\\n')\n",
        "\n",
        "        # Here is Training Algorithm per epoch\n",
        "        self.train()\n",
        "        for epoch in range(epochs):\n",
        "            for X, y in train_dataloader:\n",
        "                # X, y = X.to(device), y.to(device)\n",
        "                X = torch.flatten(X, 1, -1)\n",
        "                y = torch.where(y == y.unique()[0], 1, -1)\n",
        "                Y = self(X).squeeze()\n",
        "                loss = torch.mean(self.hinge_loss(Y, y)) + 0.5 / self.C * torch.norm(self.linear.weight, p=2)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                total_loss += loss\n",
        "            total_loss = total_loss / len(train_dataloader)\n",
        "            n_iter.append(epoch+1)\n",
        "            n_loss.append(total_loss.item())\n",
        "            print(f'epoch: [{epoch+1}/{epochs}] -> loss: {total_loss:.3f}')\n",
        "        train_accuracy = self.predict(train_dataloader)[1].item()\n",
        "        print(f'\\nTraining is finished.\\n')\n",
        "        print(f'* Final loss: {total_loss:.3f}\\n* Train accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "        # For draw graph about loss\n",
        "        return n_iter, n_loss, train_accuracy\n",
        "\n",
        "    def predict(self, test_dataloader):\n",
        "        with torch.no_grad():\n",
        "            total_loss = 0\n",
        "            accuracy = 0\n",
        "            count = 0\n",
        "            self.eval()\n",
        "            for X, y in test_dataloader:\n",
        "                X = torch.flatten(X, 1, -1)\n",
        "                y = torch.where(y == y.unique()[0], 1, -1)\n",
        "                Y = self(X).squeeze()\n",
        "                loss = torch.mean(self.hinge_loss(Y, y)) + 0.5 / self.C * torch.norm(self.linear.weight, p=2)\n",
        "                total_loss += loss\n",
        "                Y_pred = torch.where(Y < 0, -1, 1)\n",
        "                accuracy += (Y_pred==y).sum()\n",
        "                count += len(Y_pred==y)\n",
        "            total_loss = total_loss / len(test_dataloader)\n",
        "            total_accuracy = 100 * accuracy / count\n",
        "        return total_loss, total_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training SVM model with [epoch: 1, learning_rate: 0.001, optimizer: Adam, gamma: 5]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [1/1] -> loss: 0.766\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.766\n",
            "* Train accuracy: 77.64%\n"
          ]
        }
      ],
      "source": [
        "svc = SVC()\n",
        "\n",
        "epochs, losses, _ = svc.fit(train_dataloader_, learning_rate=0.001, optimethod=\"Adam\", epochs=1, gamma=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bvKK3-F45q5g"
      },
      "outputs": [],
      "source": [
        "val_loss, val_acc = svc.predict(val_dataloader_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0ZzxsJ65q5g",
        "outputId": "e684bba8-eeea-47d8-b101-184436aeea96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluate validation dataset loss/accuracy\n",
            "* val loss: 0.643\n",
            "* val accuracy: 78.40%\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluate validation dataset loss/accuracy\")\n",
        "print(f'* val loss: {val_loss:.3f}\\n* val accuracy: {val_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "c95xSD9n5q5g"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = svc.predict(test_dataloader_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqFO3HUk5q5g",
        "outputId": "b60aa64e-f313-4742-ec0c-63eed6157a6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluate test dataset loss/accuracy\n",
            "* test loss: 0.596\n",
            "* test accuracy: 81.05%\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluate test dataset loss/accuracy\")\n",
        "print(f'* test loss: {test_loss:.3f}\\n* test accuracy: {test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gRmVs7U5q5g"
      },
      "source": [
        "##### e) Train for 10 epochs with batch size 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFUFMkag5q5g",
        "outputId": "6d519ace-0b6f-4c19-9c23-9536d4540c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 5]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [1/10] -> loss: 0.775\n",
            "epoch: [2/10] -> loss: 0.649\n",
            "epoch: [3/10] -> loss: 0.628\n",
            "epoch: [4/10] -> loss: 0.624\n",
            "epoch: [5/10] -> loss: 0.606\n",
            "epoch: [6/10] -> loss: 0.608\n",
            "epoch: [7/10] -> loss: 0.615\n",
            "epoch: [8/10] -> loss: 0.604\n",
            "epoch: [9/10] -> loss: 0.606\n",
            "epoch: [10/10] -> loss: 0.607\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.607\n",
            "* Train accuracy: 82.21%\n"
          ]
        }
      ],
      "source": [
        "svc = SVC()\n",
        "\n",
        "epochs, losses, _ = svc.fit(train_dataloader_, learning_rate=0.001, optimethod=\"Adam\", epochs=10, gamma=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "HJS3XYvD5q5g",
        "outputId": "69d595c9-ed17-4475-c48e-0adbcb17cf59"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, losses, label='Loss per Epoch', color='red')\n",
        "    plt.title('Loss Graph Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cRgoQrP5q5g"
      },
      "source": [
        "##### f) Perform data normalization. You may need to look into how to use datasets in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zCU493Qn5q5g"
      },
      "outputs": [],
      "source": [
        "def Normalize_dataset():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    trainset = datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
        "    testset = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
        "    return trainset, testset\n",
        "\n",
        "normalized_trainset, normalized_testset = Normalize_dataset()\n",
        "normalized_train_dataloader, normalized_val_dataloader, normalized_test_dataloader = Select_Class(normalized_trainset, normalized_testset, [6, 7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDPGHT7A5q5h"
      },
      "source": [
        "##### g) Again, train for 10 epochs with batch size 64 after data normalization. Write down your observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ioVRsQf5q5h",
        "outputId": "73c84d8c-fe6b-4ee9-c663-c323f93d7f03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 5]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.622\n",
            "epoch: [2/10] -> loss: 0.548\n",
            "epoch: [3/10] -> loss: 0.528\n",
            "epoch: [4/10] -> loss: 0.535\n",
            "epoch: [5/10] -> loss: 0.523\n",
            "epoch: [6/10] -> loss: 0.530\n",
            "epoch: [7/10] -> loss: 0.527\n",
            "epoch: [8/10] -> loss: 0.532\n",
            "epoch: [9/10] -> loss: 0.529\n",
            "epoch: [10/10] -> loss: 0.528\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.528\n",
            "* Train accuracy: 84.37%\n"
          ]
        }
      ],
      "source": [
        "svc = SVC()\n",
        "\n",
        "epochs, norm_losses, _ = svc.fit(normalized_train_dataloader, learning_rate=0.001, optimethod=\"Adam\", epochs=10, gamma=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "7ABBq4WX5q5h",
        "outputId": "6327c428-9faf-4e82-e1ba-63523dd82225"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, losses, color=\"red\", label='Non-Nomalized dataset')\n",
        "    plt.plot(epochs, norm_losses, color=\"blue\", label='Nomalized dataset')\n",
        "    plt.title('Loss Graph Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBFnrDuW5q5h"
      },
      "source": [
        "##### h) What are the hyperparameters you can tune?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. optimizer\n",
        "2. epoch\n",
        "3. mini batch\n",
        "4. learning rate\n",
        "5. gamma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20giNVae5q5h"
      },
      "source": [
        "##### i) Try to obtain find optimal hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AG4yMw9GTkXX"
      },
      "outputs": [],
      "source": [
        "def Normalize_dataset():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    trainset = datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
        "    testset = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
        "    return trainset, testset\n",
        "\n",
        "normalized_trainset, normalized_testset = Normalize_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDQo1RMHTkXX",
        "outputId": "4301874b-47ac-4dcf-fa4d-182596763e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.252\n",
            "epoch: [2/10] -> loss: 1.191\n",
            "epoch: [3/10] -> loss: 1.187\n",
            "epoch: [4/10] -> loss: 1.178\n",
            "epoch: [5/10] -> loss: 1.200\n",
            "epoch: [6/10] -> loss: 1.178\n",
            "epoch: [7/10] -> loss: 1.185\n",
            "epoch: [8/10] -> loss: 1.179\n",
            "epoch: [9/10] -> loss: 1.177\n",
            "epoch: [10/10] -> loss: 1.188\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.188\n",
            "* Train accuracy: 63.77%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.821\n",
            "epoch: [2/10] -> loss: 0.765\n",
            "epoch: [3/10] -> loss: 0.769\n",
            "epoch: [4/10] -> loss: 0.771\n",
            "epoch: [5/10] -> loss: 0.767\n",
            "epoch: [6/10] -> loss: 0.765\n",
            "epoch: [7/10] -> loss: 0.770\n",
            "epoch: [8/10] -> loss: 0.764\n",
            "epoch: [9/10] -> loss: 0.767\n",
            "epoch: [10/10] -> loss: 0.769\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.769\n",
            "* Train accuracy: 74.43%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.581\n",
            "epoch: [2/10] -> loss: 0.511\n",
            "epoch: [3/10] -> loss: 0.491\n",
            "epoch: [4/10] -> loss: 0.485\n",
            "epoch: [5/10] -> loss: 0.482\n",
            "epoch: [6/10] -> loss: 0.479\n",
            "epoch: [7/10] -> loss: 0.476\n",
            "epoch: [8/10] -> loss: 0.474\n",
            "epoch: [9/10] -> loss: 0.471\n",
            "epoch: [10/10] -> loss: 0.469\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.469\n",
            "* Train accuracy: 84.33%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.192\n",
            "epoch: [2/10] -> loss: 1.085\n",
            "epoch: [3/10] -> loss: 1.082\n",
            "epoch: [4/10] -> loss: 1.082\n",
            "epoch: [5/10] -> loss: 1.087\n",
            "epoch: [6/10] -> loss: 1.082\n",
            "epoch: [7/10] -> loss: 1.090\n",
            "epoch: [8/10] -> loss: 1.086\n",
            "epoch: [9/10] -> loss: 1.083\n",
            "epoch: [10/10] -> loss: 1.084\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.084\n",
            "* Train accuracy: 58.06%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.833\n",
            "epoch: [2/10] -> loss: 0.746\n",
            "epoch: [3/10] -> loss: 0.739\n",
            "epoch: [4/10] -> loss: 0.737\n",
            "epoch: [5/10] -> loss: 0.737\n",
            "epoch: [6/10] -> loss: 0.734\n",
            "epoch: [7/10] -> loss: 0.736\n",
            "epoch: [8/10] -> loss: 0.734\n",
            "epoch: [9/10] -> loss: 0.738\n",
            "epoch: [10/10] -> loss: 0.737\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.737\n",
            "* Train accuracy: 79.93%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.602\n",
            "epoch: [2/10] -> loss: 0.507\n",
            "epoch: [3/10] -> loss: 0.490\n",
            "epoch: [4/10] -> loss: 0.480\n",
            "epoch: [5/10] -> loss: 0.473\n",
            "epoch: [6/10] -> loss: 0.469\n",
            "epoch: [7/10] -> loss: 0.468\n",
            "epoch: [8/10] -> loss: 0.463\n",
            "epoch: [9/10] -> loss: 0.462\n",
            "epoch: [10/10] -> loss: 0.459\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.459\n",
            "* Train accuracy: 84.66%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.573\n",
            "epoch: [2/10] -> loss: 1.023\n",
            "epoch: [3/10] -> loss: 1.021\n",
            "epoch: [4/10] -> loss: 1.020\n",
            "epoch: [5/10] -> loss: 1.021\n",
            "epoch: [6/10] -> loss: 1.021\n",
            "epoch: [7/10] -> loss: 1.021\n",
            "epoch: [8/10] -> loss: 1.021\n",
            "epoch: [9/10] -> loss: 1.021\n",
            "epoch: [10/10] -> loss: 1.021\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.021\n",
            "* Train accuracy: 60.30%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.972\n",
            "epoch: [2/10] -> loss: 0.825\n",
            "epoch: [3/10] -> loss: 0.772\n",
            "epoch: [4/10] -> loss: 0.747\n",
            "epoch: [5/10] -> loss: 0.731\n",
            "epoch: [6/10] -> loss: 0.724\n",
            "epoch: [7/10] -> loss: 0.722\n",
            "epoch: [8/10] -> loss: 0.718\n",
            "epoch: [9/10] -> loss: 0.719\n",
            "epoch: [10/10] -> loss: 0.720\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.720\n",
            "* Train accuracy: 79.43%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.734\n",
            "epoch: [2/10] -> loss: 0.595\n",
            "epoch: [3/10] -> loss: 0.549\n",
            "epoch: [4/10] -> loss: 0.528\n",
            "epoch: [5/10] -> loss: 0.514\n",
            "epoch: [6/10] -> loss: 0.504\n",
            "epoch: [7/10] -> loss: 0.496\n",
            "epoch: [8/10] -> loss: 0.490\n",
            "epoch: [9/10] -> loss: 0.485\n",
            "epoch: [10/10] -> loss: 0.482\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.482\n",
            "* Train accuracy: 82.51%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 2.140\n",
            "epoch: [2/10] -> loss: 1.017\n",
            "epoch: [3/10] -> loss: 1.012\n",
            "epoch: [4/10] -> loss: 1.012\n",
            "epoch: [5/10] -> loss: 1.012\n",
            "epoch: [6/10] -> loss: 1.012\n",
            "epoch: [7/10] -> loss: 1.013\n",
            "epoch: [8/10] -> loss: 1.012\n",
            "epoch: [9/10] -> loss: 1.012\n",
            "epoch: [10/10] -> loss: 1.012\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.012\n",
            "* Train accuracy: 58.80%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.052\n",
            "epoch: [2/10] -> loss: 0.906\n",
            "epoch: [3/10] -> loss: 0.841\n",
            "epoch: [4/10] -> loss: 0.803\n",
            "epoch: [5/10] -> loss: 0.779\n",
            "epoch: [6/10] -> loss: 0.761\n",
            "epoch: [7/10] -> loss: 0.749\n",
            "epoch: [8/10] -> loss: 0.737\n",
            "epoch: [9/10] -> loss: 0.732\n",
            "epoch: [10/10] -> loss: 0.727\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.727\n",
            "* Train accuracy: 79.40%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.808\n",
            "epoch: [2/10] -> loss: 0.673\n",
            "epoch: [3/10] -> loss: 0.613\n",
            "epoch: [4/10] -> loss: 0.577\n",
            "epoch: [5/10] -> loss: 0.556\n",
            "epoch: [6/10] -> loss: 0.543\n",
            "epoch: [7/10] -> loss: 0.532\n",
            "epoch: [8/10] -> loss: 0.521\n",
            "epoch: [9/10] -> loss: 0.515\n",
            "epoch: [10/10] -> loss: 0.509\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.509\n",
            "* Train accuracy: 81.30%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 3.425\n",
            "epoch: [2/10] -> loss: 2.672\n",
            "epoch: [3/10] -> loss: 1.999\n",
            "epoch: [4/10] -> loss: 1.418\n",
            "epoch: [5/10] -> loss: 1.080\n",
            "epoch: [6/10] -> loss: 1.011\n",
            "epoch: [7/10] -> loss: 1.005\n",
            "epoch: [8/10] -> loss: 1.005\n",
            "epoch: [9/10] -> loss: 1.005\n",
            "epoch: [10/10] -> loss: 1.005\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.005\n",
            "* Train accuracy: 55.02%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.125\n",
            "epoch: [2/10] -> loss: 1.059\n",
            "epoch: [3/10] -> loss: 1.016\n",
            "epoch: [4/10] -> loss: 0.983\n",
            "epoch: [5/10] -> loss: 0.955\n",
            "epoch: [6/10] -> loss: 0.933\n",
            "epoch: [7/10] -> loss: 0.913\n",
            "epoch: [8/10] -> loss: 0.896\n",
            "epoch: [9/10] -> loss: 0.881\n",
            "epoch: [10/10] -> loss: 0.868\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.868\n",
            "* Train accuracy: 75.30%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.890\n",
            "epoch: [2/10] -> loss: 0.808\n",
            "epoch: [3/10] -> loss: 0.767\n",
            "epoch: [4/10] -> loss: 0.737\n",
            "epoch: [5/10] -> loss: 0.712\n",
            "epoch: [6/10] -> loss: 0.690\n",
            "epoch: [7/10] -> loss: 0.672\n",
            "epoch: [8/10] -> loss: 0.657\n",
            "epoch: [9/10] -> loss: 0.644\n",
            "epoch: [10/10] -> loss: 0.632\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.632\n",
            "* Train accuracy: 76.14%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.242\n",
            "epoch: [2/20] -> loss: 1.184\n",
            "epoch: [3/20] -> loss: 1.181\n",
            "epoch: [4/20] -> loss: 1.186\n",
            "epoch: [5/20] -> loss: 1.183\n",
            "epoch: [6/20] -> loss: 1.187\n",
            "epoch: [7/20] -> loss: 1.185\n",
            "epoch: [8/20] -> loss: 1.186\n",
            "epoch: [9/20] -> loss: 1.174\n",
            "epoch: [10/20] -> loss: 1.189\n",
            "epoch: [11/20] -> loss: 1.181\n",
            "epoch: [12/20] -> loss: 1.180\n",
            "epoch: [13/20] -> loss: 1.185\n",
            "epoch: [14/20] -> loss: 1.190\n",
            "epoch: [15/20] -> loss: 1.188\n",
            "epoch: [16/20] -> loss: 1.198\n",
            "epoch: [17/20] -> loss: 1.191\n",
            "epoch: [18/20] -> loss: 1.189\n",
            "epoch: [19/20] -> loss: 1.181\n",
            "epoch: [20/20] -> loss: 1.177\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.177\n",
            "* Train accuracy: 48.63%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.822\n",
            "epoch: [2/20] -> loss: 0.769\n",
            "epoch: [3/20] -> loss: 0.765\n",
            "epoch: [4/20] -> loss: 0.767\n",
            "epoch: [5/20] -> loss: 0.760\n",
            "epoch: [6/20] -> loss: 0.771\n",
            "epoch: [7/20] -> loss: 0.765\n",
            "epoch: [8/20] -> loss: 0.771\n",
            "epoch: [9/20] -> loss: 0.765\n",
            "epoch: [10/20] -> loss: 0.769\n",
            "epoch: [11/20] -> loss: 0.772\n",
            "epoch: [12/20] -> loss: 0.767\n",
            "epoch: [13/20] -> loss: 0.767\n",
            "epoch: [14/20] -> loss: 0.767\n",
            "epoch: [15/20] -> loss: 0.765\n",
            "epoch: [16/20] -> loss: 0.773\n",
            "epoch: [17/20] -> loss: 0.770\n",
            "epoch: [18/20] -> loss: 0.766\n",
            "epoch: [19/20] -> loss: 0.763\n",
            "epoch: [20/20] -> loss: 0.771\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.771\n",
            "* Train accuracy: 72.13%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.585\n",
            "epoch: [2/20] -> loss: 0.506\n",
            "epoch: [3/20] -> loss: 0.495\n",
            "epoch: [4/20] -> loss: 0.483\n",
            "epoch: [5/20] -> loss: 0.479\n",
            "epoch: [6/20] -> loss: 0.477\n",
            "epoch: [7/20] -> loss: 0.475\n",
            "epoch: [8/20] -> loss: 0.474\n",
            "epoch: [9/20] -> loss: 0.472\n",
            "epoch: [10/20] -> loss: 0.470\n",
            "epoch: [11/20] -> loss: 0.472\n",
            "epoch: [12/20] -> loss: 0.473\n",
            "epoch: [13/20] -> loss: 0.475\n",
            "epoch: [14/20] -> loss: 0.468\n",
            "epoch: [15/20] -> loss: 0.467\n",
            "epoch: [16/20] -> loss: 0.466\n",
            "epoch: [17/20] -> loss: 0.468\n",
            "epoch: [18/20] -> loss: 0.471\n",
            "epoch: [19/20] -> loss: 0.471\n",
            "epoch: [20/20] -> loss: 0.468\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.468\n",
            "* Train accuracy: 85.08%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.191\n",
            "epoch: [2/20] -> loss: 1.084\n",
            "epoch: [3/20] -> loss: 1.083\n",
            "epoch: [4/20] -> loss: 1.084\n",
            "epoch: [5/20] -> loss: 1.083\n",
            "epoch: [6/20] -> loss: 1.085\n",
            "epoch: [7/20] -> loss: 1.088\n",
            "epoch: [8/20] -> loss: 1.086\n",
            "epoch: [9/20] -> loss: 1.083\n",
            "epoch: [10/20] -> loss: 1.085\n",
            "epoch: [11/20] -> loss: 1.089\n",
            "epoch: [12/20] -> loss: 1.088\n",
            "epoch: [13/20] -> loss: 1.082\n",
            "epoch: [14/20] -> loss: 1.089\n",
            "epoch: [15/20] -> loss: 1.082\n",
            "epoch: [16/20] -> loss: 1.081\n",
            "epoch: [17/20] -> loss: 1.085\n",
            "epoch: [18/20] -> loss: 1.084\n",
            "epoch: [19/20] -> loss: 1.087\n",
            "epoch: [20/20] -> loss: 1.085\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.085\n",
            "* Train accuracy: 50.13%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.826\n",
            "epoch: [2/20] -> loss: 0.742\n",
            "epoch: [3/20] -> loss: 0.738\n",
            "epoch: [4/20] -> loss: 0.735\n",
            "epoch: [5/20] -> loss: 0.738\n",
            "epoch: [6/20] -> loss: 0.738\n",
            "epoch: [7/20] -> loss: 0.738\n",
            "epoch: [8/20] -> loss: 0.737\n",
            "epoch: [9/20] -> loss: 0.737\n",
            "epoch: [10/20] -> loss: 0.735\n",
            "epoch: [11/20] -> loss: 0.739\n",
            "epoch: [12/20] -> loss: 0.738\n",
            "epoch: [13/20] -> loss: 0.735\n",
            "epoch: [14/20] -> loss: 0.738\n",
            "epoch: [15/20] -> loss: 0.737\n",
            "epoch: [16/20] -> loss: 0.737\n",
            "epoch: [17/20] -> loss: 0.735\n",
            "epoch: [18/20] -> loss: 0.735\n",
            "epoch: [19/20] -> loss: 0.736\n",
            "epoch: [20/20] -> loss: 0.737\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.737\n",
            "* Train accuracy: 76.87%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.603\n",
            "epoch: [2/20] -> loss: 0.510\n",
            "epoch: [3/20] -> loss: 0.490\n",
            "epoch: [4/20] -> loss: 0.479\n",
            "epoch: [5/20] -> loss: 0.473\n",
            "epoch: [6/20] -> loss: 0.469\n",
            "epoch: [7/20] -> loss: 0.467\n",
            "epoch: [8/20] -> loss: 0.462\n",
            "epoch: [9/20] -> loss: 0.462\n",
            "epoch: [10/20] -> loss: 0.459\n",
            "epoch: [11/20] -> loss: 0.461\n",
            "epoch: [12/20] -> loss: 0.456\n",
            "epoch: [13/20] -> loss: 0.453\n",
            "epoch: [14/20] -> loss: 0.455\n",
            "epoch: [15/20] -> loss: 0.455\n",
            "epoch: [16/20] -> loss: 0.452\n",
            "epoch: [17/20] -> loss: 0.454\n",
            "epoch: [18/20] -> loss: 0.453\n",
            "epoch: [19/20] -> loss: 0.452\n",
            "epoch: [20/20] -> loss: 0.455\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.455\n",
            "* Train accuracy: 83.70%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.580\n",
            "epoch: [2/20] -> loss: 1.023\n",
            "epoch: [3/20] -> loss: 1.022\n",
            "epoch: [4/20] -> loss: 1.021\n",
            "epoch: [5/20] -> loss: 1.021\n",
            "epoch: [6/20] -> loss: 1.021\n",
            "epoch: [7/20] -> loss: 1.022\n",
            "epoch: [8/20] -> loss: 1.021\n",
            "epoch: [9/20] -> loss: 1.021\n",
            "epoch: [10/20] -> loss: 1.021\n",
            "epoch: [11/20] -> loss: 1.021\n",
            "epoch: [12/20] -> loss: 1.021\n",
            "epoch: [13/20] -> loss: 1.021\n",
            "epoch: [14/20] -> loss: 1.020\n",
            "epoch: [15/20] -> loss: 1.021\n",
            "epoch: [16/20] -> loss: 1.020\n",
            "epoch: [17/20] -> loss: 1.021\n",
            "epoch: [18/20] -> loss: 1.021\n",
            "epoch: [19/20] -> loss: 1.021\n",
            "epoch: [20/20] -> loss: 1.021\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.021\n",
            "* Train accuracy: 60.14%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.984\n",
            "epoch: [2/20] -> loss: 0.826\n",
            "epoch: [3/20] -> loss: 0.772\n",
            "epoch: [4/20] -> loss: 0.746\n",
            "epoch: [5/20] -> loss: 0.731\n",
            "epoch: [6/20] -> loss: 0.725\n",
            "epoch: [7/20] -> loss: 0.721\n",
            "epoch: [8/20] -> loss: 0.720\n",
            "epoch: [9/20] -> loss: 0.719\n",
            "epoch: [10/20] -> loss: 0.719\n",
            "epoch: [11/20] -> loss: 0.718\n",
            "epoch: [12/20] -> loss: 0.718\n",
            "epoch: [13/20] -> loss: 0.717\n",
            "epoch: [14/20] -> loss: 0.717\n",
            "epoch: [15/20] -> loss: 0.717\n",
            "epoch: [16/20] -> loss: 0.717\n",
            "epoch: [17/20] -> loss: 0.717\n",
            "epoch: [18/20] -> loss: 0.717\n",
            "epoch: [19/20] -> loss: 0.718\n",
            "epoch: [20/20] -> loss: 0.717\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.717\n",
            "* Train accuracy: 79.72%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.737\n",
            "epoch: [2/20] -> loss: 0.596\n",
            "epoch: [3/20] -> loss: 0.552\n",
            "epoch: [4/20] -> loss: 0.529\n",
            "epoch: [5/20] -> loss: 0.515\n",
            "epoch: [6/20] -> loss: 0.506\n",
            "epoch: [7/20] -> loss: 0.497\n",
            "epoch: [8/20] -> loss: 0.491\n",
            "epoch: [9/20] -> loss: 0.485\n",
            "epoch: [10/20] -> loss: 0.482\n",
            "epoch: [11/20] -> loss: 0.479\n",
            "epoch: [12/20] -> loss: 0.477\n",
            "epoch: [13/20] -> loss: 0.474\n",
            "epoch: [14/20] -> loss: 0.473\n",
            "epoch: [15/20] -> loss: 0.469\n",
            "epoch: [16/20] -> loss: 0.467\n",
            "epoch: [17/20] -> loss: 0.466\n",
            "epoch: [18/20] -> loss: 0.464\n",
            "epoch: [19/20] -> loss: 0.462\n",
            "epoch: [20/20] -> loss: 0.462\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.462\n",
            "* Train accuracy: 83.98%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 2.095\n",
            "epoch: [2/20] -> loss: 1.017\n",
            "epoch: [3/20] -> loss: 1.012\n",
            "epoch: [4/20] -> loss: 1.012\n",
            "epoch: [5/20] -> loss: 1.012\n",
            "epoch: [6/20] -> loss: 1.012\n",
            "epoch: [7/20] -> loss: 1.013\n",
            "epoch: [8/20] -> loss: 1.012\n",
            "epoch: [9/20] -> loss: 1.012\n",
            "epoch: [10/20] -> loss: 1.012\n",
            "epoch: [11/20] -> loss: 1.012\n",
            "epoch: [12/20] -> loss: 1.012\n",
            "epoch: [13/20] -> loss: 1.012\n",
            "epoch: [14/20] -> loss: 1.012\n",
            "epoch: [15/20] -> loss: 1.012\n",
            "epoch: [16/20] -> loss: 1.012\n",
            "epoch: [17/20] -> loss: 1.012\n",
            "epoch: [18/20] -> loss: 1.012\n",
            "epoch: [19/20] -> loss: 1.012\n",
            "epoch: [20/20] -> loss: 1.012\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.012\n",
            "* Train accuracy: 63.43%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.045\n",
            "epoch: [2/20] -> loss: 0.902\n",
            "epoch: [3/20] -> loss: 0.840\n",
            "epoch: [4/20] -> loss: 0.802\n",
            "epoch: [5/20] -> loss: 0.778\n",
            "epoch: [6/20] -> loss: 0.760\n",
            "epoch: [7/20] -> loss: 0.748\n",
            "epoch: [8/20] -> loss: 0.738\n",
            "epoch: [9/20] -> loss: 0.736\n",
            "epoch: [10/20] -> loss: 0.727\n",
            "epoch: [11/20] -> loss: 0.723\n",
            "epoch: [12/20] -> loss: 0.722\n",
            "epoch: [13/20] -> loss: 0.720\n",
            "epoch: [14/20] -> loss: 0.719\n",
            "epoch: [15/20] -> loss: 0.717\n",
            "epoch: [16/20] -> loss: 0.717\n",
            "epoch: [17/20] -> loss: 0.716\n",
            "epoch: [18/20] -> loss: 0.716\n",
            "epoch: [19/20] -> loss: 0.716\n",
            "epoch: [20/20] -> loss: 0.715\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.715\n",
            "* Train accuracy: 79.60%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.791\n",
            "epoch: [2/20] -> loss: 0.664\n",
            "epoch: [3/20] -> loss: 0.609\n",
            "epoch: [4/20] -> loss: 0.579\n",
            "epoch: [5/20] -> loss: 0.557\n",
            "epoch: [6/20] -> loss: 0.542\n",
            "epoch: [7/20] -> loss: 0.531\n",
            "epoch: [8/20] -> loss: 0.522\n",
            "epoch: [9/20] -> loss: 0.515\n",
            "epoch: [10/20] -> loss: 0.511\n",
            "epoch: [11/20] -> loss: 0.504\n",
            "epoch: [12/20] -> loss: 0.501\n",
            "epoch: [13/20] -> loss: 0.498\n",
            "epoch: [14/20] -> loss: 0.494\n",
            "epoch: [15/20] -> loss: 0.491\n",
            "epoch: [16/20] -> loss: 0.488\n",
            "epoch: [17/20] -> loss: 0.486\n",
            "epoch: [18/20] -> loss: 0.484\n",
            "epoch: [19/20] -> loss: 0.481\n",
            "epoch: [20/20] -> loss: 0.479\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.479\n",
            "* Train accuracy: 82.98%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 3.493\n",
            "epoch: [2/20] -> loss: 2.725\n",
            "epoch: [3/20] -> loss: 2.056\n",
            "epoch: [4/20] -> loss: 1.468\n",
            "epoch: [5/20] -> loss: 1.098\n",
            "epoch: [6/20] -> loss: 1.014\n",
            "epoch: [7/20] -> loss: 1.005\n",
            "epoch: [8/20] -> loss: 1.005\n",
            "epoch: [9/20] -> loss: 1.005\n",
            "epoch: [10/20] -> loss: 1.005\n",
            "epoch: [11/20] -> loss: 1.005\n",
            "epoch: [12/20] -> loss: 1.005\n",
            "epoch: [13/20] -> loss: 1.005\n",
            "epoch: [14/20] -> loss: 1.005\n",
            "epoch: [15/20] -> loss: 1.005\n",
            "epoch: [16/20] -> loss: 1.005\n",
            "epoch: [17/20] -> loss: 1.005\n",
            "epoch: [18/20] -> loss: 1.005\n",
            "epoch: [19/20] -> loss: 1.005\n",
            "epoch: [20/20] -> loss: 1.005\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.005\n",
            "* Train accuracy: 60.60%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.161\n",
            "epoch: [2/20] -> loss: 1.059\n",
            "epoch: [3/20] -> loss: 1.011\n",
            "epoch: [4/20] -> loss: 0.977\n",
            "epoch: [5/20] -> loss: 0.951\n",
            "epoch: [6/20] -> loss: 0.927\n",
            "epoch: [7/20] -> loss: 0.909\n",
            "epoch: [8/20] -> loss: 0.892\n",
            "epoch: [9/20] -> loss: 0.877\n",
            "epoch: [10/20] -> loss: 0.865\n",
            "epoch: [11/20] -> loss: 0.853\n",
            "epoch: [12/20] -> loss: 0.843\n",
            "epoch: [13/20] -> loss: 0.833\n",
            "epoch: [14/20] -> loss: 0.824\n",
            "epoch: [15/20] -> loss: 0.817\n",
            "epoch: [16/20] -> loss: 0.810\n",
            "epoch: [17/20] -> loss: 0.803\n",
            "epoch: [18/20] -> loss: 0.798\n",
            "epoch: [19/20] -> loss: 0.792\n",
            "epoch: [20/20] -> loss: 0.787\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.787\n",
            "* Train accuracy: 78.32%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.890\n",
            "epoch: [2/20] -> loss: 0.811\n",
            "epoch: [3/20] -> loss: 0.771\n",
            "epoch: [4/20] -> loss: 0.739\n",
            "epoch: [5/20] -> loss: 0.714\n",
            "epoch: [6/20] -> loss: 0.694\n",
            "epoch: [7/20] -> loss: 0.675\n",
            "epoch: [8/20] -> loss: 0.659\n",
            "epoch: [9/20] -> loss: 0.645\n",
            "epoch: [10/20] -> loss: 0.634\n",
            "epoch: [11/20] -> loss: 0.625\n",
            "epoch: [12/20] -> loss: 0.615\n",
            "epoch: [13/20] -> loss: 0.606\n",
            "epoch: [14/20] -> loss: 0.598\n",
            "epoch: [15/20] -> loss: 0.592\n",
            "epoch: [16/20] -> loss: 0.585\n",
            "epoch: [17/20] -> loss: 0.580\n",
            "epoch: [18/20] -> loss: 0.574\n",
            "epoch: [19/20] -> loss: 0.570\n",
            "epoch: [20/20] -> loss: 0.565\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.565\n",
            "* Train accuracy: 78.94%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.242\n",
            "epoch: [2/30] -> loss: 1.192\n",
            "epoch: [3/30] -> loss: 1.185\n",
            "epoch: [4/30] -> loss: 1.179\n",
            "epoch: [5/30] -> loss: 1.192\n",
            "epoch: [6/30] -> loss: 1.186\n",
            "epoch: [7/30] -> loss: 1.181\n",
            "epoch: [8/30] -> loss: 1.186\n",
            "epoch: [9/30] -> loss: 1.184\n",
            "epoch: [10/30] -> loss: 1.186\n",
            "epoch: [11/30] -> loss: 1.190\n",
            "epoch: [12/30] -> loss: 1.187\n",
            "epoch: [13/30] -> loss: 1.191\n",
            "epoch: [14/30] -> loss: 1.190\n",
            "epoch: [15/30] -> loss: 1.183\n",
            "epoch: [16/30] -> loss: 1.188\n",
            "epoch: [17/30] -> loss: 1.189\n",
            "epoch: [18/30] -> loss: 1.188\n",
            "epoch: [19/30] -> loss: 1.187\n",
            "epoch: [20/30] -> loss: 1.173\n",
            "epoch: [21/30] -> loss: 1.193\n",
            "epoch: [22/30] -> loss: 1.197\n",
            "epoch: [23/30] -> loss: 1.193\n",
            "epoch: [24/30] -> loss: 1.196\n",
            "epoch: [25/30] -> loss: 1.185\n",
            "epoch: [26/30] -> loss: 1.171\n",
            "epoch: [27/30] -> loss: 1.186\n",
            "epoch: [28/30] -> loss: 1.196\n",
            "epoch: [29/30] -> loss: 1.190\n",
            "epoch: [30/30] -> loss: 1.190\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.190\n",
            "* Train accuracy: 61.20%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.824\n",
            "epoch: [2/30] -> loss: 0.771\n",
            "epoch: [3/30] -> loss: 0.766\n",
            "epoch: [4/30] -> loss: 0.767\n",
            "epoch: [5/30] -> loss: 0.770\n",
            "epoch: [6/30] -> loss: 0.765\n",
            "epoch: [7/30] -> loss: 0.770\n",
            "epoch: [8/30] -> loss: 0.769\n",
            "epoch: [9/30] -> loss: 0.770\n",
            "epoch: [10/30] -> loss: 0.770\n",
            "epoch: [11/30] -> loss: 0.765\n",
            "epoch: [12/30] -> loss: 0.768\n",
            "epoch: [13/30] -> loss: 0.764\n",
            "epoch: [14/30] -> loss: 0.767\n",
            "epoch: [15/30] -> loss: 0.759\n",
            "epoch: [16/30] -> loss: 0.767\n",
            "epoch: [17/30] -> loss: 0.764\n",
            "epoch: [18/30] -> loss: 0.765\n",
            "epoch: [19/30] -> loss: 0.763\n",
            "epoch: [20/30] -> loss: 0.767\n",
            "epoch: [21/30] -> loss: 0.760\n",
            "epoch: [22/30] -> loss: 0.770\n",
            "epoch: [23/30] -> loss: 0.762\n",
            "epoch: [24/30] -> loss: 0.762\n",
            "epoch: [25/30] -> loss: 0.764\n",
            "epoch: [26/30] -> loss: 0.764\n",
            "epoch: [27/30] -> loss: 0.773\n",
            "epoch: [28/30] -> loss: 0.767\n",
            "epoch: [29/30] -> loss: 0.769\n",
            "epoch: [30/30] -> loss: 0.771\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.771\n",
            "* Train accuracy: 66.99%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.582\n",
            "epoch: [2/30] -> loss: 0.507\n",
            "epoch: [3/30] -> loss: 0.493\n",
            "epoch: [4/30] -> loss: 0.480\n",
            "epoch: [5/30] -> loss: 0.482\n",
            "epoch: [6/30] -> loss: 0.476\n",
            "epoch: [7/30] -> loss: 0.475\n",
            "epoch: [8/30] -> loss: 0.475\n",
            "epoch: [9/30] -> loss: 0.472\n",
            "epoch: [10/30] -> loss: 0.474\n",
            "epoch: [11/30] -> loss: 0.469\n",
            "epoch: [12/30] -> loss: 0.473\n",
            "epoch: [13/30] -> loss: 0.473\n",
            "epoch: [14/30] -> loss: 0.467\n",
            "epoch: [15/30] -> loss: 0.469\n",
            "epoch: [16/30] -> loss: 0.471\n",
            "epoch: [17/30] -> loss: 0.467\n",
            "epoch: [18/30] -> loss: 0.472\n",
            "epoch: [19/30] -> loss: 0.468\n",
            "epoch: [20/30] -> loss: 0.469\n",
            "epoch: [21/30] -> loss: 0.472\n",
            "epoch: [22/30] -> loss: 0.470\n",
            "epoch: [23/30] -> loss: 0.465\n",
            "epoch: [24/30] -> loss: 0.467\n",
            "epoch: [25/30] -> loss: 0.468\n",
            "epoch: [26/30] -> loss: 0.472\n",
            "epoch: [27/30] -> loss: 0.470\n",
            "epoch: [28/30] -> loss: 0.469\n",
            "epoch: [29/30] -> loss: 0.465\n",
            "epoch: [30/30] -> loss: 0.467\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.467\n",
            "* Train accuracy: 85.12%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.193\n",
            "epoch: [2/30] -> loss: 1.087\n",
            "epoch: [3/30] -> loss: 1.088\n",
            "epoch: [4/30] -> loss: 1.087\n",
            "epoch: [5/30] -> loss: 1.086\n",
            "epoch: [6/30] -> loss: 1.083\n",
            "epoch: [7/30] -> loss: 1.085\n",
            "epoch: [8/30] -> loss: 1.083\n",
            "epoch: [9/30] -> loss: 1.083\n",
            "epoch: [10/30] -> loss: 1.082\n",
            "epoch: [11/30] -> loss: 1.084\n",
            "epoch: [12/30] -> loss: 1.084\n",
            "epoch: [13/30] -> loss: 1.086\n",
            "epoch: [14/30] -> loss: 1.085\n",
            "epoch: [15/30] -> loss: 1.088\n",
            "epoch: [16/30] -> loss: 1.084\n",
            "epoch: [17/30] -> loss: 1.084\n",
            "epoch: [18/30] -> loss: 1.084\n",
            "epoch: [19/30] -> loss: 1.086\n",
            "epoch: [20/30] -> loss: 1.086\n",
            "epoch: [21/30] -> loss: 1.081\n",
            "epoch: [22/30] -> loss: 1.083\n",
            "epoch: [23/30] -> loss: 1.082\n",
            "epoch: [24/30] -> loss: 1.086\n",
            "epoch: [25/30] -> loss: 1.085\n",
            "epoch: [26/30] -> loss: 1.085\n",
            "epoch: [27/30] -> loss: 1.083\n",
            "epoch: [28/30] -> loss: 1.084\n",
            "epoch: [29/30] -> loss: 1.089\n",
            "epoch: [30/30] -> loss: 1.083\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.083\n",
            "* Train accuracy: 56.87%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.839\n",
            "epoch: [2/30] -> loss: 0.744\n",
            "epoch: [3/30] -> loss: 0.741\n",
            "epoch: [4/30] -> loss: 0.738\n",
            "epoch: [5/30] -> loss: 0.739\n",
            "epoch: [6/30] -> loss: 0.742\n",
            "epoch: [7/30] -> loss: 0.738\n",
            "epoch: [8/30] -> loss: 0.740\n",
            "epoch: [9/30] -> loss: 0.736\n",
            "epoch: [10/30] -> loss: 0.735\n",
            "epoch: [11/30] -> loss: 0.735\n",
            "epoch: [12/30] -> loss: 0.738\n",
            "epoch: [13/30] -> loss: 0.737\n",
            "epoch: [14/30] -> loss: 0.740\n",
            "epoch: [15/30] -> loss: 0.736\n",
            "epoch: [16/30] -> loss: 0.735\n",
            "epoch: [17/30] -> loss: 0.739\n",
            "epoch: [18/30] -> loss: 0.737\n",
            "epoch: [19/30] -> loss: 0.735\n",
            "epoch: [20/30] -> loss: 0.736\n",
            "epoch: [21/30] -> loss: 0.738\n",
            "epoch: [22/30] -> loss: 0.738\n",
            "epoch: [23/30] -> loss: 0.738\n",
            "epoch: [24/30] -> loss: 0.736\n",
            "epoch: [25/30] -> loss: 0.738\n",
            "epoch: [26/30] -> loss: 0.738\n",
            "epoch: [27/30] -> loss: 0.737\n",
            "epoch: [28/30] -> loss: 0.736\n",
            "epoch: [29/30] -> loss: 0.736\n",
            "epoch: [30/30] -> loss: 0.735\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.735\n",
            "* Train accuracy: 74.54%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.603\n",
            "epoch: [2/30] -> loss: 0.509\n",
            "epoch: [3/30] -> loss: 0.491\n",
            "epoch: [4/30] -> loss: 0.480\n",
            "epoch: [5/30] -> loss: 0.476\n",
            "epoch: [6/30] -> loss: 0.469\n",
            "epoch: [7/30] -> loss: 0.466\n",
            "epoch: [8/30] -> loss: 0.461\n",
            "epoch: [9/30] -> loss: 0.461\n",
            "epoch: [10/30] -> loss: 0.460\n",
            "epoch: [11/30] -> loss: 0.457\n",
            "epoch: [12/30] -> loss: 0.456\n",
            "epoch: [13/30] -> loss: 0.456\n",
            "epoch: [14/30] -> loss: 0.455\n",
            "epoch: [15/30] -> loss: 0.453\n",
            "epoch: [16/30] -> loss: 0.454\n",
            "epoch: [17/30] -> loss: 0.453\n",
            "epoch: [18/30] -> loss: 0.455\n",
            "epoch: [19/30] -> loss: 0.455\n",
            "epoch: [20/30] -> loss: 0.452\n",
            "epoch: [21/30] -> loss: 0.451\n",
            "epoch: [22/30] -> loss: 0.451\n",
            "epoch: [23/30] -> loss: 0.450\n",
            "epoch: [24/30] -> loss: 0.451\n",
            "epoch: [25/30] -> loss: 0.452\n",
            "epoch: [26/30] -> loss: 0.449\n",
            "epoch: [27/30] -> loss: 0.451\n",
            "epoch: [28/30] -> loss: 0.449\n",
            "epoch: [29/30] -> loss: 0.451\n",
            "epoch: [30/30] -> loss: 0.450\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.450\n",
            "* Train accuracy: 82.79%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.574\n",
            "epoch: [2/30] -> loss: 1.024\n",
            "epoch: [3/30] -> loss: 1.021\n",
            "epoch: [4/30] -> loss: 1.020\n",
            "epoch: [5/30] -> loss: 1.021\n",
            "epoch: [6/30] -> loss: 1.022\n",
            "epoch: [7/30] -> loss: 1.021\n",
            "epoch: [8/30] -> loss: 1.021\n",
            "epoch: [9/30] -> loss: 1.020\n",
            "epoch: [10/30] -> loss: 1.022\n",
            "epoch: [11/30] -> loss: 1.021\n",
            "epoch: [12/30] -> loss: 1.020\n",
            "epoch: [13/30] -> loss: 1.021\n",
            "epoch: [14/30] -> loss: 1.021\n",
            "epoch: [15/30] -> loss: 1.020\n",
            "epoch: [16/30] -> loss: 1.021\n",
            "epoch: [17/30] -> loss: 1.020\n",
            "epoch: [18/30] -> loss: 1.021\n",
            "epoch: [19/30] -> loss: 1.021\n",
            "epoch: [20/30] -> loss: 1.021\n",
            "epoch: [21/30] -> loss: 1.021\n",
            "epoch: [22/30] -> loss: 1.021\n",
            "epoch: [23/30] -> loss: 1.021\n",
            "epoch: [24/30] -> loss: 1.021\n",
            "epoch: [25/30] -> loss: 1.020\n",
            "epoch: [26/30] -> loss: 1.021\n",
            "epoch: [27/30] -> loss: 1.022\n",
            "epoch: [28/30] -> loss: 1.021\n",
            "epoch: [29/30] -> loss: 1.020\n",
            "epoch: [30/30] -> loss: 1.021\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.021\n",
            "* Train accuracy: 56.67%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.982\n",
            "epoch: [2/30] -> loss: 0.830\n",
            "epoch: [3/30] -> loss: 0.774\n",
            "epoch: [4/30] -> loss: 0.747\n",
            "epoch: [5/30] -> loss: 0.732\n",
            "epoch: [6/30] -> loss: 0.726\n",
            "epoch: [7/30] -> loss: 0.721\n",
            "epoch: [8/30] -> loss: 0.719\n",
            "epoch: [9/30] -> loss: 0.719\n",
            "epoch: [10/30] -> loss: 0.718\n",
            "epoch: [11/30] -> loss: 0.717\n",
            "epoch: [12/30] -> loss: 0.718\n",
            "epoch: [13/30] -> loss: 0.717\n",
            "epoch: [14/30] -> loss: 0.718\n",
            "epoch: [15/30] -> loss: 0.717\n",
            "epoch: [16/30] -> loss: 0.717\n",
            "epoch: [17/30] -> loss: 0.718\n",
            "epoch: [18/30] -> loss: 0.718\n",
            "epoch: [19/30] -> loss: 0.717\n",
            "epoch: [20/30] -> loss: 0.718\n",
            "epoch: [21/30] -> loss: 0.717\n",
            "epoch: [22/30] -> loss: 0.715\n",
            "epoch: [23/30] -> loss: 0.716\n",
            "epoch: [24/30] -> loss: 0.716\n",
            "epoch: [25/30] -> loss: 0.715\n",
            "epoch: [26/30] -> loss: 0.717\n",
            "epoch: [27/30] -> loss: 0.716\n",
            "epoch: [28/30] -> loss: 0.717\n",
            "epoch: [29/30] -> loss: 0.715\n",
            "epoch: [30/30] -> loss: 0.717\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.717\n",
            "* Train accuracy: 79.19%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.734\n",
            "epoch: [2/30] -> loss: 0.600\n",
            "epoch: [3/30] -> loss: 0.555\n",
            "epoch: [4/30] -> loss: 0.532\n",
            "epoch: [5/30] -> loss: 0.517\n",
            "epoch: [6/30] -> loss: 0.507\n",
            "epoch: [7/30] -> loss: 0.499\n",
            "epoch: [8/30] -> loss: 0.493\n",
            "epoch: [9/30] -> loss: 0.488\n",
            "epoch: [10/30] -> loss: 0.484\n",
            "epoch: [11/30] -> loss: 0.479\n",
            "epoch: [12/30] -> loss: 0.476\n",
            "epoch: [13/30] -> loss: 0.473\n",
            "epoch: [14/30] -> loss: 0.471\n",
            "epoch: [15/30] -> loss: 0.471\n",
            "epoch: [16/30] -> loss: 0.468\n",
            "epoch: [17/30] -> loss: 0.467\n",
            "epoch: [18/30] -> loss: 0.466\n",
            "epoch: [19/30] -> loss: 0.463\n",
            "epoch: [20/30] -> loss: 0.462\n",
            "epoch: [21/30] -> loss: 0.462\n",
            "epoch: [22/30] -> loss: 0.460\n",
            "epoch: [23/30] -> loss: 0.458\n",
            "epoch: [24/30] -> loss: 0.457\n",
            "epoch: [25/30] -> loss: 0.456\n",
            "epoch: [26/30] -> loss: 0.457\n",
            "epoch: [27/30] -> loss: 0.456\n",
            "epoch: [28/30] -> loss: 0.455\n",
            "epoch: [29/30] -> loss: 0.452\n",
            "epoch: [30/30] -> loss: 0.453\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.453\n",
            "* Train accuracy: 84.16%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 2.115\n",
            "epoch: [2/30] -> loss: 1.018\n",
            "epoch: [3/30] -> loss: 1.012\n",
            "epoch: [4/30] -> loss: 1.012\n",
            "epoch: [5/30] -> loss: 1.012\n",
            "epoch: [6/30] -> loss: 1.012\n",
            "epoch: [7/30] -> loss: 1.012\n",
            "epoch: [8/30] -> loss: 1.012\n",
            "epoch: [9/30] -> loss: 1.012\n",
            "epoch: [10/30] -> loss: 1.012\n",
            "epoch: [11/30] -> loss: 1.012\n",
            "epoch: [12/30] -> loss: 1.012\n",
            "epoch: [13/30] -> loss: 1.012\n",
            "epoch: [14/30] -> loss: 1.012\n",
            "epoch: [15/30] -> loss: 1.012\n",
            "epoch: [16/30] -> loss: 1.012\n",
            "epoch: [17/30] -> loss: 1.012\n",
            "epoch: [18/30] -> loss: 1.012\n",
            "epoch: [19/30] -> loss: 1.012\n",
            "epoch: [20/30] -> loss: 1.012\n",
            "epoch: [21/30] -> loss: 1.012\n",
            "epoch: [22/30] -> loss: 1.012\n",
            "epoch: [23/30] -> loss: 1.012\n",
            "epoch: [24/30] -> loss: 1.012\n",
            "epoch: [25/30] -> loss: 1.012\n",
            "epoch: [26/30] -> loss: 1.012\n",
            "epoch: [27/30] -> loss: 1.012\n",
            "epoch: [28/30] -> loss: 1.012\n",
            "epoch: [29/30] -> loss: 1.012\n",
            "epoch: [30/30] -> loss: 1.012\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.012\n",
            "* Train accuracy: 51.08%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.030\n",
            "epoch: [2/30] -> loss: 0.900\n",
            "epoch: [3/30] -> loss: 0.838\n",
            "epoch: [4/30] -> loss: 0.801\n",
            "epoch: [5/30] -> loss: 0.777\n",
            "epoch: [6/30] -> loss: 0.760\n",
            "epoch: [7/30] -> loss: 0.747\n",
            "epoch: [8/30] -> loss: 0.738\n",
            "epoch: [9/30] -> loss: 0.730\n",
            "epoch: [10/30] -> loss: 0.726\n",
            "epoch: [11/30] -> loss: 0.723\n",
            "epoch: [12/30] -> loss: 0.721\n",
            "epoch: [13/30] -> loss: 0.719\n",
            "epoch: [14/30] -> loss: 0.718\n",
            "epoch: [15/30] -> loss: 0.717\n",
            "epoch: [16/30] -> loss: 0.716\n",
            "epoch: [17/30] -> loss: 0.717\n",
            "epoch: [18/30] -> loss: 0.716\n",
            "epoch: [19/30] -> loss: 0.715\n",
            "epoch: [20/30] -> loss: 0.715\n",
            "epoch: [21/30] -> loss: 0.714\n",
            "epoch: [22/30] -> loss: 0.716\n",
            "epoch: [23/30] -> loss: 0.716\n",
            "epoch: [24/30] -> loss: 0.715\n",
            "epoch: [25/30] -> loss: 0.716\n",
            "epoch: [26/30] -> loss: 0.716\n",
            "epoch: [27/30] -> loss: 0.714\n",
            "epoch: [28/30] -> loss: 0.715\n",
            "epoch: [29/30] -> loss: 0.715\n",
            "epoch: [30/30] -> loss: 0.714\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.714\n",
            "* Train accuracy: 79.49%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.779\n",
            "epoch: [2/30] -> loss: 0.658\n",
            "epoch: [3/30] -> loss: 0.605\n",
            "epoch: [4/30] -> loss: 0.577\n",
            "epoch: [5/30] -> loss: 0.554\n",
            "epoch: [6/30] -> loss: 0.541\n",
            "epoch: [7/30] -> loss: 0.529\n",
            "epoch: [8/30] -> loss: 0.520\n",
            "epoch: [9/30] -> loss: 0.514\n",
            "epoch: [10/30] -> loss: 0.509\n",
            "epoch: [11/30] -> loss: 0.504\n",
            "epoch: [12/30] -> loss: 0.501\n",
            "epoch: [13/30] -> loss: 0.495\n",
            "epoch: [14/30] -> loss: 0.492\n",
            "epoch: [15/30] -> loss: 0.491\n",
            "epoch: [16/30] -> loss: 0.488\n",
            "epoch: [17/30] -> loss: 0.485\n",
            "epoch: [18/30] -> loss: 0.482\n",
            "epoch: [19/30] -> loss: 0.482\n",
            "epoch: [20/30] -> loss: 0.479\n",
            "epoch: [21/30] -> loss: 0.477\n",
            "epoch: [22/30] -> loss: 0.476\n",
            "epoch: [23/30] -> loss: 0.474\n",
            "epoch: [24/30] -> loss: 0.473\n",
            "epoch: [25/30] -> loss: 0.471\n",
            "epoch: [26/30] -> loss: 0.471\n",
            "epoch: [27/30] -> loss: 0.469\n",
            "epoch: [28/30] -> loss: 0.469\n",
            "epoch: [29/30] -> loss: 0.469\n",
            "epoch: [30/30] -> loss: 0.467\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.467\n",
            "* Train accuracy: 83.74%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 3.443\n",
            "epoch: [2/30] -> loss: 2.696\n",
            "epoch: [3/30] -> loss: 2.019\n",
            "epoch: [4/30] -> loss: 1.433\n",
            "epoch: [5/30] -> loss: 1.084\n",
            "epoch: [6/30] -> loss: 1.011\n",
            "epoch: [7/30] -> loss: 1.005\n",
            "epoch: [8/30] -> loss: 1.005\n",
            "epoch: [9/30] -> loss: 1.005\n",
            "epoch: [10/30] -> loss: 1.005\n",
            "epoch: [11/30] -> loss: 1.005\n",
            "epoch: [12/30] -> loss: 1.005\n",
            "epoch: [13/30] -> loss: 1.005\n",
            "epoch: [14/30] -> loss: 1.005\n",
            "epoch: [15/30] -> loss: 1.005\n",
            "epoch: [16/30] -> loss: 1.005\n",
            "epoch: [17/30] -> loss: 1.005\n",
            "epoch: [18/30] -> loss: 1.005\n",
            "epoch: [19/30] -> loss: 1.005\n",
            "epoch: [20/30] -> loss: 1.005\n",
            "epoch: [21/30] -> loss: 1.005\n",
            "epoch: [22/30] -> loss: 1.005\n",
            "epoch: [23/30] -> loss: 1.005\n",
            "epoch: [24/30] -> loss: 1.005\n",
            "epoch: [25/30] -> loss: 1.005\n",
            "epoch: [26/30] -> loss: 1.005\n",
            "epoch: [27/30] -> loss: 1.005\n",
            "epoch: [28/30] -> loss: 1.005\n",
            "epoch: [29/30] -> loss: 1.005\n",
            "epoch: [30/30] -> loss: 1.005\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.005\n",
            "* Train accuracy: 61.99%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.180\n",
            "epoch: [2/30] -> loss: 1.075\n",
            "epoch: [3/30] -> loss: 1.025\n",
            "epoch: [4/30] -> loss: 0.989\n",
            "epoch: [5/30] -> loss: 0.959\n",
            "epoch: [6/30] -> loss: 0.935\n",
            "epoch: [7/30] -> loss: 0.916\n",
            "epoch: [8/30] -> loss: 0.898\n",
            "epoch: [9/30] -> loss: 0.883\n",
            "epoch: [10/30] -> loss: 0.870\n",
            "epoch: [11/30] -> loss: 0.857\n",
            "epoch: [12/30] -> loss: 0.847\n",
            "epoch: [13/30] -> loss: 0.838\n",
            "epoch: [14/30] -> loss: 0.829\n",
            "epoch: [15/30] -> loss: 0.821\n",
            "epoch: [16/30] -> loss: 0.814\n",
            "epoch: [17/30] -> loss: 0.806\n",
            "epoch: [18/30] -> loss: 0.801\n",
            "epoch: [19/30] -> loss: 0.795\n",
            "epoch: [20/30] -> loss: 0.791\n",
            "epoch: [21/30] -> loss: 0.786\n",
            "epoch: [22/30] -> loss: 0.780\n",
            "epoch: [23/30] -> loss: 0.777\n",
            "epoch: [24/30] -> loss: 0.773\n",
            "epoch: [25/30] -> loss: 0.768\n",
            "epoch: [26/30] -> loss: 0.765\n",
            "epoch: [27/30] -> loss: 0.762\n",
            "epoch: [28/30] -> loss: 0.759\n",
            "epoch: [29/30] -> loss: 0.755\n",
            "epoch: [30/30] -> loss: 0.754\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.754\n",
            "* Train accuracy: 79.12%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.904\n",
            "epoch: [2/30] -> loss: 0.810\n",
            "epoch: [3/30] -> loss: 0.767\n",
            "epoch: [4/30] -> loss: 0.736\n",
            "epoch: [5/30] -> loss: 0.711\n",
            "epoch: [6/30] -> loss: 0.690\n",
            "epoch: [7/30] -> loss: 0.672\n",
            "epoch: [8/30] -> loss: 0.656\n",
            "epoch: [9/30] -> loss: 0.644\n",
            "epoch: [10/30] -> loss: 0.632\n",
            "epoch: [11/30] -> loss: 0.623\n",
            "epoch: [12/30] -> loss: 0.613\n",
            "epoch: [13/30] -> loss: 0.604\n",
            "epoch: [14/30] -> loss: 0.598\n",
            "epoch: [15/30] -> loss: 0.590\n",
            "epoch: [16/30] -> loss: 0.583\n",
            "epoch: [17/30] -> loss: 0.579\n",
            "epoch: [18/30] -> loss: 0.573\n",
            "epoch: [19/30] -> loss: 0.569\n",
            "epoch: [20/30] -> loss: 0.565\n",
            "epoch: [21/30] -> loss: 0.561\n",
            "epoch: [22/30] -> loss: 0.557\n",
            "epoch: [23/30] -> loss: 0.554\n",
            "epoch: [24/30] -> loss: 0.551\n",
            "epoch: [25/30] -> loss: 0.549\n",
            "epoch: [26/30] -> loss: 0.545\n",
            "epoch: [27/30] -> loss: 0.542\n",
            "epoch: [28/30] -> loss: 0.540\n",
            "epoch: [29/30] -> loss: 0.537\n",
            "epoch: [30/30] -> loss: 0.535\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.535\n",
            "* Train accuracy: 80.39%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.245\n",
            "epoch: [2/10] -> loss: 1.135\n",
            "epoch: [3/10] -> loss: 1.139\n",
            "epoch: [4/10] -> loss: 1.128\n",
            "epoch: [5/10] -> loss: 1.141\n",
            "epoch: [6/10] -> loss: 1.128\n",
            "epoch: [7/10] -> loss: 1.132\n",
            "epoch: [8/10] -> loss: 1.128\n",
            "epoch: [9/10] -> loss: 1.129\n",
            "epoch: [10/10] -> loss: 1.141\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.141\n",
            "* Train accuracy: 60.91%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.841\n",
            "epoch: [2/10] -> loss: 0.751\n",
            "epoch: [3/10] -> loss: 0.746\n",
            "epoch: [4/10] -> loss: 0.750\n",
            "epoch: [5/10] -> loss: 0.750\n",
            "epoch: [6/10] -> loss: 0.751\n",
            "epoch: [7/10] -> loss: 0.744\n",
            "epoch: [8/10] -> loss: 0.747\n",
            "epoch: [9/10] -> loss: 0.747\n",
            "epoch: [10/10] -> loss: 0.747\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.747\n",
            "* Train accuracy: 79.86%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.610\n",
            "epoch: [2/10] -> loss: 0.518\n",
            "epoch: [3/10] -> loss: 0.498\n",
            "epoch: [4/10] -> loss: 0.486\n",
            "epoch: [5/10] -> loss: 0.480\n",
            "epoch: [6/10] -> loss: 0.475\n",
            "epoch: [7/10] -> loss: 0.472\n",
            "epoch: [8/10] -> loss: 0.465\n",
            "epoch: [9/10] -> loss: 0.463\n",
            "epoch: [10/10] -> loss: 0.463\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.463\n",
            "* Train accuracy: 84.08%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.286\n",
            "epoch: [2/10] -> loss: 1.070\n",
            "epoch: [3/10] -> loss: 1.065\n",
            "epoch: [4/10] -> loss: 1.066\n",
            "epoch: [5/10] -> loss: 1.062\n",
            "epoch: [6/10] -> loss: 1.064\n",
            "epoch: [7/10] -> loss: 1.065\n",
            "epoch: [8/10] -> loss: 1.065\n",
            "epoch: [9/10] -> loss: 1.065\n",
            "epoch: [10/10] -> loss: 1.065\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.065\n",
            "* Train accuracy: 48.92%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.891\n",
            "epoch: [2/10] -> loss: 0.760\n",
            "epoch: [3/10] -> loss: 0.740\n",
            "epoch: [4/10] -> loss: 0.732\n",
            "epoch: [5/10] -> loss: 0.732\n",
            "epoch: [6/10] -> loss: 0.731\n",
            "epoch: [7/10] -> loss: 0.730\n",
            "epoch: [8/10] -> loss: 0.732\n",
            "epoch: [9/10] -> loss: 0.730\n",
            "epoch: [10/10] -> loss: 0.729\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.729\n",
            "* Train accuracy: 80.47%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.648\n",
            "epoch: [2/10] -> loss: 0.536\n",
            "epoch: [3/10] -> loss: 0.509\n",
            "epoch: [4/10] -> loss: 0.494\n",
            "epoch: [5/10] -> loss: 0.484\n",
            "epoch: [6/10] -> loss: 0.479\n",
            "epoch: [7/10] -> loss: 0.473\n",
            "epoch: [8/10] -> loss: 0.470\n",
            "epoch: [9/10] -> loss: 0.465\n",
            "epoch: [10/10] -> loss: 0.463\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.463\n",
            "* Train accuracy: 84.09%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 2.127\n",
            "epoch: [2/10] -> loss: 1.028\n",
            "epoch: [3/10] -> loss: 1.019\n",
            "epoch: [4/10] -> loss: 1.019\n",
            "epoch: [5/10] -> loss: 1.018\n",
            "epoch: [6/10] -> loss: 1.019\n",
            "epoch: [7/10] -> loss: 1.019\n",
            "epoch: [8/10] -> loss: 1.019\n",
            "epoch: [9/10] -> loss: 1.019\n",
            "epoch: [10/10] -> loss: 1.019\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.019\n",
            "* Train accuracy: 59.96%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.039\n",
            "epoch: [2/10] -> loss: 0.909\n",
            "epoch: [3/10] -> loss: 0.845\n",
            "epoch: [4/10] -> loss: 0.808\n",
            "epoch: [5/10] -> loss: 0.784\n",
            "epoch: [6/10] -> loss: 0.765\n",
            "epoch: [7/10] -> loss: 0.753\n",
            "epoch: [8/10] -> loss: 0.744\n",
            "epoch: [9/10] -> loss: 0.737\n",
            "epoch: [10/10] -> loss: 0.732\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.732\n",
            "* Train accuracy: 79.10%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.803\n",
            "epoch: [2/10] -> loss: 0.671\n",
            "epoch: [3/10] -> loss: 0.615\n",
            "epoch: [4/10] -> loss: 0.582\n",
            "epoch: [5/10] -> loss: 0.562\n",
            "epoch: [6/10] -> loss: 0.547\n",
            "epoch: [7/10] -> loss: 0.536\n",
            "epoch: [8/10] -> loss: 0.527\n",
            "epoch: [9/10] -> loss: 0.521\n",
            "epoch: [10/10] -> loss: 0.514\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.514\n",
            "* Train accuracy: 81.32%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 2.884\n",
            "epoch: [2/10] -> loss: 1.394\n",
            "epoch: [3/10] -> loss: 1.018\n",
            "epoch: [4/10] -> loss: 1.013\n",
            "epoch: [5/10] -> loss: 1.013\n",
            "epoch: [6/10] -> loss: 1.013\n",
            "epoch: [7/10] -> loss: 1.013\n",
            "epoch: [8/10] -> loss: 1.013\n",
            "epoch: [9/10] -> loss: 1.013\n",
            "epoch: [10/10] -> loss: 1.013\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.013\n",
            "* Train accuracy: 63.73%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.086\n",
            "epoch: [2/10] -> loss: 0.986\n",
            "epoch: [3/10] -> loss: 0.926\n",
            "epoch: [4/10] -> loss: 0.885\n",
            "epoch: [5/10] -> loss: 0.854\n",
            "epoch: [6/10] -> loss: 0.831\n",
            "epoch: [7/10] -> loss: 0.812\n",
            "epoch: [8/10] -> loss: 0.797\n",
            "epoch: [9/10] -> loss: 0.785\n",
            "epoch: [10/10] -> loss: 0.774\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.774\n",
            "* Train accuracy: 78.63%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.856\n",
            "epoch: [2/10] -> loss: 0.747\n",
            "epoch: [3/10] -> loss: 0.688\n",
            "epoch: [4/10] -> loss: 0.650\n",
            "epoch: [5/10] -> loss: 0.623\n",
            "epoch: [6/10] -> loss: 0.603\n",
            "epoch: [7/10] -> loss: 0.587\n",
            "epoch: [8/10] -> loss: 0.575\n",
            "epoch: [9/10] -> loss: 0.564\n",
            "epoch: [10/10] -> loss: 0.556\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.556\n",
            "* Train accuracy: 79.94%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 3.694\n",
            "epoch: [2/10] -> loss: 3.263\n",
            "epoch: [3/10] -> loss: 2.877\n",
            "epoch: [4/10] -> loss: 2.511\n",
            "epoch: [5/10] -> loss: 2.164\n",
            "epoch: [6/10] -> loss: 1.836\n",
            "epoch: [7/10] -> loss: 1.536\n",
            "epoch: [8/10] -> loss: 1.281\n",
            "epoch: [9/10] -> loss: 1.109\n",
            "epoch: [10/10] -> loss: 1.042\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.042\n",
            "* Train accuracy: 61.43%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.218\n",
            "epoch: [2/10] -> loss: 1.119\n",
            "epoch: [3/10] -> loss: 1.087\n",
            "epoch: [4/10] -> loss: 1.062\n",
            "epoch: [5/10] -> loss: 1.040\n",
            "epoch: [6/10] -> loss: 1.020\n",
            "epoch: [7/10] -> loss: 1.004\n",
            "epoch: [8/10] -> loss: 0.988\n",
            "epoch: [9/10] -> loss: 0.974\n",
            "epoch: [10/10] -> loss: 0.961\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.961\n",
            "* Train accuracy: 70.69%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.960\n",
            "epoch: [2/10] -> loss: 0.876\n",
            "epoch: [3/10] -> loss: 0.842\n",
            "epoch: [4/10] -> loss: 0.817\n",
            "epoch: [5/10] -> loss: 0.796\n",
            "epoch: [6/10] -> loss: 0.778\n",
            "epoch: [7/10] -> loss: 0.761\n",
            "epoch: [8/10] -> loss: 0.747\n",
            "epoch: [9/10] -> loss: 0.733\n",
            "epoch: [10/10] -> loss: 0.721\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.721\n",
            "* Train accuracy: 71.02%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.248\n",
            "epoch: [2/20] -> loss: 1.145\n",
            "epoch: [3/20] -> loss: 1.136\n",
            "epoch: [4/20] -> loss: 1.128\n",
            "epoch: [5/20] -> loss: 1.123\n",
            "epoch: [6/20] -> loss: 1.140\n",
            "epoch: [7/20] -> loss: 1.134\n",
            "epoch: [8/20] -> loss: 1.133\n",
            "epoch: [9/20] -> loss: 1.127\n",
            "epoch: [10/20] -> loss: 1.139\n",
            "epoch: [11/20] -> loss: 1.140\n",
            "epoch: [12/20] -> loss: 1.131\n",
            "epoch: [13/20] -> loss: 1.137\n",
            "epoch: [14/20] -> loss: 1.138\n",
            "epoch: [15/20] -> loss: 1.128\n",
            "epoch: [16/20] -> loss: 1.128\n",
            "epoch: [17/20] -> loss: 1.137\n",
            "epoch: [18/20] -> loss: 1.132\n",
            "epoch: [19/20] -> loss: 1.127\n",
            "epoch: [20/20] -> loss: 1.137\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.137\n",
            "* Train accuracy: 49.94%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.840\n",
            "epoch: [2/20] -> loss: 0.753\n",
            "epoch: [3/20] -> loss: 0.746\n",
            "epoch: [4/20] -> loss: 0.750\n",
            "epoch: [5/20] -> loss: 0.748\n",
            "epoch: [6/20] -> loss: 0.748\n",
            "epoch: [7/20] -> loss: 0.753\n",
            "epoch: [8/20] -> loss: 0.753\n",
            "epoch: [9/20] -> loss: 0.749\n",
            "epoch: [10/20] -> loss: 0.749\n",
            "epoch: [11/20] -> loss: 0.745\n",
            "epoch: [12/20] -> loss: 0.747\n",
            "epoch: [13/20] -> loss: 0.745\n",
            "epoch: [14/20] -> loss: 0.747\n",
            "epoch: [15/20] -> loss: 0.750\n",
            "epoch: [16/20] -> loss: 0.744\n",
            "epoch: [17/20] -> loss: 0.748\n",
            "epoch: [18/20] -> loss: 0.750\n",
            "epoch: [19/20] -> loss: 0.751\n",
            "epoch: [20/20] -> loss: 0.751\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.751\n",
            "* Train accuracy: 79.52%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.613\n",
            "epoch: [2/20] -> loss: 0.516\n",
            "epoch: [3/20] -> loss: 0.495\n",
            "epoch: [4/20] -> loss: 0.486\n",
            "epoch: [5/20] -> loss: 0.477\n",
            "epoch: [6/20] -> loss: 0.474\n",
            "epoch: [7/20] -> loss: 0.469\n",
            "epoch: [8/20] -> loss: 0.466\n",
            "epoch: [9/20] -> loss: 0.466\n",
            "epoch: [10/20] -> loss: 0.463\n",
            "epoch: [11/20] -> loss: 0.463\n",
            "epoch: [12/20] -> loss: 0.461\n",
            "epoch: [13/20] -> loss: 0.460\n",
            "epoch: [14/20] -> loss: 0.462\n",
            "epoch: [15/20] -> loss: 0.457\n",
            "epoch: [16/20] -> loss: 0.457\n",
            "epoch: [17/20] -> loss: 0.457\n",
            "epoch: [18/20] -> loss: 0.457\n",
            "epoch: [19/20] -> loss: 0.455\n",
            "epoch: [20/20] -> loss: 0.455\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.455\n",
            "* Train accuracy: 85.43%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.285\n",
            "epoch: [2/20] -> loss: 1.064\n",
            "epoch: [3/20] -> loss: 1.065\n",
            "epoch: [4/20] -> loss: 1.065\n",
            "epoch: [5/20] -> loss: 1.063\n",
            "epoch: [6/20] -> loss: 1.064\n",
            "epoch: [7/20] -> loss: 1.065\n",
            "epoch: [8/20] -> loss: 1.066\n",
            "epoch: [9/20] -> loss: 1.061\n",
            "epoch: [10/20] -> loss: 1.065\n",
            "epoch: [11/20] -> loss: 1.068\n",
            "epoch: [12/20] -> loss: 1.062\n",
            "epoch: [13/20] -> loss: 1.065\n",
            "epoch: [14/20] -> loss: 1.061\n",
            "epoch: [15/20] -> loss: 1.064\n",
            "epoch: [16/20] -> loss: 1.062\n",
            "epoch: [17/20] -> loss: 1.063\n",
            "epoch: [18/20] -> loss: 1.066\n",
            "epoch: [19/20] -> loss: 1.063\n",
            "epoch: [20/20] -> loss: 1.062\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.062\n",
            "* Train accuracy: 61.03%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.891\n",
            "epoch: [2/20] -> loss: 0.757\n",
            "epoch: [3/20] -> loss: 0.737\n",
            "epoch: [4/20] -> loss: 0.733\n",
            "epoch: [5/20] -> loss: 0.732\n",
            "epoch: [6/20] -> loss: 0.731\n",
            "epoch: [7/20] -> loss: 0.732\n",
            "epoch: [8/20] -> loss: 0.733\n",
            "epoch: [9/20] -> loss: 0.732\n",
            "epoch: [10/20] -> loss: 0.733\n",
            "epoch: [11/20] -> loss: 0.729\n",
            "epoch: [12/20] -> loss: 0.730\n",
            "epoch: [13/20] -> loss: 0.730\n",
            "epoch: [14/20] -> loss: 0.730\n",
            "epoch: [15/20] -> loss: 0.729\n",
            "epoch: [16/20] -> loss: 0.731\n",
            "epoch: [17/20] -> loss: 0.729\n",
            "epoch: [18/20] -> loss: 0.728\n",
            "epoch: [19/20] -> loss: 0.731\n",
            "epoch: [20/20] -> loss: 0.730\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.730\n",
            "* Train accuracy: 80.07%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.659\n",
            "epoch: [2/20] -> loss: 0.540\n",
            "epoch: [3/20] -> loss: 0.509\n",
            "epoch: [4/20] -> loss: 0.496\n",
            "epoch: [5/20] -> loss: 0.486\n",
            "epoch: [6/20] -> loss: 0.480\n",
            "epoch: [7/20] -> loss: 0.474\n",
            "epoch: [8/20] -> loss: 0.472\n",
            "epoch: [9/20] -> loss: 0.468\n",
            "epoch: [10/20] -> loss: 0.466\n",
            "epoch: [11/20] -> loss: 0.463\n",
            "epoch: [12/20] -> loss: 0.461\n",
            "epoch: [13/20] -> loss: 0.459\n",
            "epoch: [14/20] -> loss: 0.457\n",
            "epoch: [15/20] -> loss: 0.456\n",
            "epoch: [16/20] -> loss: 0.456\n",
            "epoch: [17/20] -> loss: 0.453\n",
            "epoch: [18/20] -> loss: 0.454\n",
            "epoch: [19/20] -> loss: 0.453\n",
            "epoch: [20/20] -> loss: 0.452\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.452\n",
            "* Train accuracy: 84.69%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 2.144\n",
            "epoch: [2/20] -> loss: 1.028\n",
            "epoch: [3/20] -> loss: 1.018\n",
            "epoch: [4/20] -> loss: 1.019\n",
            "epoch: [5/20] -> loss: 1.019\n",
            "epoch: [6/20] -> loss: 1.018\n",
            "epoch: [7/20] -> loss: 1.019\n",
            "epoch: [8/20] -> loss: 1.019\n",
            "epoch: [9/20] -> loss: 1.019\n",
            "epoch: [10/20] -> loss: 1.019\n",
            "epoch: [11/20] -> loss: 1.019\n",
            "epoch: [12/20] -> loss: 1.019\n",
            "epoch: [13/20] -> loss: 1.019\n",
            "epoch: [14/20] -> loss: 1.019\n",
            "epoch: [15/20] -> loss: 1.018\n",
            "epoch: [16/20] -> loss: 1.019\n",
            "epoch: [17/20] -> loss: 1.018\n",
            "epoch: [18/20] -> loss: 1.019\n",
            "epoch: [19/20] -> loss: 1.019\n",
            "epoch: [20/20] -> loss: 1.019\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.019\n",
            "* Train accuracy: 60.86%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.052\n",
            "epoch: [2/20] -> loss: 0.914\n",
            "epoch: [3/20] -> loss: 0.848\n",
            "epoch: [4/20] -> loss: 0.810\n",
            "epoch: [5/20] -> loss: 0.784\n",
            "epoch: [6/20] -> loss: 0.766\n",
            "epoch: [7/20] -> loss: 0.753\n",
            "epoch: [8/20] -> loss: 0.744\n",
            "epoch: [9/20] -> loss: 0.737\n",
            "epoch: [10/20] -> loss: 0.733\n",
            "epoch: [11/20] -> loss: 0.729\n",
            "epoch: [12/20] -> loss: 0.726\n",
            "epoch: [13/20] -> loss: 0.725\n",
            "epoch: [14/20] -> loss: 0.724\n",
            "epoch: [15/20] -> loss: 0.723\n",
            "epoch: [16/20] -> loss: 0.721\n",
            "epoch: [17/20] -> loss: 0.721\n",
            "epoch: [18/20] -> loss: 0.721\n",
            "epoch: [19/20] -> loss: 0.721\n",
            "epoch: [20/20] -> loss: 0.721\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.721\n",
            "* Train accuracy: 79.42%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.802\n",
            "epoch: [2/20] -> loss: 0.675\n",
            "epoch: [3/20] -> loss: 0.617\n",
            "epoch: [4/20] -> loss: 0.585\n",
            "epoch: [5/20] -> loss: 0.563\n",
            "epoch: [6/20] -> loss: 0.547\n",
            "epoch: [7/20] -> loss: 0.538\n",
            "epoch: [8/20] -> loss: 0.528\n",
            "epoch: [9/20] -> loss: 0.521\n",
            "epoch: [10/20] -> loss: 0.515\n",
            "epoch: [11/20] -> loss: 0.509\n",
            "epoch: [12/20] -> loss: 0.505\n",
            "epoch: [13/20] -> loss: 0.501\n",
            "epoch: [14/20] -> loss: 0.498\n",
            "epoch: [15/20] -> loss: 0.495\n",
            "epoch: [16/20] -> loss: 0.492\n",
            "epoch: [17/20] -> loss: 0.489\n",
            "epoch: [18/20] -> loss: 0.487\n",
            "epoch: [19/20] -> loss: 0.485\n",
            "epoch: [20/20] -> loss: 0.483\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.483\n",
            "* Train accuracy: 82.87%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 2.874\n",
            "epoch: [2/20] -> loss: 1.378\n",
            "epoch: [3/20] -> loss: 1.016\n",
            "epoch: [4/20] -> loss: 1.013\n",
            "epoch: [5/20] -> loss: 1.013\n",
            "epoch: [6/20] -> loss: 1.013\n",
            "epoch: [7/20] -> loss: 1.013\n",
            "epoch: [8/20] -> loss: 1.013\n",
            "epoch: [9/20] -> loss: 1.013\n",
            "epoch: [10/20] -> loss: 1.013\n",
            "epoch: [11/20] -> loss: 1.013\n",
            "epoch: [12/20] -> loss: 1.013\n",
            "epoch: [13/20] -> loss: 1.013\n",
            "epoch: [14/20] -> loss: 1.013\n",
            "epoch: [15/20] -> loss: 1.013\n",
            "epoch: [16/20] -> loss: 1.013\n",
            "epoch: [17/20] -> loss: 1.013\n",
            "epoch: [18/20] -> loss: 1.013\n",
            "epoch: [19/20] -> loss: 1.013\n",
            "epoch: [20/20] -> loss: 1.013\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.013\n",
            "* Train accuracy: 60.90%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.097\n",
            "epoch: [2/20] -> loss: 0.990\n",
            "epoch: [3/20] -> loss: 0.926\n",
            "epoch: [4/20] -> loss: 0.885\n",
            "epoch: [5/20] -> loss: 0.854\n",
            "epoch: [6/20] -> loss: 0.831\n",
            "epoch: [7/20] -> loss: 0.813\n",
            "epoch: [8/20] -> loss: 0.798\n",
            "epoch: [9/20] -> loss: 0.786\n",
            "epoch: [10/20] -> loss: 0.775\n",
            "epoch: [11/20] -> loss: 0.767\n",
            "epoch: [12/20] -> loss: 0.760\n",
            "epoch: [13/20] -> loss: 0.754\n",
            "epoch: [14/20] -> loss: 0.749\n",
            "epoch: [15/20] -> loss: 0.744\n",
            "epoch: [16/20] -> loss: 0.740\n",
            "epoch: [17/20] -> loss: 0.737\n",
            "epoch: [18/20] -> loss: 0.734\n",
            "epoch: [19/20] -> loss: 0.732\n",
            "epoch: [20/20] -> loss: 0.730\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.730\n",
            "* Train accuracy: 79.21%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.829\n",
            "epoch: [2/20] -> loss: 0.736\n",
            "epoch: [3/20] -> loss: 0.682\n",
            "epoch: [4/20] -> loss: 0.646\n",
            "epoch: [5/20] -> loss: 0.620\n",
            "epoch: [6/20] -> loss: 0.600\n",
            "epoch: [7/20] -> loss: 0.585\n",
            "epoch: [8/20] -> loss: 0.574\n",
            "epoch: [9/20] -> loss: 0.563\n",
            "epoch: [10/20] -> loss: 0.555\n",
            "epoch: [11/20] -> loss: 0.548\n",
            "epoch: [12/20] -> loss: 0.541\n",
            "epoch: [13/20] -> loss: 0.536\n",
            "epoch: [14/20] -> loss: 0.531\n",
            "epoch: [15/20] -> loss: 0.527\n",
            "epoch: [16/20] -> loss: 0.522\n",
            "epoch: [17/20] -> loss: 0.519\n",
            "epoch: [18/20] -> loss: 0.516\n",
            "epoch: [19/20] -> loss: 0.513\n",
            "epoch: [20/20] -> loss: 0.510\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.510\n",
            "* Train accuracy: 81.77%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 3.640\n",
            "epoch: [2/20] -> loss: 3.231\n",
            "epoch: [3/20] -> loss: 2.864\n",
            "epoch: [4/20] -> loss: 2.512\n",
            "epoch: [5/20] -> loss: 2.175\n",
            "epoch: [6/20] -> loss: 1.856\n",
            "epoch: [7/20] -> loss: 1.560\n",
            "epoch: [8/20] -> loss: 1.305\n",
            "epoch: [9/20] -> loss: 1.126\n",
            "epoch: [10/20] -> loss: 1.048\n",
            "epoch: [11/20] -> loss: 1.020\n",
            "epoch: [12/20] -> loss: 1.008\n",
            "epoch: [13/20] -> loss: 1.008\n",
            "epoch: [14/20] -> loss: 1.008\n",
            "epoch: [15/20] -> loss: 1.008\n",
            "epoch: [16/20] -> loss: 1.008\n",
            "epoch: [17/20] -> loss: 1.008\n",
            "epoch: [18/20] -> loss: 1.008\n",
            "epoch: [19/20] -> loss: 1.008\n",
            "epoch: [20/20] -> loss: 1.008\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.008\n",
            "* Train accuracy: 56.00%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.178\n",
            "epoch: [2/20] -> loss: 1.126\n",
            "epoch: [3/20] -> loss: 1.094\n",
            "epoch: [4/20] -> loss: 1.068\n",
            "epoch: [5/20] -> loss: 1.046\n",
            "epoch: [6/20] -> loss: 1.026\n",
            "epoch: [7/20] -> loss: 1.010\n",
            "epoch: [8/20] -> loss: 0.993\n",
            "epoch: [9/20] -> loss: 0.979\n",
            "epoch: [10/20] -> loss: 0.965\n",
            "epoch: [11/20] -> loss: 0.953\n",
            "epoch: [12/20] -> loss: 0.942\n",
            "epoch: [13/20] -> loss: 0.932\n",
            "epoch: [14/20] -> loss: 0.921\n",
            "epoch: [15/20] -> loss: 0.913\n",
            "epoch: [16/20] -> loss: 0.904\n",
            "epoch: [17/20] -> loss: 0.896\n",
            "epoch: [18/20] -> loss: 0.889\n",
            "epoch: [19/20] -> loss: 0.881\n",
            "epoch: [20/20] -> loss: 0.875\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.875\n",
            "* Train accuracy: 75.00%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.960\n",
            "epoch: [2/20] -> loss: 0.852\n",
            "epoch: [3/20] -> loss: 0.822\n",
            "epoch: [4/20] -> loss: 0.801\n",
            "epoch: [5/20] -> loss: 0.782\n",
            "epoch: [6/20] -> loss: 0.765\n",
            "epoch: [7/20] -> loss: 0.749\n",
            "epoch: [8/20] -> loss: 0.736\n",
            "epoch: [9/20] -> loss: 0.724\n",
            "epoch: [10/20] -> loss: 0.712\n",
            "epoch: [11/20] -> loss: 0.701\n",
            "epoch: [12/20] -> loss: 0.691\n",
            "epoch: [13/20] -> loss: 0.683\n",
            "epoch: [14/20] -> loss: 0.675\n",
            "epoch: [15/20] -> loss: 0.667\n",
            "epoch: [16/20] -> loss: 0.660\n",
            "epoch: [17/20] -> loss: 0.653\n",
            "epoch: [18/20] -> loss: 0.647\n",
            "epoch: [19/20] -> loss: 0.641\n",
            "epoch: [20/20] -> loss: 0.636\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.636\n",
            "* Train accuracy: 75.91%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.248\n",
            "epoch: [2/30] -> loss: 1.150\n",
            "epoch: [3/30] -> loss: 1.141\n",
            "epoch: [4/30] -> loss: 1.132\n",
            "epoch: [5/30] -> loss: 1.136\n",
            "epoch: [6/30] -> loss: 1.135\n",
            "epoch: [7/30] -> loss: 1.138\n",
            "epoch: [8/30] -> loss: 1.134\n",
            "epoch: [9/30] -> loss: 1.133\n",
            "epoch: [10/30] -> loss: 1.142\n",
            "epoch: [11/30] -> loss: 1.137\n",
            "epoch: [12/30] -> loss: 1.127\n",
            "epoch: [13/30] -> loss: 1.124\n",
            "epoch: [14/30] -> loss: 1.135\n",
            "epoch: [15/30] -> loss: 1.134\n",
            "epoch: [16/30] -> loss: 1.128\n",
            "epoch: [17/30] -> loss: 1.138\n",
            "epoch: [18/30] -> loss: 1.127\n",
            "epoch: [19/30] -> loss: 1.129\n",
            "epoch: [20/30] -> loss: 1.140\n",
            "epoch: [21/30] -> loss: 1.128\n",
            "epoch: [22/30] -> loss: 1.130\n",
            "epoch: [23/30] -> loss: 1.131\n",
            "epoch: [24/30] -> loss: 1.140\n",
            "epoch: [25/30] -> loss: 1.138\n",
            "epoch: [26/30] -> loss: 1.128\n",
            "epoch: [27/30] -> loss: 1.128\n",
            "epoch: [28/30] -> loss: 1.140\n",
            "epoch: [29/30] -> loss: 1.137\n",
            "epoch: [30/30] -> loss: 1.135\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.135\n",
            "* Train accuracy: 63.86%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.838\n",
            "epoch: [2/30] -> loss: 0.752\n",
            "epoch: [3/30] -> loss: 0.751\n",
            "epoch: [4/30] -> loss: 0.747\n",
            "epoch: [5/30] -> loss: 0.746\n",
            "epoch: [6/30] -> loss: 0.755\n",
            "epoch: [7/30] -> loss: 0.748\n",
            "epoch: [8/30] -> loss: 0.744\n",
            "epoch: [9/30] -> loss: 0.751\n",
            "epoch: [10/30] -> loss: 0.749\n",
            "epoch: [11/30] -> loss: 0.744\n",
            "epoch: [12/30] -> loss: 0.749\n",
            "epoch: [13/30] -> loss: 0.742\n",
            "epoch: [14/30] -> loss: 0.747\n",
            "epoch: [15/30] -> loss: 0.746\n",
            "epoch: [16/30] -> loss: 0.750\n",
            "epoch: [17/30] -> loss: 0.750\n",
            "epoch: [18/30] -> loss: 0.748\n",
            "epoch: [19/30] -> loss: 0.745\n",
            "epoch: [20/30] -> loss: 0.744\n",
            "epoch: [21/30] -> loss: 0.748\n",
            "epoch: [22/30] -> loss: 0.747\n",
            "epoch: [23/30] -> loss: 0.747\n",
            "epoch: [24/30] -> loss: 0.742\n",
            "epoch: [25/30] -> loss: 0.744\n",
            "epoch: [26/30] -> loss: 0.750\n",
            "epoch: [27/30] -> loss: 0.751\n",
            "epoch: [28/30] -> loss: 0.747\n",
            "epoch: [29/30] -> loss: 0.749\n",
            "epoch: [30/30] -> loss: 0.746\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.746\n",
            "* Train accuracy: 77.73%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.620\n",
            "epoch: [2/30] -> loss: 0.513\n",
            "epoch: [3/30] -> loss: 0.492\n",
            "epoch: [4/30] -> loss: 0.487\n",
            "epoch: [5/30] -> loss: 0.477\n",
            "epoch: [6/30] -> loss: 0.475\n",
            "epoch: [7/30] -> loss: 0.471\n",
            "epoch: [8/30] -> loss: 0.468\n",
            "epoch: [9/30] -> loss: 0.463\n",
            "epoch: [10/30] -> loss: 0.463\n",
            "epoch: [11/30] -> loss: 0.461\n",
            "epoch: [12/30] -> loss: 0.464\n",
            "epoch: [13/30] -> loss: 0.459\n",
            "epoch: [14/30] -> loss: 0.459\n",
            "epoch: [15/30] -> loss: 0.456\n",
            "epoch: [16/30] -> loss: 0.461\n",
            "epoch: [17/30] -> loss: 0.457\n",
            "epoch: [18/30] -> loss: 0.457\n",
            "epoch: [19/30] -> loss: 0.460\n",
            "epoch: [20/30] -> loss: 0.456\n",
            "epoch: [21/30] -> loss: 0.454\n",
            "epoch: [22/30] -> loss: 0.455\n",
            "epoch: [23/30] -> loss: 0.454\n",
            "epoch: [24/30] -> loss: 0.453\n",
            "epoch: [25/30] -> loss: 0.456\n",
            "epoch: [26/30] -> loss: 0.454\n",
            "epoch: [27/30] -> loss: 0.455\n",
            "epoch: [28/30] -> loss: 0.454\n",
            "epoch: [29/30] -> loss: 0.451\n",
            "epoch: [30/30] -> loss: 0.454\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.454\n",
            "* Train accuracy: 85.91%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.283\n",
            "epoch: [2/30] -> loss: 1.068\n",
            "epoch: [3/30] -> loss: 1.064\n",
            "epoch: [4/30] -> loss: 1.064\n",
            "epoch: [5/30] -> loss: 1.065\n",
            "epoch: [6/30] -> loss: 1.063\n",
            "epoch: [7/30] -> loss: 1.064\n",
            "epoch: [8/30] -> loss: 1.066\n",
            "epoch: [9/30] -> loss: 1.065\n",
            "epoch: [10/30] -> loss: 1.067\n",
            "epoch: [11/30] -> loss: 1.063\n",
            "epoch: [12/30] -> loss: 1.063\n",
            "epoch: [13/30] -> loss: 1.064\n",
            "epoch: [14/30] -> loss: 1.064\n",
            "epoch: [15/30] -> loss: 1.067\n",
            "epoch: [16/30] -> loss: 1.062\n",
            "epoch: [17/30] -> loss: 1.063\n",
            "epoch: [18/30] -> loss: 1.065\n",
            "epoch: [19/30] -> loss: 1.062\n",
            "epoch: [20/30] -> loss: 1.067\n",
            "epoch: [21/30] -> loss: 1.065\n",
            "epoch: [22/30] -> loss: 1.064\n",
            "epoch: [23/30] -> loss: 1.064\n",
            "epoch: [24/30] -> loss: 1.059\n",
            "epoch: [25/30] -> loss: 1.066\n",
            "epoch: [26/30] -> loss: 1.067\n",
            "epoch: [27/30] -> loss: 1.064\n",
            "epoch: [28/30] -> loss: 1.066\n",
            "epoch: [29/30] -> loss: 1.065\n",
            "epoch: [30/30] -> loss: 1.067\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.067\n",
            "* Train accuracy: 61.51%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.890\n",
            "epoch: [2/30] -> loss: 0.759\n",
            "epoch: [3/30] -> loss: 0.737\n",
            "epoch: [4/30] -> loss: 0.732\n",
            "epoch: [5/30] -> loss: 0.732\n",
            "epoch: [6/30] -> loss: 0.732\n",
            "epoch: [7/30] -> loss: 0.734\n",
            "epoch: [8/30] -> loss: 0.730\n",
            "epoch: [9/30] -> loss: 0.731\n",
            "epoch: [10/30] -> loss: 0.731\n",
            "epoch: [11/30] -> loss: 0.730\n",
            "epoch: [12/30] -> loss: 0.731\n",
            "epoch: [13/30] -> loss: 0.731\n",
            "epoch: [14/30] -> loss: 0.731\n",
            "epoch: [15/30] -> loss: 0.729\n",
            "epoch: [16/30] -> loss: 0.730\n",
            "epoch: [17/30] -> loss: 0.727\n",
            "epoch: [18/30] -> loss: 0.732\n",
            "epoch: [19/30] -> loss: 0.730\n",
            "epoch: [20/30] -> loss: 0.732\n",
            "epoch: [21/30] -> loss: 0.730\n",
            "epoch: [22/30] -> loss: 0.730\n",
            "epoch: [23/30] -> loss: 0.727\n",
            "epoch: [24/30] -> loss: 0.731\n",
            "epoch: [25/30] -> loss: 0.730\n",
            "epoch: [26/30] -> loss: 0.729\n",
            "epoch: [27/30] -> loss: 0.729\n",
            "epoch: [28/30] -> loss: 0.730\n",
            "epoch: [29/30] -> loss: 0.728\n",
            "epoch: [30/30] -> loss: 0.729\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.729\n",
            "* Train accuracy: 77.30%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.653\n",
            "epoch: [2/30] -> loss: 0.538\n",
            "epoch: [3/30] -> loss: 0.511\n",
            "epoch: [4/30] -> loss: 0.495\n",
            "epoch: [5/30] -> loss: 0.487\n",
            "epoch: [6/30] -> loss: 0.480\n",
            "epoch: [7/30] -> loss: 0.474\n",
            "epoch: [8/30] -> loss: 0.470\n",
            "epoch: [9/30] -> loss: 0.467\n",
            "epoch: [10/30] -> loss: 0.465\n",
            "epoch: [11/30] -> loss: 0.463\n",
            "epoch: [12/30] -> loss: 0.460\n",
            "epoch: [13/30] -> loss: 0.460\n",
            "epoch: [14/30] -> loss: 0.457\n",
            "epoch: [15/30] -> loss: 0.457\n",
            "epoch: [16/30] -> loss: 0.455\n",
            "epoch: [17/30] -> loss: 0.454\n",
            "epoch: [18/30] -> loss: 0.454\n",
            "epoch: [19/30] -> loss: 0.451\n",
            "epoch: [20/30] -> loss: 0.452\n",
            "epoch: [21/30] -> loss: 0.451\n",
            "epoch: [22/30] -> loss: 0.451\n",
            "epoch: [23/30] -> loss: 0.452\n",
            "epoch: [24/30] -> loss: 0.449\n",
            "epoch: [25/30] -> loss: 0.449\n",
            "epoch: [26/30] -> loss: 0.450\n",
            "epoch: [27/30] -> loss: 0.448\n",
            "epoch: [28/30] -> loss: 0.447\n",
            "epoch: [29/30] -> loss: 0.447\n",
            "epoch: [30/30] -> loss: 0.447\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.447\n",
            "* Train accuracy: 85.48%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 2.140\n",
            "epoch: [2/30] -> loss: 1.029\n",
            "epoch: [3/30] -> loss: 1.019\n",
            "epoch: [4/30] -> loss: 1.019\n",
            "epoch: [5/30] -> loss: 1.019\n",
            "epoch: [6/30] -> loss: 1.018\n",
            "epoch: [7/30] -> loss: 1.019\n",
            "epoch: [8/30] -> loss: 1.019\n",
            "epoch: [9/30] -> loss: 1.019\n",
            "epoch: [10/30] -> loss: 1.019\n",
            "epoch: [11/30] -> loss: 1.019\n",
            "epoch: [12/30] -> loss: 1.020\n",
            "epoch: [13/30] -> loss: 1.019\n",
            "epoch: [14/30] -> loss: 1.019\n",
            "epoch: [15/30] -> loss: 1.019\n",
            "epoch: [16/30] -> loss: 1.018\n",
            "epoch: [17/30] -> loss: 1.018\n",
            "epoch: [18/30] -> loss: 1.020\n",
            "epoch: [19/30] -> loss: 1.019\n",
            "epoch: [20/30] -> loss: 1.019\n",
            "epoch: [21/30] -> loss: 1.019\n",
            "epoch: [22/30] -> loss: 1.019\n",
            "epoch: [23/30] -> loss: 1.019\n",
            "epoch: [24/30] -> loss: 1.019\n",
            "epoch: [25/30] -> loss: 1.019\n",
            "epoch: [26/30] -> loss: 1.019\n",
            "epoch: [27/30] -> loss: 1.018\n",
            "epoch: [28/30] -> loss: 1.018\n",
            "epoch: [29/30] -> loss: 1.019\n",
            "epoch: [30/30] -> loss: 1.019\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.019\n",
            "* Train accuracy: 61.30%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.056\n",
            "epoch: [2/30] -> loss: 0.915\n",
            "epoch: [3/30] -> loss: 0.847\n",
            "epoch: [4/30] -> loss: 0.808\n",
            "epoch: [5/30] -> loss: 0.782\n",
            "epoch: [6/30] -> loss: 0.765\n",
            "epoch: [7/30] -> loss: 0.752\n",
            "epoch: [8/30] -> loss: 0.743\n",
            "epoch: [9/30] -> loss: 0.736\n",
            "epoch: [10/30] -> loss: 0.731\n",
            "epoch: [11/30] -> loss: 0.728\n",
            "epoch: [12/30] -> loss: 0.725\n",
            "epoch: [13/30] -> loss: 0.724\n",
            "epoch: [14/30] -> loss: 0.723\n",
            "epoch: [15/30] -> loss: 0.723\n",
            "epoch: [16/30] -> loss: 0.720\n",
            "epoch: [17/30] -> loss: 0.721\n",
            "epoch: [18/30] -> loss: 0.720\n",
            "epoch: [19/30] -> loss: 0.720\n",
            "epoch: [20/30] -> loss: 0.720\n",
            "epoch: [21/30] -> loss: 0.721\n",
            "epoch: [22/30] -> loss: 0.721\n",
            "epoch: [23/30] -> loss: 0.720\n",
            "epoch: [24/30] -> loss: 0.720\n",
            "epoch: [25/30] -> loss: 0.720\n",
            "epoch: [26/30] -> loss: 0.720\n",
            "epoch: [27/30] -> loss: 0.719\n",
            "epoch: [28/30] -> loss: 0.720\n",
            "epoch: [29/30] -> loss: 0.720\n",
            "epoch: [30/30] -> loss: 0.721\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.721\n",
            "* Train accuracy: 79.49%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.796\n",
            "epoch: [2/30] -> loss: 0.682\n",
            "epoch: [3/30] -> loss: 0.622\n",
            "epoch: [4/30] -> loss: 0.587\n",
            "epoch: [5/30] -> loss: 0.565\n",
            "epoch: [6/30] -> loss: 0.550\n",
            "epoch: [7/30] -> loss: 0.538\n",
            "epoch: [8/30] -> loss: 0.528\n",
            "epoch: [9/30] -> loss: 0.521\n",
            "epoch: [10/30] -> loss: 0.514\n",
            "epoch: [11/30] -> loss: 0.509\n",
            "epoch: [12/30] -> loss: 0.505\n",
            "epoch: [13/30] -> loss: 0.501\n",
            "epoch: [14/30] -> loss: 0.497\n",
            "epoch: [15/30] -> loss: 0.495\n",
            "epoch: [16/30] -> loss: 0.492\n",
            "epoch: [17/30] -> loss: 0.489\n",
            "epoch: [18/30] -> loss: 0.487\n",
            "epoch: [19/30] -> loss: 0.485\n",
            "epoch: [20/30] -> loss: 0.483\n",
            "epoch: [21/30] -> loss: 0.480\n",
            "epoch: [22/30] -> loss: 0.480\n",
            "epoch: [23/30] -> loss: 0.477\n",
            "epoch: [24/30] -> loss: 0.476\n",
            "epoch: [25/30] -> loss: 0.475\n",
            "epoch: [26/30] -> loss: 0.473\n",
            "epoch: [27/30] -> loss: 0.471\n",
            "epoch: [28/30] -> loss: 0.470\n",
            "epoch: [29/30] -> loss: 0.469\n",
            "epoch: [30/30] -> loss: 0.468\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.468\n",
            "* Train accuracy: 83.38%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 2.849\n",
            "epoch: [2/30] -> loss: 1.384\n",
            "epoch: [3/30] -> loss: 1.017\n",
            "epoch: [4/30] -> loss: 1.013\n",
            "epoch: [5/30] -> loss: 1.013\n",
            "epoch: [6/30] -> loss: 1.013\n",
            "epoch: [7/30] -> loss: 1.013\n",
            "epoch: [8/30] -> loss: 1.013\n",
            "epoch: [9/30] -> loss: 1.013\n",
            "epoch: [10/30] -> loss: 1.013\n",
            "epoch: [11/30] -> loss: 1.013\n",
            "epoch: [12/30] -> loss: 1.013\n",
            "epoch: [13/30] -> loss: 1.013\n",
            "epoch: [14/30] -> loss: 1.013\n",
            "epoch: [15/30] -> loss: 1.013\n",
            "epoch: [16/30] -> loss: 1.013\n",
            "epoch: [17/30] -> loss: 1.013\n",
            "epoch: [18/30] -> loss: 1.013\n",
            "epoch: [19/30] -> loss: 1.013\n",
            "epoch: [20/30] -> loss: 1.013\n",
            "epoch: [21/30] -> loss: 1.013\n",
            "epoch: [22/30] -> loss: 1.013\n",
            "epoch: [23/30] -> loss: 1.013\n",
            "epoch: [24/30] -> loss: 1.013\n",
            "epoch: [25/30] -> loss: 1.013\n",
            "epoch: [26/30] -> loss: 1.013\n",
            "epoch: [27/30] -> loss: 1.013\n",
            "epoch: [28/30] -> loss: 1.013\n",
            "epoch: [29/30] -> loss: 1.013\n",
            "epoch: [30/30] -> loss: 1.013\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.013\n",
            "* Train accuracy: 63.50%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.118\n",
            "epoch: [2/30] -> loss: 1.003\n",
            "epoch: [3/30] -> loss: 0.935\n",
            "epoch: [4/30] -> loss: 0.889\n",
            "epoch: [5/30] -> loss: 0.857\n",
            "epoch: [6/30] -> loss: 0.832\n",
            "epoch: [7/30] -> loss: 0.813\n",
            "epoch: [8/30] -> loss: 0.798\n",
            "epoch: [9/30] -> loss: 0.785\n",
            "epoch: [10/30] -> loss: 0.775\n",
            "epoch: [11/30] -> loss: 0.766\n",
            "epoch: [12/30] -> loss: 0.759\n",
            "epoch: [13/30] -> loss: 0.753\n",
            "epoch: [14/30] -> loss: 0.747\n",
            "epoch: [15/30] -> loss: 0.743\n",
            "epoch: [16/30] -> loss: 0.740\n",
            "epoch: [17/30] -> loss: 0.736\n",
            "epoch: [18/30] -> loss: 0.733\n",
            "epoch: [19/30] -> loss: 0.731\n",
            "epoch: [20/30] -> loss: 0.729\n",
            "epoch: [21/30] -> loss: 0.727\n",
            "epoch: [22/30] -> loss: 0.726\n",
            "epoch: [23/30] -> loss: 0.725\n",
            "epoch: [24/30] -> loss: 0.724\n",
            "epoch: [25/30] -> loss: 0.723\n",
            "epoch: [26/30] -> loss: 0.722\n",
            "epoch: [27/30] -> loss: 0.722\n",
            "epoch: [28/30] -> loss: 0.722\n",
            "epoch: [29/30] -> loss: 0.721\n",
            "epoch: [30/30] -> loss: 0.721\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.721\n",
            "* Train accuracy: 79.36%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.845\n",
            "epoch: [2/30] -> loss: 0.745\n",
            "epoch: [3/30] -> loss: 0.688\n",
            "epoch: [4/30] -> loss: 0.650\n",
            "epoch: [5/30] -> loss: 0.623\n",
            "epoch: [6/30] -> loss: 0.602\n",
            "epoch: [7/30] -> loss: 0.587\n",
            "epoch: [8/30] -> loss: 0.574\n",
            "epoch: [9/30] -> loss: 0.563\n",
            "epoch: [10/30] -> loss: 0.555\n",
            "epoch: [11/30] -> loss: 0.547\n",
            "epoch: [12/30] -> loss: 0.541\n",
            "epoch: [13/30] -> loss: 0.536\n",
            "epoch: [14/30] -> loss: 0.530\n",
            "epoch: [15/30] -> loss: 0.526\n",
            "epoch: [16/30] -> loss: 0.522\n",
            "epoch: [17/30] -> loss: 0.518\n",
            "epoch: [18/30] -> loss: 0.515\n",
            "epoch: [19/30] -> loss: 0.512\n",
            "epoch: [20/30] -> loss: 0.509\n",
            "epoch: [21/30] -> loss: 0.508\n",
            "epoch: [22/30] -> loss: 0.505\n",
            "epoch: [23/30] -> loss: 0.503\n",
            "epoch: [24/30] -> loss: 0.501\n",
            "epoch: [25/30] -> loss: 0.499\n",
            "epoch: [26/30] -> loss: 0.497\n",
            "epoch: [27/30] -> loss: 0.496\n",
            "epoch: [28/30] -> loss: 0.494\n",
            "epoch: [29/30] -> loss: 0.492\n",
            "epoch: [30/30] -> loss: 0.491\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.491\n",
            "* Train accuracy: 82.51%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 3.694\n",
            "epoch: [2/30] -> loss: 3.282\n",
            "epoch: [3/30] -> loss: 2.896\n",
            "epoch: [4/30] -> loss: 2.530\n",
            "epoch: [5/30] -> loss: 2.180\n",
            "epoch: [6/30] -> loss: 1.852\n",
            "epoch: [7/30] -> loss: 1.550\n",
            "epoch: [8/30] -> loss: 1.291\n",
            "epoch: [9/30] -> loss: 1.115\n",
            "epoch: [10/30] -> loss: 1.044\n",
            "epoch: [11/30] -> loss: 1.017\n",
            "epoch: [12/30] -> loss: 1.008\n",
            "epoch: [13/30] -> loss: 1.008\n",
            "epoch: [14/30] -> loss: 1.008\n",
            "epoch: [15/30] -> loss: 1.008\n",
            "epoch: [16/30] -> loss: 1.008\n",
            "epoch: [17/30] -> loss: 1.008\n",
            "epoch: [18/30] -> loss: 1.008\n",
            "epoch: [19/30] -> loss: 1.008\n",
            "epoch: [20/30] -> loss: 1.008\n",
            "epoch: [21/30] -> loss: 1.008\n",
            "epoch: [22/30] -> loss: 1.008\n",
            "epoch: [23/30] -> loss: 1.008\n",
            "epoch: [24/30] -> loss: 1.008\n",
            "epoch: [25/30] -> loss: 1.008\n",
            "epoch: [26/30] -> loss: 1.008\n",
            "epoch: [27/30] -> loss: 1.008\n",
            "epoch: [28/30] -> loss: 1.008\n",
            "epoch: [29/30] -> loss: 1.008\n",
            "epoch: [30/30] -> loss: 1.008\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.008\n",
            "* Train accuracy: 50.16%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.263\n",
            "epoch: [2/30] -> loss: 1.130\n",
            "epoch: [3/30] -> loss: 1.087\n",
            "epoch: [4/30] -> loss: 1.059\n",
            "epoch: [5/30] -> loss: 1.037\n",
            "epoch: [6/30] -> loss: 1.017\n",
            "epoch: [7/30] -> loss: 0.999\n",
            "epoch: [8/30] -> loss: 0.984\n",
            "epoch: [9/30] -> loss: 0.970\n",
            "epoch: [10/30] -> loss: 0.958\n",
            "epoch: [11/30] -> loss: 0.946\n",
            "epoch: [12/30] -> loss: 0.936\n",
            "epoch: [13/30] -> loss: 0.926\n",
            "epoch: [14/30] -> loss: 0.917\n",
            "epoch: [15/30] -> loss: 0.908\n",
            "epoch: [16/30] -> loss: 0.900\n",
            "epoch: [17/30] -> loss: 0.892\n",
            "epoch: [18/30] -> loss: 0.885\n",
            "epoch: [19/30] -> loss: 0.879\n",
            "epoch: [20/30] -> loss: 0.873\n",
            "epoch: [21/30] -> loss: 0.866\n",
            "epoch: [22/30] -> loss: 0.861\n",
            "epoch: [23/30] -> loss: 0.855\n",
            "epoch: [24/30] -> loss: 0.850\n",
            "epoch: [25/30] -> loss: 0.846\n",
            "epoch: [26/30] -> loss: 0.841\n",
            "epoch: [27/30] -> loss: 0.837\n",
            "epoch: [28/30] -> loss: 0.832\n",
            "epoch: [29/30] -> loss: 0.829\n",
            "epoch: [30/30] -> loss: 0.824\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.824\n",
            "* Train accuracy: 77.20%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.925\n",
            "epoch: [2/30] -> loss: 0.863\n",
            "epoch: [3/30] -> loss: 0.831\n",
            "epoch: [4/30] -> loss: 0.806\n",
            "epoch: [5/30] -> loss: 0.785\n",
            "epoch: [6/30] -> loss: 0.767\n",
            "epoch: [7/30] -> loss: 0.750\n",
            "epoch: [8/30] -> loss: 0.736\n",
            "epoch: [9/30] -> loss: 0.723\n",
            "epoch: [10/30] -> loss: 0.712\n",
            "epoch: [11/30] -> loss: 0.700\n",
            "epoch: [12/30] -> loss: 0.691\n",
            "epoch: [13/30] -> loss: 0.681\n",
            "epoch: [14/30] -> loss: 0.673\n",
            "epoch: [15/30] -> loss: 0.665\n",
            "epoch: [16/30] -> loss: 0.658\n",
            "epoch: [17/30] -> loss: 0.652\n",
            "epoch: [18/30] -> loss: 0.645\n",
            "epoch: [19/30] -> loss: 0.639\n",
            "epoch: [20/30] -> loss: 0.633\n",
            "epoch: [21/30] -> loss: 0.629\n",
            "epoch: [22/30] -> loss: 0.623\n",
            "epoch: [23/30] -> loss: 0.618\n",
            "epoch: [24/30] -> loss: 0.614\n",
            "epoch: [25/30] -> loss: 0.610\n",
            "epoch: [26/30] -> loss: 0.606\n",
            "epoch: [27/30] -> loss: 0.602\n",
            "epoch: [28/30] -> loss: 0.598\n",
            "epoch: [29/30] -> loss: 0.595\n",
            "epoch: [30/30] -> loss: 0.592\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.592\n",
            "* Train accuracy: 78.24%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.335\n",
            "epoch: [2/10] -> loss: 1.127\n",
            "epoch: [3/10] -> loss: 1.114\n",
            "epoch: [4/10] -> loss: 1.117\n",
            "epoch: [5/10] -> loss: 1.108\n",
            "epoch: [6/10] -> loss: 1.099\n",
            "epoch: [7/10] -> loss: 1.110\n",
            "epoch: [8/10] -> loss: 1.111\n",
            "epoch: [9/10] -> loss: 1.115\n",
            "epoch: [10/10] -> loss: 1.112\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.112\n",
            "* Train accuracy: 61.82%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.886\n",
            "epoch: [2/10] -> loss: 0.766\n",
            "epoch: [3/10] -> loss: 0.749\n",
            "epoch: [4/10] -> loss: 0.740\n",
            "epoch: [5/10] -> loss: 0.742\n",
            "epoch: [6/10] -> loss: 0.738\n",
            "epoch: [7/10] -> loss: 0.737\n",
            "epoch: [8/10] -> loss: 0.742\n",
            "epoch: [9/10] -> loss: 0.742\n",
            "epoch: [10/10] -> loss: 0.738\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.738\n",
            "* Train accuracy: 76.14%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.657\n",
            "epoch: [2/10] -> loss: 0.543\n",
            "epoch: [3/10] -> loss: 0.513\n",
            "epoch: [4/10] -> loss: 0.501\n",
            "epoch: [5/10] -> loss: 0.491\n",
            "epoch: [6/10] -> loss: 0.482\n",
            "epoch: [7/10] -> loss: 0.479\n",
            "epoch: [8/10] -> loss: 0.474\n",
            "epoch: [9/10] -> loss: 0.468\n",
            "epoch: [10/10] -> loss: 0.466\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.466\n",
            "* Train accuracy: 83.54%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.498\n",
            "epoch: [2/10] -> loss: 1.064\n",
            "epoch: [3/10] -> loss: 1.058\n",
            "epoch: [4/10] -> loss: 1.060\n",
            "epoch: [5/10] -> loss: 1.057\n",
            "epoch: [6/10] -> loss: 1.059\n",
            "epoch: [7/10] -> loss: 1.057\n",
            "epoch: [8/10] -> loss: 1.056\n",
            "epoch: [9/10] -> loss: 1.060\n",
            "epoch: [10/10] -> loss: 1.059\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.059\n",
            "* Train accuracy: 61.60%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.958\n",
            "epoch: [2/10] -> loss: 0.813\n",
            "epoch: [3/10] -> loss: 0.766\n",
            "epoch: [4/10] -> loss: 0.743\n",
            "epoch: [5/10] -> loss: 0.737\n",
            "epoch: [6/10] -> loss: 0.734\n",
            "epoch: [7/10] -> loss: 0.731\n",
            "epoch: [8/10] -> loss: 0.731\n",
            "epoch: [9/10] -> loss: 0.729\n",
            "epoch: [10/10] -> loss: 0.729\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.729\n",
            "* Train accuracy: 79.72%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.712\n",
            "epoch: [2/10] -> loss: 0.583\n",
            "epoch: [3/10] -> loss: 0.542\n",
            "epoch: [4/10] -> loss: 0.520\n",
            "epoch: [5/10] -> loss: 0.509\n",
            "epoch: [6/10] -> loss: 0.500\n",
            "epoch: [7/10] -> loss: 0.494\n",
            "epoch: [8/10] -> loss: 0.489\n",
            "epoch: [9/10] -> loss: 0.483\n",
            "epoch: [10/10] -> loss: 0.482\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.482\n",
            "* Train accuracy: 83.26%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 2.880\n",
            "epoch: [2/10] -> loss: 1.406\n",
            "epoch: [3/10] -> loss: 1.030\n",
            "epoch: [4/10] -> loss: 1.023\n",
            "epoch: [5/10] -> loss: 1.023\n",
            "epoch: [6/10] -> loss: 1.023\n",
            "epoch: [7/10] -> loss: 1.024\n",
            "epoch: [8/10] -> loss: 1.023\n",
            "epoch: [9/10] -> loss: 1.023\n",
            "epoch: [10/10] -> loss: 1.023\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.023\n",
            "* Train accuracy: 55.18%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.149\n",
            "epoch: [2/10] -> loss: 1.011\n",
            "epoch: [3/10] -> loss: 0.941\n",
            "epoch: [4/10] -> loss: 0.893\n",
            "epoch: [5/10] -> loss: 0.862\n",
            "epoch: [6/10] -> loss: 0.835\n",
            "epoch: [7/10] -> loss: 0.818\n",
            "epoch: [8/10] -> loss: 0.801\n",
            "epoch: [9/10] -> loss: 0.789\n",
            "epoch: [10/10] -> loss: 0.778\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.778\n",
            "* Train accuracy: 79.10%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.874\n",
            "epoch: [2/10] -> loss: 0.764\n",
            "epoch: [3/10] -> loss: 0.702\n",
            "epoch: [4/10] -> loss: 0.660\n",
            "epoch: [5/10] -> loss: 0.629\n",
            "epoch: [6/10] -> loss: 0.608\n",
            "epoch: [7/10] -> loss: 0.593\n",
            "epoch: [8/10] -> loss: 0.578\n",
            "epoch: [9/10] -> loss: 0.570\n",
            "epoch: [10/10] -> loss: 0.559\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.559\n",
            "* Train accuracy: 79.86%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 3.345\n",
            "epoch: [2/10] -> loss: 2.475\n",
            "epoch: [3/10] -> loss: 1.670\n",
            "epoch: [4/10] -> loss: 1.135\n",
            "epoch: [5/10] -> loss: 1.022\n",
            "epoch: [6/10] -> loss: 1.019\n",
            "epoch: [7/10] -> loss: 1.018\n",
            "epoch: [8/10] -> loss: 1.018\n",
            "epoch: [9/10] -> loss: 1.019\n",
            "epoch: [10/10] -> loss: 1.019\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.019\n",
            "* Train accuracy: 47.22%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.158\n",
            "epoch: [2/10] -> loss: 1.065\n",
            "epoch: [3/10] -> loss: 1.017\n",
            "epoch: [4/10] -> loss: 0.976\n",
            "epoch: [5/10] -> loss: 0.945\n",
            "epoch: [6/10] -> loss: 0.922\n",
            "epoch: [7/10] -> loss: 0.900\n",
            "epoch: [8/10] -> loss: 0.881\n",
            "epoch: [9/10] -> loss: 0.867\n",
            "epoch: [10/10] -> loss: 0.854\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.854\n",
            "* Train accuracy: 76.37%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.865\n",
            "epoch: [2/10] -> loss: 0.796\n",
            "epoch: [3/10] -> loss: 0.752\n",
            "epoch: [4/10] -> loss: 0.718\n",
            "epoch: [5/10] -> loss: 0.692\n",
            "epoch: [6/10] -> loss: 0.671\n",
            "epoch: [7/10] -> loss: 0.652\n",
            "epoch: [8/10] -> loss: 0.637\n",
            "epoch: [9/10] -> loss: 0.624\n",
            "epoch: [10/10] -> loss: 0.613\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.613\n",
            "* Train accuracy: 77.54%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 3.776\n",
            "epoch: [2/10] -> loss: 3.579\n",
            "epoch: [3/10] -> loss: 3.368\n",
            "epoch: [4/10] -> loss: 3.170\n",
            "epoch: [5/10] -> loss: 2.979\n",
            "epoch: [6/10] -> loss: 2.793\n",
            "epoch: [7/10] -> loss: 2.608\n",
            "epoch: [8/10] -> loss: 2.432\n",
            "epoch: [9/10] -> loss: 2.257\n",
            "epoch: [10/10] -> loss: 2.086\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 2.086\n",
            "* Train accuracy: 65.49%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.211\n",
            "epoch: [2/10] -> loss: 1.151\n",
            "epoch: [3/10] -> loss: 1.121\n",
            "epoch: [4/10] -> loss: 1.104\n",
            "epoch: [5/10] -> loss: 1.088\n",
            "epoch: [6/10] -> loss: 1.076\n",
            "epoch: [7/10] -> loss: 1.064\n",
            "epoch: [8/10] -> loss: 1.052\n",
            "epoch: [9/10] -> loss: 1.040\n",
            "epoch: [10/10] -> loss: 1.031\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.031\n",
            "* Train accuracy: 67.69%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.985\n",
            "epoch: [2/10] -> loss: 0.918\n",
            "epoch: [3/10] -> loss: 0.884\n",
            "epoch: [4/10] -> loss: 0.863\n",
            "epoch: [5/10] -> loss: 0.849\n",
            "epoch: [6/10] -> loss: 0.837\n",
            "epoch: [7/10] -> loss: 0.824\n",
            "epoch: [8/10] -> loss: 0.812\n",
            "epoch: [9/10] -> loss: 0.803\n",
            "epoch: [10/10] -> loss: 0.792\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.792\n",
            "* Train accuracy: 67.10%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.332\n",
            "epoch: [2/20] -> loss: 1.113\n",
            "epoch: [3/20] -> loss: 1.104\n",
            "epoch: [4/20] -> loss: 1.110\n",
            "epoch: [5/20] -> loss: 1.103\n",
            "epoch: [6/20] -> loss: 1.111\n",
            "epoch: [7/20] -> loss: 1.122\n",
            "epoch: [8/20] -> loss: 1.119\n",
            "epoch: [9/20] -> loss: 1.107\n",
            "epoch: [10/20] -> loss: 1.107\n",
            "epoch: [11/20] -> loss: 1.108\n",
            "epoch: [12/20] -> loss: 1.103\n",
            "epoch: [13/20] -> loss: 1.109\n",
            "epoch: [14/20] -> loss: 1.121\n",
            "epoch: [15/20] -> loss: 1.112\n",
            "epoch: [16/20] -> loss: 1.117\n",
            "epoch: [17/20] -> loss: 1.104\n",
            "epoch: [18/20] -> loss: 1.121\n",
            "epoch: [19/20] -> loss: 1.111\n",
            "epoch: [20/20] -> loss: 1.114\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.114\n",
            "* Train accuracy: 63.04%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.893\n",
            "epoch: [2/20] -> loss: 0.765\n",
            "epoch: [3/20] -> loss: 0.740\n",
            "epoch: [4/20] -> loss: 0.737\n",
            "epoch: [5/20] -> loss: 0.739\n",
            "epoch: [6/20] -> loss: 0.738\n",
            "epoch: [7/20] -> loss: 0.735\n",
            "epoch: [8/20] -> loss: 0.737\n",
            "epoch: [9/20] -> loss: 0.737\n",
            "epoch: [10/20] -> loss: 0.736\n",
            "epoch: [11/20] -> loss: 0.736\n",
            "epoch: [12/20] -> loss: 0.735\n",
            "epoch: [13/20] -> loss: 0.736\n",
            "epoch: [14/20] -> loss: 0.738\n",
            "epoch: [15/20] -> loss: 0.738\n",
            "epoch: [16/20] -> loss: 0.741\n",
            "epoch: [17/20] -> loss: 0.737\n",
            "epoch: [18/20] -> loss: 0.736\n",
            "epoch: [19/20] -> loss: 0.737\n",
            "epoch: [20/20] -> loss: 0.739\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.739\n",
            "* Train accuracy: 76.32%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.664\n",
            "epoch: [2/20] -> loss: 0.542\n",
            "epoch: [3/20] -> loss: 0.513\n",
            "epoch: [4/20] -> loss: 0.496\n",
            "epoch: [5/20] -> loss: 0.490\n",
            "epoch: [6/20] -> loss: 0.481\n",
            "epoch: [7/20] -> loss: 0.478\n",
            "epoch: [8/20] -> loss: 0.472\n",
            "epoch: [9/20] -> loss: 0.471\n",
            "epoch: [10/20] -> loss: 0.469\n",
            "epoch: [11/20] -> loss: 0.466\n",
            "epoch: [12/20] -> loss: 0.461\n",
            "epoch: [13/20] -> loss: 0.465\n",
            "epoch: [14/20] -> loss: 0.459\n",
            "epoch: [15/20] -> loss: 0.461\n",
            "epoch: [16/20] -> loss: 0.458\n",
            "epoch: [17/20] -> loss: 0.457\n",
            "epoch: [18/20] -> loss: 0.458\n",
            "epoch: [19/20] -> loss: 0.455\n",
            "epoch: [20/20] -> loss: 0.454\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.454\n",
            "* Train accuracy: 84.08%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.486\n",
            "epoch: [2/20] -> loss: 1.066\n",
            "epoch: [3/20] -> loss: 1.059\n",
            "epoch: [4/20] -> loss: 1.056\n",
            "epoch: [5/20] -> loss: 1.060\n",
            "epoch: [6/20] -> loss: 1.062\n",
            "epoch: [7/20] -> loss: 1.058\n",
            "epoch: [8/20] -> loss: 1.059\n",
            "epoch: [9/20] -> loss: 1.057\n",
            "epoch: [10/20] -> loss: 1.060\n",
            "epoch: [11/20] -> loss: 1.055\n",
            "epoch: [12/20] -> loss: 1.060\n",
            "epoch: [13/20] -> loss: 1.058\n",
            "epoch: [14/20] -> loss: 1.058\n",
            "epoch: [15/20] -> loss: 1.057\n",
            "epoch: [16/20] -> loss: 1.059\n",
            "epoch: [17/20] -> loss: 1.060\n",
            "epoch: [18/20] -> loss: 1.058\n",
            "epoch: [19/20] -> loss: 1.059\n",
            "epoch: [20/20] -> loss: 1.061\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.061\n",
            "* Train accuracy: 60.60%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.961\n",
            "epoch: [2/20] -> loss: 0.818\n",
            "epoch: [3/20] -> loss: 0.764\n",
            "epoch: [4/20] -> loss: 0.745\n",
            "epoch: [5/20] -> loss: 0.737\n",
            "epoch: [6/20] -> loss: 0.731\n",
            "epoch: [7/20] -> loss: 0.729\n",
            "epoch: [8/20] -> loss: 0.729\n",
            "epoch: [9/20] -> loss: 0.729\n",
            "epoch: [10/20] -> loss: 0.729\n",
            "epoch: [11/20] -> loss: 0.728\n",
            "epoch: [12/20] -> loss: 0.731\n",
            "epoch: [13/20] -> loss: 0.730\n",
            "epoch: [14/20] -> loss: 0.729\n",
            "epoch: [15/20] -> loss: 0.729\n",
            "epoch: [16/20] -> loss: 0.729\n",
            "epoch: [17/20] -> loss: 0.726\n",
            "epoch: [18/20] -> loss: 0.729\n",
            "epoch: [19/20] -> loss: 0.729\n",
            "epoch: [20/20] -> loss: 0.727\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.727\n",
            "* Train accuracy: 76.62%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.698\n",
            "epoch: [2/20] -> loss: 0.583\n",
            "epoch: [3/20] -> loss: 0.544\n",
            "epoch: [4/20] -> loss: 0.524\n",
            "epoch: [5/20] -> loss: 0.509\n",
            "epoch: [6/20] -> loss: 0.502\n",
            "epoch: [7/20] -> loss: 0.494\n",
            "epoch: [8/20] -> loss: 0.488\n",
            "epoch: [9/20] -> loss: 0.483\n",
            "epoch: [10/20] -> loss: 0.481\n",
            "epoch: [11/20] -> loss: 0.476\n",
            "epoch: [12/20] -> loss: 0.478\n",
            "epoch: [13/20] -> loss: 0.471\n",
            "epoch: [14/20] -> loss: 0.470\n",
            "epoch: [15/20] -> loss: 0.470\n",
            "epoch: [16/20] -> loss: 0.470\n",
            "epoch: [17/20] -> loss: 0.465\n",
            "epoch: [18/20] -> loss: 0.463\n",
            "epoch: [19/20] -> loss: 0.462\n",
            "epoch: [20/20] -> loss: 0.462\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.462\n",
            "* Train accuracy: 84.23%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 2.896\n",
            "epoch: [2/20] -> loss: 1.401\n",
            "epoch: [3/20] -> loss: 1.031\n",
            "epoch: [4/20] -> loss: 1.024\n",
            "epoch: [5/20] -> loss: 1.023\n",
            "epoch: [6/20] -> loss: 1.023\n",
            "epoch: [7/20] -> loss: 1.023\n",
            "epoch: [8/20] -> loss: 1.024\n",
            "epoch: [9/20] -> loss: 1.023\n",
            "epoch: [10/20] -> loss: 1.023\n",
            "epoch: [11/20] -> loss: 1.023\n",
            "epoch: [12/20] -> loss: 1.024\n",
            "epoch: [13/20] -> loss: 1.023\n",
            "epoch: [14/20] -> loss: 1.023\n",
            "epoch: [15/20] -> loss: 1.023\n",
            "epoch: [16/20] -> loss: 1.023\n",
            "epoch: [17/20] -> loss: 1.023\n",
            "epoch: [18/20] -> loss: 1.023\n",
            "epoch: [19/20] -> loss: 1.023\n",
            "epoch: [20/20] -> loss: 1.023\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.023\n",
            "* Train accuracy: 61.97%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.101\n",
            "epoch: [2/20] -> loss: 0.999\n",
            "epoch: [3/20] -> loss: 0.935\n",
            "epoch: [4/20] -> loss: 0.893\n",
            "epoch: [5/20] -> loss: 0.861\n",
            "epoch: [6/20] -> loss: 0.838\n",
            "epoch: [7/20] -> loss: 0.819\n",
            "epoch: [8/20] -> loss: 0.803\n",
            "epoch: [9/20] -> loss: 0.790\n",
            "epoch: [10/20] -> loss: 0.780\n",
            "epoch: [11/20] -> loss: 0.771\n",
            "epoch: [12/20] -> loss: 0.763\n",
            "epoch: [13/20] -> loss: 0.757\n",
            "epoch: [14/20] -> loss: 0.752\n",
            "epoch: [15/20] -> loss: 0.748\n",
            "epoch: [16/20] -> loss: 0.742\n",
            "epoch: [17/20] -> loss: 0.741\n",
            "epoch: [18/20] -> loss: 0.737\n",
            "epoch: [19/20] -> loss: 0.735\n",
            "epoch: [20/20] -> loss: 0.734\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.734\n",
            "* Train accuracy: 79.49%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.862\n",
            "epoch: [2/20] -> loss: 0.749\n",
            "epoch: [3/20] -> loss: 0.691\n",
            "epoch: [4/20] -> loss: 0.651\n",
            "epoch: [5/20] -> loss: 0.624\n",
            "epoch: [6/20] -> loss: 0.602\n",
            "epoch: [7/20] -> loss: 0.586\n",
            "epoch: [8/20] -> loss: 0.577\n",
            "epoch: [9/20] -> loss: 0.565\n",
            "epoch: [10/20] -> loss: 0.555\n",
            "epoch: [11/20] -> loss: 0.549\n",
            "epoch: [12/20] -> loss: 0.545\n",
            "epoch: [13/20] -> loss: 0.538\n",
            "epoch: [14/20] -> loss: 0.532\n",
            "epoch: [15/20] -> loss: 0.530\n",
            "epoch: [16/20] -> loss: 0.523\n",
            "epoch: [17/20] -> loss: 0.521\n",
            "epoch: [18/20] -> loss: 0.520\n",
            "epoch: [19/20] -> loss: 0.516\n",
            "epoch: [20/20] -> loss: 0.511\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.511\n",
            "* Train accuracy: 81.71%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 3.324\n",
            "epoch: [2/20] -> loss: 2.453\n",
            "epoch: [3/20] -> loss: 1.647\n",
            "epoch: [4/20] -> loss: 1.129\n",
            "epoch: [5/20] -> loss: 1.025\n",
            "epoch: [6/20] -> loss: 1.019\n",
            "epoch: [7/20] -> loss: 1.019\n",
            "epoch: [8/20] -> loss: 1.019\n",
            "epoch: [9/20] -> loss: 1.019\n",
            "epoch: [10/20] -> loss: 1.019\n",
            "epoch: [11/20] -> loss: 1.019\n",
            "epoch: [12/20] -> loss: 1.019\n",
            "epoch: [13/20] -> loss: 1.019\n",
            "epoch: [14/20] -> loss: 1.019\n",
            "epoch: [15/20] -> loss: 1.019\n",
            "epoch: [16/20] -> loss: 1.019\n",
            "epoch: [17/20] -> loss: 1.019\n",
            "epoch: [18/20] -> loss: 1.019\n",
            "epoch: [19/20] -> loss: 1.019\n",
            "epoch: [20/20] -> loss: 1.019\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.019\n",
            "* Train accuracy: 59.50%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.144\n",
            "epoch: [2/20] -> loss: 1.061\n",
            "epoch: [3/20] -> loss: 1.011\n",
            "epoch: [4/20] -> loss: 0.974\n",
            "epoch: [5/20] -> loss: 0.945\n",
            "epoch: [6/20] -> loss: 0.921\n",
            "epoch: [7/20] -> loss: 0.899\n",
            "epoch: [8/20] -> loss: 0.882\n",
            "epoch: [9/20] -> loss: 0.868\n",
            "epoch: [10/20] -> loss: 0.854\n",
            "epoch: [11/20] -> loss: 0.843\n",
            "epoch: [12/20] -> loss: 0.831\n",
            "epoch: [13/20] -> loss: 0.823\n",
            "epoch: [14/20] -> loss: 0.815\n",
            "epoch: [15/20] -> loss: 0.807\n",
            "epoch: [16/20] -> loss: 0.801\n",
            "epoch: [17/20] -> loss: 0.793\n",
            "epoch: [18/20] -> loss: 0.786\n",
            "epoch: [19/20] -> loss: 0.783\n",
            "epoch: [20/20] -> loss: 0.778\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.778\n",
            "* Train accuracy: 78.46%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.925\n",
            "epoch: [2/20] -> loss: 0.842\n",
            "epoch: [3/20] -> loss: 0.791\n",
            "epoch: [4/20] -> loss: 0.752\n",
            "epoch: [5/20] -> loss: 0.721\n",
            "epoch: [6/20] -> loss: 0.695\n",
            "epoch: [7/20] -> loss: 0.673\n",
            "epoch: [8/20] -> loss: 0.658\n",
            "epoch: [9/20] -> loss: 0.642\n",
            "epoch: [10/20] -> loss: 0.632\n",
            "epoch: [11/20] -> loss: 0.618\n",
            "epoch: [12/20] -> loss: 0.609\n",
            "epoch: [13/20] -> loss: 0.600\n",
            "epoch: [14/20] -> loss: 0.593\n",
            "epoch: [15/20] -> loss: 0.585\n",
            "epoch: [16/20] -> loss: 0.579\n",
            "epoch: [17/20] -> loss: 0.574\n",
            "epoch: [18/20] -> loss: 0.570\n",
            "epoch: [19/20] -> loss: 0.563\n",
            "epoch: [20/20] -> loss: 0.561\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.561\n",
            "* Train accuracy: 79.53%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 3.780\n",
            "epoch: [2/20] -> loss: 3.579\n",
            "epoch: [3/20] -> loss: 3.363\n",
            "epoch: [4/20] -> loss: 3.172\n",
            "epoch: [5/20] -> loss: 2.984\n",
            "epoch: [6/20] -> loss: 2.800\n",
            "epoch: [7/20] -> loss: 2.619\n",
            "epoch: [8/20] -> loss: 2.442\n",
            "epoch: [9/20] -> loss: 2.271\n",
            "epoch: [10/20] -> loss: 2.101\n",
            "epoch: [11/20] -> loss: 1.937\n",
            "epoch: [12/20] -> loss: 1.777\n",
            "epoch: [13/20] -> loss: 1.628\n",
            "epoch: [14/20] -> loss: 1.484\n",
            "epoch: [15/20] -> loss: 1.355\n",
            "epoch: [16/20] -> loss: 1.244\n",
            "epoch: [17/20] -> loss: 1.153\n",
            "epoch: [18/20] -> loss: 1.093\n",
            "epoch: [19/20] -> loss: 1.059\n",
            "epoch: [20/20] -> loss: 1.043\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.043\n",
            "* Train accuracy: 61.29%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.290\n",
            "epoch: [2/20] -> loss: 1.218\n",
            "epoch: [3/20] -> loss: 1.170\n",
            "epoch: [4/20] -> loss: 1.145\n",
            "epoch: [5/20] -> loss: 1.126\n",
            "epoch: [6/20] -> loss: 1.110\n",
            "epoch: [7/20] -> loss: 1.093\n",
            "epoch: [8/20] -> loss: 1.077\n",
            "epoch: [9/20] -> loss: 1.066\n",
            "epoch: [10/20] -> loss: 1.055\n",
            "epoch: [11/20] -> loss: 1.043\n",
            "epoch: [12/20] -> loss: 1.033\n",
            "epoch: [13/20] -> loss: 1.027\n",
            "epoch: [14/20] -> loss: 1.018\n",
            "epoch: [15/20] -> loss: 1.008\n",
            "epoch: [16/20] -> loss: 1.001\n",
            "epoch: [17/20] -> loss: 0.992\n",
            "epoch: [18/20] -> loss: 0.984\n",
            "epoch: [19/20] -> loss: 0.977\n",
            "epoch: [20/20] -> loss: 0.971\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.971\n",
            "* Train accuracy: 70.63%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.988\n",
            "epoch: [2/20] -> loss: 0.914\n",
            "epoch: [3/20] -> loss: 0.857\n",
            "epoch: [4/20] -> loss: 0.838\n",
            "epoch: [5/20] -> loss: 0.823\n",
            "epoch: [6/20] -> loss: 0.812\n",
            "epoch: [7/20] -> loss: 0.801\n",
            "epoch: [8/20] -> loss: 0.789\n",
            "epoch: [9/20] -> loss: 0.781\n",
            "epoch: [10/20] -> loss: 0.772\n",
            "epoch: [11/20] -> loss: 0.764\n",
            "epoch: [12/20] -> loss: 0.756\n",
            "epoch: [13/20] -> loss: 0.747\n",
            "epoch: [14/20] -> loss: 0.740\n",
            "epoch: [15/20] -> loss: 0.733\n",
            "epoch: [16/20] -> loss: 0.726\n",
            "epoch: [17/20] -> loss: 0.720\n",
            "epoch: [18/20] -> loss: 0.715\n",
            "epoch: [19/20] -> loss: 0.708\n",
            "epoch: [20/20] -> loss: 0.702\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.702\n",
            "* Train accuracy: 72.26%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.328\n",
            "epoch: [2/30] -> loss: 1.127\n",
            "epoch: [3/30] -> loss: 1.109\n",
            "epoch: [4/30] -> loss: 1.113\n",
            "epoch: [5/30] -> loss: 1.109\n",
            "epoch: [6/30] -> loss: 1.113\n",
            "epoch: [7/30] -> loss: 1.113\n",
            "epoch: [8/30] -> loss: 1.109\n",
            "epoch: [9/30] -> loss: 1.118\n",
            "epoch: [10/30] -> loss: 1.105\n",
            "epoch: [11/30] -> loss: 1.116\n",
            "epoch: [12/30] -> loss: 1.118\n",
            "epoch: [13/30] -> loss: 1.109\n",
            "epoch: [14/30] -> loss: 1.121\n",
            "epoch: [15/30] -> loss: 1.106\n",
            "epoch: [16/30] -> loss: 1.108\n",
            "epoch: [17/30] -> loss: 1.115\n",
            "epoch: [18/30] -> loss: 1.112\n",
            "epoch: [19/30] -> loss: 1.116\n",
            "epoch: [20/30] -> loss: 1.114\n",
            "epoch: [21/30] -> loss: 1.112\n",
            "epoch: [22/30] -> loss: 1.116\n",
            "epoch: [23/30] -> loss: 1.111\n",
            "epoch: [24/30] -> loss: 1.112\n",
            "epoch: [25/30] -> loss: 1.107\n",
            "epoch: [26/30] -> loss: 1.116\n",
            "epoch: [27/30] -> loss: 1.110\n",
            "epoch: [28/30] -> loss: 1.110\n",
            "epoch: [29/30] -> loss: 1.105\n",
            "epoch: [30/30] -> loss: 1.108\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.108\n",
            "* Train accuracy: 59.84%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.890\n",
            "epoch: [2/30] -> loss: 0.763\n",
            "epoch: [3/30] -> loss: 0.747\n",
            "epoch: [4/30] -> loss: 0.741\n",
            "epoch: [5/30] -> loss: 0.739\n",
            "epoch: [6/30] -> loss: 0.742\n",
            "epoch: [7/30] -> loss: 0.739\n",
            "epoch: [8/30] -> loss: 0.744\n",
            "epoch: [9/30] -> loss: 0.740\n",
            "epoch: [10/30] -> loss: 0.736\n",
            "epoch: [11/30] -> loss: 0.741\n",
            "epoch: [12/30] -> loss: 0.735\n",
            "epoch: [13/30] -> loss: 0.734\n",
            "epoch: [14/30] -> loss: 0.741\n",
            "epoch: [15/30] -> loss: 0.734\n",
            "epoch: [16/30] -> loss: 0.737\n",
            "epoch: [17/30] -> loss: 0.738\n",
            "epoch: [18/30] -> loss: 0.736\n",
            "epoch: [19/30] -> loss: 0.737\n",
            "epoch: [20/30] -> loss: 0.733\n",
            "epoch: [21/30] -> loss: 0.738\n",
            "epoch: [22/30] -> loss: 0.742\n",
            "epoch: [23/30] -> loss: 0.737\n",
            "epoch: [24/30] -> loss: 0.734\n",
            "epoch: [25/30] -> loss: 0.735\n",
            "epoch: [26/30] -> loss: 0.740\n",
            "epoch: [27/30] -> loss: 0.738\n",
            "epoch: [28/30] -> loss: 0.739\n",
            "epoch: [29/30] -> loss: 0.736\n",
            "epoch: [30/30] -> loss: 0.734\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.734\n",
            "* Train accuracy: 74.61%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.655\n",
            "epoch: [2/30] -> loss: 0.544\n",
            "epoch: [3/30] -> loss: 0.513\n",
            "epoch: [4/30] -> loss: 0.497\n",
            "epoch: [5/30] -> loss: 0.488\n",
            "epoch: [6/30] -> loss: 0.482\n",
            "epoch: [7/30] -> loss: 0.479\n",
            "epoch: [8/30] -> loss: 0.473\n",
            "epoch: [9/30] -> loss: 0.471\n",
            "epoch: [10/30] -> loss: 0.467\n",
            "epoch: [11/30] -> loss: 0.462\n",
            "epoch: [12/30] -> loss: 0.465\n",
            "epoch: [13/30] -> loss: 0.461\n",
            "epoch: [14/30] -> loss: 0.458\n",
            "epoch: [15/30] -> loss: 0.460\n",
            "epoch: [16/30] -> loss: 0.458\n",
            "epoch: [17/30] -> loss: 0.458\n",
            "epoch: [18/30] -> loss: 0.456\n",
            "epoch: [19/30] -> loss: 0.455\n",
            "epoch: [20/30] -> loss: 0.455\n",
            "epoch: [21/30] -> loss: 0.455\n",
            "epoch: [22/30] -> loss: 0.454\n",
            "epoch: [23/30] -> loss: 0.453\n",
            "epoch: [24/30] -> loss: 0.453\n",
            "epoch: [25/30] -> loss: 0.454\n",
            "epoch: [26/30] -> loss: 0.451\n",
            "epoch: [27/30] -> loss: 0.452\n",
            "epoch: [28/30] -> loss: 0.451\n",
            "epoch: [29/30] -> loss: 0.450\n",
            "epoch: [30/30] -> loss: 0.448\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.448\n",
            "* Train accuracy: 85.58%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.483\n",
            "epoch: [2/30] -> loss: 1.064\n",
            "epoch: [3/30] -> loss: 1.058\n",
            "epoch: [4/30] -> loss: 1.063\n",
            "epoch: [5/30] -> loss: 1.058\n",
            "epoch: [6/30] -> loss: 1.057\n",
            "epoch: [7/30] -> loss: 1.062\n",
            "epoch: [8/30] -> loss: 1.058\n",
            "epoch: [9/30] -> loss: 1.057\n",
            "epoch: [10/30] -> loss: 1.058\n",
            "epoch: [11/30] -> loss: 1.059\n",
            "epoch: [12/30] -> loss: 1.059\n",
            "epoch: [13/30] -> loss: 1.059\n",
            "epoch: [14/30] -> loss: 1.060\n",
            "epoch: [15/30] -> loss: 1.059\n",
            "epoch: [16/30] -> loss: 1.058\n",
            "epoch: [17/30] -> loss: 1.056\n",
            "epoch: [18/30] -> loss: 1.057\n",
            "epoch: [19/30] -> loss: 1.057\n",
            "epoch: [20/30] -> loss: 1.059\n",
            "epoch: [21/30] -> loss: 1.058\n",
            "epoch: [22/30] -> loss: 1.059\n",
            "epoch: [23/30] -> loss: 1.061\n",
            "epoch: [24/30] -> loss: 1.057\n",
            "epoch: [25/30] -> loss: 1.061\n",
            "epoch: [26/30] -> loss: 1.062\n",
            "epoch: [27/30] -> loss: 1.057\n",
            "epoch: [28/30] -> loss: 1.060\n",
            "epoch: [29/30] -> loss: 1.059\n",
            "epoch: [30/30] -> loss: 1.059\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.059\n",
            "* Train accuracy: 61.76%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.962\n",
            "epoch: [2/30] -> loss: 0.816\n",
            "epoch: [3/30] -> loss: 0.765\n",
            "epoch: [4/30] -> loss: 0.743\n",
            "epoch: [5/30] -> loss: 0.736\n",
            "epoch: [6/30] -> loss: 0.732\n",
            "epoch: [7/30] -> loss: 0.730\n",
            "epoch: [8/30] -> loss: 0.728\n",
            "epoch: [9/30] -> loss: 0.731\n",
            "epoch: [10/30] -> loss: 0.729\n",
            "epoch: [11/30] -> loss: 0.729\n",
            "epoch: [12/30] -> loss: 0.728\n",
            "epoch: [13/30] -> loss: 0.728\n",
            "epoch: [14/30] -> loss: 0.727\n",
            "epoch: [15/30] -> loss: 0.727\n",
            "epoch: [16/30] -> loss: 0.727\n",
            "epoch: [17/30] -> loss: 0.727\n",
            "epoch: [18/30] -> loss: 0.727\n",
            "epoch: [19/30] -> loss: 0.728\n",
            "epoch: [20/30] -> loss: 0.727\n",
            "epoch: [21/30] -> loss: 0.727\n",
            "epoch: [22/30] -> loss: 0.729\n",
            "epoch: [23/30] -> loss: 0.727\n",
            "epoch: [24/30] -> loss: 0.728\n",
            "epoch: [25/30] -> loss: 0.727\n",
            "epoch: [26/30] -> loss: 0.728\n",
            "epoch: [27/30] -> loss: 0.728\n",
            "epoch: [28/30] -> loss: 0.730\n",
            "epoch: [29/30] -> loss: 0.726\n",
            "epoch: [30/30] -> loss: 0.728\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.728\n",
            "* Train accuracy: 78.94%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.718\n",
            "epoch: [2/30] -> loss: 0.591\n",
            "epoch: [3/30] -> loss: 0.548\n",
            "epoch: [4/30] -> loss: 0.525\n",
            "epoch: [5/30] -> loss: 0.514\n",
            "epoch: [6/30] -> loss: 0.503\n",
            "epoch: [7/30] -> loss: 0.495\n",
            "epoch: [8/30] -> loss: 0.489\n",
            "epoch: [9/30] -> loss: 0.484\n",
            "epoch: [10/30] -> loss: 0.481\n",
            "epoch: [11/30] -> loss: 0.477\n",
            "epoch: [12/30] -> loss: 0.474\n",
            "epoch: [13/30] -> loss: 0.473\n",
            "epoch: [14/30] -> loss: 0.470\n",
            "epoch: [15/30] -> loss: 0.468\n",
            "epoch: [16/30] -> loss: 0.467\n",
            "epoch: [17/30] -> loss: 0.466\n",
            "epoch: [18/30] -> loss: 0.463\n",
            "epoch: [19/30] -> loss: 0.464\n",
            "epoch: [20/30] -> loss: 0.465\n",
            "epoch: [21/30] -> loss: 0.460\n",
            "epoch: [22/30] -> loss: 0.461\n",
            "epoch: [23/30] -> loss: 0.461\n",
            "epoch: [24/30] -> loss: 0.459\n",
            "epoch: [25/30] -> loss: 0.457\n",
            "epoch: [26/30] -> loss: 0.456\n",
            "epoch: [27/30] -> loss: 0.455\n",
            "epoch: [28/30] -> loss: 0.456\n",
            "epoch: [29/30] -> loss: 0.451\n",
            "epoch: [30/30] -> loss: 0.455\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.455\n",
            "* Train accuracy: 84.07%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 2.856\n",
            "epoch: [2/30] -> loss: 1.388\n",
            "epoch: [3/30] -> loss: 1.029\n",
            "epoch: [4/30] -> loss: 1.024\n",
            "epoch: [5/30] -> loss: 1.023\n",
            "epoch: [6/30] -> loss: 1.023\n",
            "epoch: [7/30] -> loss: 1.023\n",
            "epoch: [8/30] -> loss: 1.023\n",
            "epoch: [9/30] -> loss: 1.024\n",
            "epoch: [10/30] -> loss: 1.023\n",
            "epoch: [11/30] -> loss: 1.023\n",
            "epoch: [12/30] -> loss: 1.023\n",
            "epoch: [13/30] -> loss: 1.023\n",
            "epoch: [14/30] -> loss: 1.023\n",
            "epoch: [15/30] -> loss: 1.023\n",
            "epoch: [16/30] -> loss: 1.023\n",
            "epoch: [17/30] -> loss: 1.023\n",
            "epoch: [18/30] -> loss: 1.023\n",
            "epoch: [19/30] -> loss: 1.023\n",
            "epoch: [20/30] -> loss: 1.023\n",
            "epoch: [21/30] -> loss: 1.023\n",
            "epoch: [22/30] -> loss: 1.023\n",
            "epoch: [23/30] -> loss: 1.023\n",
            "epoch: [24/30] -> loss: 1.023\n",
            "epoch: [25/30] -> loss: 1.023\n",
            "epoch: [26/30] -> loss: 1.023\n",
            "epoch: [27/30] -> loss: 1.023\n",
            "epoch: [28/30] -> loss: 1.023\n",
            "epoch: [29/30] -> loss: 1.023\n",
            "epoch: [30/30] -> loss: 1.023\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.023\n",
            "* Train accuracy: 59.48%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.086\n",
            "epoch: [2/30] -> loss: 0.988\n",
            "epoch: [3/30] -> loss: 0.930\n",
            "epoch: [4/30] -> loss: 0.892\n",
            "epoch: [5/30] -> loss: 0.861\n",
            "epoch: [6/30] -> loss: 0.837\n",
            "epoch: [7/30] -> loss: 0.821\n",
            "epoch: [8/30] -> loss: 0.804\n",
            "epoch: [9/30] -> loss: 0.792\n",
            "epoch: [10/30] -> loss: 0.781\n",
            "epoch: [11/30] -> loss: 0.773\n",
            "epoch: [12/30] -> loss: 0.765\n",
            "epoch: [13/30] -> loss: 0.760\n",
            "epoch: [14/30] -> loss: 0.753\n",
            "epoch: [15/30] -> loss: 0.747\n",
            "epoch: [16/30] -> loss: 0.743\n",
            "epoch: [17/30] -> loss: 0.740\n",
            "epoch: [18/30] -> loss: 0.737\n",
            "epoch: [19/30] -> loss: 0.736\n",
            "epoch: [20/30] -> loss: 0.734\n",
            "epoch: [21/30] -> loss: 0.734\n",
            "epoch: [22/30] -> loss: 0.731\n",
            "epoch: [23/30] -> loss: 0.731\n",
            "epoch: [24/30] -> loss: 0.729\n",
            "epoch: [25/30] -> loss: 0.728\n",
            "epoch: [26/30] -> loss: 0.727\n",
            "epoch: [27/30] -> loss: 0.726\n",
            "epoch: [28/30] -> loss: 0.726\n",
            "epoch: [29/30] -> loss: 0.725\n",
            "epoch: [30/30] -> loss: 0.725\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.725\n",
            "* Train accuracy: 79.37%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.853\n",
            "epoch: [2/30] -> loss: 0.751\n",
            "epoch: [3/30] -> loss: 0.689\n",
            "epoch: [4/30] -> loss: 0.653\n",
            "epoch: [5/30] -> loss: 0.625\n",
            "epoch: [6/30] -> loss: 0.606\n",
            "epoch: [7/30] -> loss: 0.591\n",
            "epoch: [8/30] -> loss: 0.580\n",
            "epoch: [9/30] -> loss: 0.567\n",
            "epoch: [10/30] -> loss: 0.559\n",
            "epoch: [11/30] -> loss: 0.551\n",
            "epoch: [12/30] -> loss: 0.544\n",
            "epoch: [13/30] -> loss: 0.539\n",
            "epoch: [14/30] -> loss: 0.536\n",
            "epoch: [15/30] -> loss: 0.531\n",
            "epoch: [16/30] -> loss: 0.527\n",
            "epoch: [17/30] -> loss: 0.524\n",
            "epoch: [18/30] -> loss: 0.520\n",
            "epoch: [19/30] -> loss: 0.517\n",
            "epoch: [20/30] -> loss: 0.514\n",
            "epoch: [21/30] -> loss: 0.511\n",
            "epoch: [22/30] -> loss: 0.508\n",
            "epoch: [23/30] -> loss: 0.506\n",
            "epoch: [24/30] -> loss: 0.505\n",
            "epoch: [25/30] -> loss: 0.502\n",
            "epoch: [26/30] -> loss: 0.501\n",
            "epoch: [27/30] -> loss: 0.497\n",
            "epoch: [28/30] -> loss: 0.499\n",
            "epoch: [29/30] -> loss: 0.495\n",
            "epoch: [30/30] -> loss: 0.495\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.495\n",
            "* Train accuracy: 82.34%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 3.278\n",
            "epoch: [2/30] -> loss: 2.414\n",
            "epoch: [3/30] -> loss: 1.613\n",
            "epoch: [4/30] -> loss: 1.115\n",
            "epoch: [5/30] -> loss: 1.022\n",
            "epoch: [6/30] -> loss: 1.019\n",
            "epoch: [7/30] -> loss: 1.019\n",
            "epoch: [8/30] -> loss: 1.019\n",
            "epoch: [9/30] -> loss: 1.019\n",
            "epoch: [10/30] -> loss: 1.019\n",
            "epoch: [11/30] -> loss: 1.019\n",
            "epoch: [12/30] -> loss: 1.019\n",
            "epoch: [13/30] -> loss: 1.019\n",
            "epoch: [14/30] -> loss: 1.019\n",
            "epoch: [15/30] -> loss: 1.019\n",
            "epoch: [16/30] -> loss: 1.019\n",
            "epoch: [17/30] -> loss: 1.019\n",
            "epoch: [18/30] -> loss: 1.019\n",
            "epoch: [19/30] -> loss: 1.019\n",
            "epoch: [20/30] -> loss: 1.019\n",
            "epoch: [21/30] -> loss: 1.019\n",
            "epoch: [22/30] -> loss: 1.019\n",
            "epoch: [23/30] -> loss: 1.019\n",
            "epoch: [24/30] -> loss: 1.019\n",
            "epoch: [25/30] -> loss: 1.019\n",
            "epoch: [26/30] -> loss: 1.019\n",
            "epoch: [27/30] -> loss: 1.019\n",
            "epoch: [28/30] -> loss: 1.019\n",
            "epoch: [29/30] -> loss: 1.019\n",
            "epoch: [30/30] -> loss: 1.019\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.019\n",
            "* Train accuracy: 62.24%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.113\n",
            "epoch: [2/30] -> loss: 1.042\n",
            "epoch: [3/30] -> loss: 0.992\n",
            "epoch: [4/30] -> loss: 0.958\n",
            "epoch: [5/30] -> loss: 0.928\n",
            "epoch: [6/30] -> loss: 0.905\n",
            "epoch: [7/30] -> loss: 0.885\n",
            "epoch: [8/30] -> loss: 0.870\n",
            "epoch: [9/30] -> loss: 0.856\n",
            "epoch: [10/30] -> loss: 0.843\n",
            "epoch: [11/30] -> loss: 0.833\n",
            "epoch: [12/30] -> loss: 0.822\n",
            "epoch: [13/30] -> loss: 0.814\n",
            "epoch: [14/30] -> loss: 0.807\n",
            "epoch: [15/30] -> loss: 0.800\n",
            "epoch: [16/30] -> loss: 0.796\n",
            "epoch: [17/30] -> loss: 0.788\n",
            "epoch: [18/30] -> loss: 0.783\n",
            "epoch: [19/30] -> loss: 0.779\n",
            "epoch: [20/30] -> loss: 0.774\n",
            "epoch: [21/30] -> loss: 0.769\n",
            "epoch: [22/30] -> loss: 0.766\n",
            "epoch: [23/30] -> loss: 0.763\n",
            "epoch: [24/30] -> loss: 0.760\n",
            "epoch: [25/30] -> loss: 0.756\n",
            "epoch: [26/30] -> loss: 0.753\n",
            "epoch: [27/30] -> loss: 0.751\n",
            "epoch: [28/30] -> loss: 0.749\n",
            "epoch: [29/30] -> loss: 0.746\n",
            "epoch: [30/30] -> loss: 0.745\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.745\n",
            "* Train accuracy: 79.82%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.882\n",
            "epoch: [2/30] -> loss: 0.802\n",
            "epoch: [3/30] -> loss: 0.761\n",
            "epoch: [4/30] -> loss: 0.729\n",
            "epoch: [5/30] -> loss: 0.701\n",
            "epoch: [6/30] -> loss: 0.678\n",
            "epoch: [7/30] -> loss: 0.661\n",
            "epoch: [8/30] -> loss: 0.644\n",
            "epoch: [9/30] -> loss: 0.630\n",
            "epoch: [10/30] -> loss: 0.618\n",
            "epoch: [11/30] -> loss: 0.610\n",
            "epoch: [12/30] -> loss: 0.601\n",
            "epoch: [13/30] -> loss: 0.591\n",
            "epoch: [14/30] -> loss: 0.584\n",
            "epoch: [15/30] -> loss: 0.580\n",
            "epoch: [16/30] -> loss: 0.576\n",
            "epoch: [17/30] -> loss: 0.570\n",
            "epoch: [18/30] -> loss: 0.563\n",
            "epoch: [19/30] -> loss: 0.561\n",
            "epoch: [20/30] -> loss: 0.556\n",
            "epoch: [21/30] -> loss: 0.554\n",
            "epoch: [22/30] -> loss: 0.550\n",
            "epoch: [23/30] -> loss: 0.545\n",
            "epoch: [24/30] -> loss: 0.544\n",
            "epoch: [25/30] -> loss: 0.541\n",
            "epoch: [26/30] -> loss: 0.537\n",
            "epoch: [27/30] -> loss: 0.534\n",
            "epoch: [28/30] -> loss: 0.532\n",
            "epoch: [29/30] -> loss: 0.530\n",
            "epoch: [30/30] -> loss: 0.529\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.529\n",
            "* Train accuracy: 80.90%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 3.692\n",
            "epoch: [2/30] -> loss: 3.499\n",
            "epoch: [3/30] -> loss: 3.294\n",
            "epoch: [4/30] -> loss: 3.103\n",
            "epoch: [5/30] -> loss: 2.919\n",
            "epoch: [6/30] -> loss: 2.736\n",
            "epoch: [7/30] -> loss: 2.559\n",
            "epoch: [8/30] -> loss: 2.385\n",
            "epoch: [9/30] -> loss: 2.216\n",
            "epoch: [10/30] -> loss: 2.053\n",
            "epoch: [11/30] -> loss: 1.891\n",
            "epoch: [12/30] -> loss: 1.736\n",
            "epoch: [13/30] -> loss: 1.588\n",
            "epoch: [14/30] -> loss: 1.450\n",
            "epoch: [15/30] -> loss: 1.327\n",
            "epoch: [16/30] -> loss: 1.220\n",
            "epoch: [17/30] -> loss: 1.139\n",
            "epoch: [18/30] -> loss: 1.084\n",
            "epoch: [19/30] -> loss: 1.056\n",
            "epoch: [20/30] -> loss: 1.040\n",
            "epoch: [21/30] -> loss: 1.028\n",
            "epoch: [22/30] -> loss: 1.017\n",
            "epoch: [23/30] -> loss: 1.015\n",
            "epoch: [24/30] -> loss: 1.015\n",
            "epoch: [25/30] -> loss: 1.015\n",
            "epoch: [26/30] -> loss: 1.015\n",
            "epoch: [27/30] -> loss: 1.015\n",
            "epoch: [28/30] -> loss: 1.015\n",
            "epoch: [29/30] -> loss: 1.015\n",
            "epoch: [30/30] -> loss: 1.015\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.015\n",
            "* Train accuracy: 55.47%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.285\n",
            "epoch: [2/30] -> loss: 1.209\n",
            "epoch: [3/30] -> loss: 1.151\n",
            "epoch: [4/30] -> loss: 1.123\n",
            "epoch: [5/30] -> loss: 1.101\n",
            "epoch: [6/30] -> loss: 1.087\n",
            "epoch: [7/30] -> loss: 1.072\n",
            "epoch: [8/30] -> loss: 1.059\n",
            "epoch: [9/30] -> loss: 1.046\n",
            "epoch: [10/30] -> loss: 1.037\n",
            "epoch: [11/30] -> loss: 1.026\n",
            "epoch: [12/30] -> loss: 1.016\n",
            "epoch: [13/30] -> loss: 1.008\n",
            "epoch: [14/30] -> loss: 1.001\n",
            "epoch: [15/30] -> loss: 0.991\n",
            "epoch: [16/30] -> loss: 0.984\n",
            "epoch: [17/30] -> loss: 0.976\n",
            "epoch: [18/30] -> loss: 0.970\n",
            "epoch: [19/30] -> loss: 0.962\n",
            "epoch: [20/30] -> loss: 0.956\n",
            "epoch: [21/30] -> loss: 0.951\n",
            "epoch: [22/30] -> loss: 0.947\n",
            "epoch: [23/30] -> loss: 0.942\n",
            "epoch: [24/30] -> loss: 0.936\n",
            "epoch: [25/30] -> loss: 0.929\n",
            "epoch: [26/30] -> loss: 0.925\n",
            "epoch: [27/30] -> loss: 0.920\n",
            "epoch: [28/30] -> loss: 0.915\n",
            "epoch: [29/30] -> loss: 0.912\n",
            "epoch: [30/30] -> loss: 0.907\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.907\n",
            "* Train accuracy: 73.67%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.011\n",
            "epoch: [2/30] -> loss: 0.932\n",
            "epoch: [3/30] -> loss: 0.878\n",
            "epoch: [4/30] -> loss: 0.857\n",
            "epoch: [5/30] -> loss: 0.844\n",
            "epoch: [6/30] -> loss: 0.828\n",
            "epoch: [7/30] -> loss: 0.817\n",
            "epoch: [8/30] -> loss: 0.806\n",
            "epoch: [9/30] -> loss: 0.793\n",
            "epoch: [10/30] -> loss: 0.786\n",
            "epoch: [11/30] -> loss: 0.777\n",
            "epoch: [12/30] -> loss: 0.767\n",
            "epoch: [13/30] -> loss: 0.760\n",
            "epoch: [14/30] -> loss: 0.756\n",
            "epoch: [15/30] -> loss: 0.746\n",
            "epoch: [16/30] -> loss: 0.739\n",
            "epoch: [17/30] -> loss: 0.733\n",
            "epoch: [18/30] -> loss: 0.726\n",
            "epoch: [19/30] -> loss: 0.720\n",
            "epoch: [20/30] -> loss: 0.715\n",
            "epoch: [21/30] -> loss: 0.708\n",
            "epoch: [22/30] -> loss: 0.705\n",
            "epoch: [23/30] -> loss: 0.698\n",
            "epoch: [24/30] -> loss: 0.692\n",
            "epoch: [25/30] -> loss: 0.688\n",
            "epoch: [26/30] -> loss: 0.683\n",
            "epoch: [27/30] -> loss: 0.679\n",
            "epoch: [28/30] -> loss: 0.676\n",
            "epoch: [29/30] -> loss: 0.671\n",
            "epoch: [30/30] -> loss: 0.667\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.667\n",
            "* Train accuracy: 73.88%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.521\n",
            "epoch: [2/10] -> loss: 1.124\n",
            "epoch: [3/10] -> loss: 1.115\n",
            "epoch: [4/10] -> loss: 1.107\n",
            "epoch: [5/10] -> loss: 1.107\n",
            "epoch: [6/10] -> loss: 1.105\n",
            "epoch: [7/10] -> loss: 1.109\n",
            "epoch: [8/10] -> loss: 1.114\n",
            "epoch: [9/10] -> loss: 1.107\n",
            "epoch: [10/10] -> loss: 1.107\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.107\n",
            "* Train accuracy: 64.76%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.956\n",
            "epoch: [2/10] -> loss: 0.831\n",
            "epoch: [3/10] -> loss: 0.779\n",
            "epoch: [4/10] -> loss: 0.764\n",
            "epoch: [5/10] -> loss: 0.750\n",
            "epoch: [6/10] -> loss: 0.745\n",
            "epoch: [7/10] -> loss: 0.744\n",
            "epoch: [8/10] -> loss: 0.739\n",
            "epoch: [9/10] -> loss: 0.740\n",
            "epoch: [10/10] -> loss: 0.742\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.742\n",
            "* Train accuracy: 78.60%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.718\n",
            "epoch: [2/10] -> loss: 0.599\n",
            "epoch: [3/10] -> loss: 0.555\n",
            "epoch: [4/10] -> loss: 0.539\n",
            "epoch: [5/10] -> loss: 0.521\n",
            "epoch: [6/10] -> loss: 0.508\n",
            "epoch: [7/10] -> loss: 0.504\n",
            "epoch: [8/10] -> loss: 0.496\n",
            "epoch: [9/10] -> loss: 0.490\n",
            "epoch: [10/10] -> loss: 0.481\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.481\n",
            "* Train accuracy: 79.61%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.929\n",
            "epoch: [2/10] -> loss: 1.095\n",
            "epoch: [3/10] -> loss: 1.066\n",
            "epoch: [4/10] -> loss: 1.069\n",
            "epoch: [5/10] -> loss: 1.068\n",
            "epoch: [6/10] -> loss: 1.065\n",
            "epoch: [7/10] -> loss: 1.065\n",
            "epoch: [8/10] -> loss: 1.067\n",
            "epoch: [9/10] -> loss: 1.067\n",
            "epoch: [10/10] -> loss: 1.067\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.067\n",
            "* Train accuracy: 56.33%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.030\n",
            "epoch: [2/10] -> loss: 0.906\n",
            "epoch: [3/10] -> loss: 0.840\n",
            "epoch: [4/10] -> loss: 0.804\n",
            "epoch: [5/10] -> loss: 0.779\n",
            "epoch: [6/10] -> loss: 0.765\n",
            "epoch: [7/10] -> loss: 0.757\n",
            "epoch: [8/10] -> loss: 0.748\n",
            "epoch: [9/10] -> loss: 0.741\n",
            "epoch: [10/10] -> loss: 0.742\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.742\n",
            "* Train accuracy: 79.73%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.756\n",
            "epoch: [2/10] -> loss: 0.656\n",
            "epoch: [3/10] -> loss: 0.599\n",
            "epoch: [4/10] -> loss: 0.573\n",
            "epoch: [5/10] -> loss: 0.555\n",
            "epoch: [6/10] -> loss: 0.543\n",
            "epoch: [7/10] -> loss: 0.530\n",
            "epoch: [8/10] -> loss: 0.526\n",
            "epoch: [9/10] -> loss: 0.516\n",
            "epoch: [10/10] -> loss: 0.512\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.512\n",
            "* Train accuracy: 81.97%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 3.338\n",
            "epoch: [2/10] -> loss: 2.499\n",
            "epoch: [3/10] -> loss: 1.671\n",
            "epoch: [4/10] -> loss: 1.142\n",
            "epoch: [5/10] -> loss: 1.042\n",
            "epoch: [6/10] -> loss: 1.036\n",
            "epoch: [7/10] -> loss: 1.036\n",
            "epoch: [8/10] -> loss: 1.036\n",
            "epoch: [9/10] -> loss: 1.036\n",
            "epoch: [10/10] -> loss: 1.037\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.037\n",
            "* Train accuracy: 61.73%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.130\n",
            "epoch: [2/10] -> loss: 1.064\n",
            "epoch: [3/10] -> loss: 1.018\n",
            "epoch: [4/10] -> loss: 0.975\n",
            "epoch: [5/10] -> loss: 0.948\n",
            "epoch: [6/10] -> loss: 0.929\n",
            "epoch: [7/10] -> loss: 0.905\n",
            "epoch: [8/10] -> loss: 0.888\n",
            "epoch: [9/10] -> loss: 0.875\n",
            "epoch: [10/10] -> loss: 0.861\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.861\n",
            "* Train accuracy: 76.90%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.900\n",
            "epoch: [2/10] -> loss: 0.828\n",
            "epoch: [3/10] -> loss: 0.782\n",
            "epoch: [4/10] -> loss: 0.738\n",
            "epoch: [5/10] -> loss: 0.708\n",
            "epoch: [6/10] -> loss: 0.688\n",
            "epoch: [7/10] -> loss: 0.666\n",
            "epoch: [8/10] -> loss: 0.656\n",
            "epoch: [9/10] -> loss: 0.638\n",
            "epoch: [10/10] -> loss: 0.627\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.627\n",
            "* Train accuracy: 76.62%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 3.532\n",
            "epoch: [2/10] -> loss: 3.115\n",
            "epoch: [3/10] -> loss: 2.643\n",
            "epoch: [4/10] -> loss: 2.203\n",
            "epoch: [5/10] -> loss: 1.783\n",
            "epoch: [6/10] -> loss: 1.420\n",
            "epoch: [7/10] -> loss: 1.163\n",
            "epoch: [8/10] -> loss: 1.066\n",
            "epoch: [9/10] -> loss: 1.036\n",
            "epoch: [10/10] -> loss: 1.032\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.032\n",
            "* Train accuracy: 58.11%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.196\n",
            "epoch: [2/10] -> loss: 1.139\n",
            "epoch: [3/10] -> loss: 1.092\n",
            "epoch: [4/10] -> loss: 1.060\n",
            "epoch: [5/10] -> loss: 1.040\n",
            "epoch: [6/10] -> loss: 1.016\n",
            "epoch: [7/10] -> loss: 0.993\n",
            "epoch: [8/10] -> loss: 0.975\n",
            "epoch: [9/10] -> loss: 0.961\n",
            "epoch: [10/10] -> loss: 0.944\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.944\n",
            "* Train accuracy: 72.27%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.929\n",
            "epoch: [2/10] -> loss: 0.852\n",
            "epoch: [3/10] -> loss: 0.818\n",
            "epoch: [4/10] -> loss: 0.788\n",
            "epoch: [5/10] -> loss: 0.766\n",
            "epoch: [6/10] -> loss: 0.747\n",
            "epoch: [7/10] -> loss: 0.738\n",
            "epoch: [8/10] -> loss: 0.722\n",
            "epoch: [9/10] -> loss: 0.707\n",
            "epoch: [10/10] -> loss: 0.698\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.698\n",
            "* Train accuracy: 73.72%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 3.858\n",
            "epoch: [2/10] -> loss: 3.823\n",
            "epoch: [3/10] -> loss: 3.689\n",
            "epoch: [4/10] -> loss: 3.563\n",
            "epoch: [5/10] -> loss: 3.457\n",
            "epoch: [6/10] -> loss: 3.351\n",
            "epoch: [7/10] -> loss: 3.252\n",
            "epoch: [8/10] -> loss: 3.155\n",
            "epoch: [9/10] -> loss: 3.062\n",
            "epoch: [10/10] -> loss: 2.963\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 2.963\n",
            "* Train accuracy: 63.94%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.263\n",
            "epoch: [2/10] -> loss: 1.256\n",
            "epoch: [3/10] -> loss: 1.220\n",
            "epoch: [4/10] -> loss: 1.202\n",
            "epoch: [5/10] -> loss: 1.190\n",
            "epoch: [6/10] -> loss: 1.177\n",
            "epoch: [7/10] -> loss: 1.164\n",
            "epoch: [8/10] -> loss: 1.153\n",
            "epoch: [9/10] -> loss: 1.146\n",
            "epoch: [10/10] -> loss: 1.134\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.134\n",
            "* Train accuracy: 62.59%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.020\n",
            "epoch: [2/10] -> loss: 0.998\n",
            "epoch: [3/10] -> loss: 0.950\n",
            "epoch: [4/10] -> loss: 0.919\n",
            "epoch: [5/10] -> loss: 0.899\n",
            "epoch: [6/10] -> loss: 0.889\n",
            "epoch: [7/10] -> loss: 0.881\n",
            "epoch: [8/10] -> loss: 0.875\n",
            "epoch: [9/10] -> loss: 0.862\n",
            "epoch: [10/10] -> loss: 0.857\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.857\n",
            "* Train accuracy: 63.70%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.525\n",
            "epoch: [2/20] -> loss: 1.115\n",
            "epoch: [3/20] -> loss: 1.111\n",
            "epoch: [4/20] -> loss: 1.109\n",
            "epoch: [5/20] -> loss: 1.117\n",
            "epoch: [6/20] -> loss: 1.103\n",
            "epoch: [7/20] -> loss: 1.107\n",
            "epoch: [8/20] -> loss: 1.115\n",
            "epoch: [9/20] -> loss: 1.114\n",
            "epoch: [10/20] -> loss: 1.111\n",
            "epoch: [11/20] -> loss: 1.108\n",
            "epoch: [12/20] -> loss: 1.118\n",
            "epoch: [13/20] -> loss: 1.112\n",
            "epoch: [14/20] -> loss: 1.112\n",
            "epoch: [15/20] -> loss: 1.106\n",
            "epoch: [16/20] -> loss: 1.107\n",
            "epoch: [17/20] -> loss: 1.106\n",
            "epoch: [18/20] -> loss: 1.109\n",
            "epoch: [19/20] -> loss: 1.119\n",
            "epoch: [20/20] -> loss: 1.106\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.106\n",
            "* Train accuracy: 60.74%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.965\n",
            "epoch: [2/20] -> loss: 0.829\n",
            "epoch: [3/20] -> loss: 0.776\n",
            "epoch: [4/20] -> loss: 0.758\n",
            "epoch: [5/20] -> loss: 0.749\n",
            "epoch: [6/20] -> loss: 0.741\n",
            "epoch: [7/20] -> loss: 0.745\n",
            "epoch: [8/20] -> loss: 0.741\n",
            "epoch: [9/20] -> loss: 0.739\n",
            "epoch: [10/20] -> loss: 0.739\n",
            "epoch: [11/20] -> loss: 0.740\n",
            "epoch: [12/20] -> loss: 0.739\n",
            "epoch: [13/20] -> loss: 0.743\n",
            "epoch: [14/20] -> loss: 0.743\n",
            "epoch: [15/20] -> loss: 0.740\n",
            "epoch: [16/20] -> loss: 0.738\n",
            "epoch: [17/20] -> loss: 0.740\n",
            "epoch: [18/20] -> loss: 0.739\n",
            "epoch: [19/20] -> loss: 0.744\n",
            "epoch: [20/20] -> loss: 0.739\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.739\n",
            "* Train accuracy: 76.76%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.718\n",
            "epoch: [2/20] -> loss: 0.599\n",
            "epoch: [3/20] -> loss: 0.557\n",
            "epoch: [4/20] -> loss: 0.537\n",
            "epoch: [5/20] -> loss: 0.521\n",
            "epoch: [6/20] -> loss: 0.510\n",
            "epoch: [7/20] -> loss: 0.502\n",
            "epoch: [8/20] -> loss: 0.499\n",
            "epoch: [9/20] -> loss: 0.496\n",
            "epoch: [10/20] -> loss: 0.491\n",
            "epoch: [11/20] -> loss: 0.492\n",
            "epoch: [12/20] -> loss: 0.483\n",
            "epoch: [13/20] -> loss: 0.477\n",
            "epoch: [14/20] -> loss: 0.482\n",
            "epoch: [15/20] -> loss: 0.480\n",
            "epoch: [16/20] -> loss: 0.477\n",
            "epoch: [17/20] -> loss: 0.475\n",
            "epoch: [18/20] -> loss: 0.475\n",
            "epoch: [19/20] -> loss: 0.470\n",
            "epoch: [20/20] -> loss: 0.472\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.472\n",
            "* Train accuracy: 82.32%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.935\n",
            "epoch: [2/20] -> loss: 1.090\n",
            "epoch: [3/20] -> loss: 1.069\n",
            "epoch: [4/20] -> loss: 1.067\n",
            "epoch: [5/20] -> loss: 1.067\n",
            "epoch: [6/20] -> loss: 1.066\n",
            "epoch: [7/20] -> loss: 1.065\n",
            "epoch: [8/20] -> loss: 1.066\n",
            "epoch: [9/20] -> loss: 1.066\n",
            "epoch: [10/20] -> loss: 1.070\n",
            "epoch: [11/20] -> loss: 1.070\n",
            "epoch: [12/20] -> loss: 1.067\n",
            "epoch: [13/20] -> loss: 1.068\n",
            "epoch: [14/20] -> loss: 1.066\n",
            "epoch: [15/20] -> loss: 1.065\n",
            "epoch: [16/20] -> loss: 1.069\n",
            "epoch: [17/20] -> loss: 1.070\n",
            "epoch: [18/20] -> loss: 1.069\n",
            "epoch: [19/20] -> loss: 1.067\n",
            "epoch: [20/20] -> loss: 1.066\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.066\n",
            "* Train accuracy: 60.29%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.018\n",
            "epoch: [2/20] -> loss: 0.903\n",
            "epoch: [3/20] -> loss: 0.837\n",
            "epoch: [4/20] -> loss: 0.805\n",
            "epoch: [5/20] -> loss: 0.781\n",
            "epoch: [6/20] -> loss: 0.769\n",
            "epoch: [7/20] -> loss: 0.756\n",
            "epoch: [8/20] -> loss: 0.747\n",
            "epoch: [9/20] -> loss: 0.746\n",
            "epoch: [10/20] -> loss: 0.740\n",
            "epoch: [11/20] -> loss: 0.738\n",
            "epoch: [12/20] -> loss: 0.738\n",
            "epoch: [13/20] -> loss: 0.738\n",
            "epoch: [14/20] -> loss: 0.734\n",
            "epoch: [15/20] -> loss: 0.739\n",
            "epoch: [16/20] -> loss: 0.736\n",
            "epoch: [17/20] -> loss: 0.738\n",
            "epoch: [18/20] -> loss: 0.733\n",
            "epoch: [19/20] -> loss: 0.737\n",
            "epoch: [20/20] -> loss: 0.736\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.736\n",
            "* Train accuracy: 76.16%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.782\n",
            "epoch: [2/20] -> loss: 0.660\n",
            "epoch: [3/20] -> loss: 0.607\n",
            "epoch: [4/20] -> loss: 0.571\n",
            "epoch: [5/20] -> loss: 0.550\n",
            "epoch: [6/20] -> loss: 0.542\n",
            "epoch: [7/20] -> loss: 0.528\n",
            "epoch: [8/20] -> loss: 0.519\n",
            "epoch: [9/20] -> loss: 0.514\n",
            "epoch: [10/20] -> loss: 0.515\n",
            "epoch: [11/20] -> loss: 0.509\n",
            "epoch: [12/20] -> loss: 0.504\n",
            "epoch: [13/20] -> loss: 0.498\n",
            "epoch: [14/20] -> loss: 0.497\n",
            "epoch: [15/20] -> loss: 0.496\n",
            "epoch: [16/20] -> loss: 0.487\n",
            "epoch: [17/20] -> loss: 0.490\n",
            "epoch: [18/20] -> loss: 0.488\n",
            "epoch: [19/20] -> loss: 0.486\n",
            "epoch: [20/20] -> loss: 0.480\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.480\n",
            "* Train accuracy: 82.67%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 3.283\n",
            "epoch: [2/20] -> loss: 2.453\n",
            "epoch: [3/20] -> loss: 1.638\n",
            "epoch: [4/20] -> loss: 1.129\n",
            "epoch: [5/20] -> loss: 1.040\n",
            "epoch: [6/20] -> loss: 1.036\n",
            "epoch: [7/20] -> loss: 1.036\n",
            "epoch: [8/20] -> loss: 1.036\n",
            "epoch: [9/20] -> loss: 1.036\n",
            "epoch: [10/20] -> loss: 1.036\n",
            "epoch: [11/20] -> loss: 1.036\n",
            "epoch: [12/20] -> loss: 1.036\n",
            "epoch: [13/20] -> loss: 1.035\n",
            "epoch: [14/20] -> loss: 1.036\n",
            "epoch: [15/20] -> loss: 1.036\n",
            "epoch: [16/20] -> loss: 1.036\n",
            "epoch: [17/20] -> loss: 1.036\n",
            "epoch: [18/20] -> loss: 1.036\n",
            "epoch: [19/20] -> loss: 1.036\n",
            "epoch: [20/20] -> loss: 1.036\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.036\n",
            "* Train accuracy: 59.61%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.169\n",
            "epoch: [2/20] -> loss: 1.102\n",
            "epoch: [3/20] -> loss: 1.042\n",
            "epoch: [4/20] -> loss: 0.999\n",
            "epoch: [5/20] -> loss: 0.962\n",
            "epoch: [6/20] -> loss: 0.935\n",
            "epoch: [7/20] -> loss: 0.914\n",
            "epoch: [8/20] -> loss: 0.897\n",
            "epoch: [9/20] -> loss: 0.882\n",
            "epoch: [10/20] -> loss: 0.866\n",
            "epoch: [11/20] -> loss: 0.854\n",
            "epoch: [12/20] -> loss: 0.842\n",
            "epoch: [13/20] -> loss: 0.836\n",
            "epoch: [14/20] -> loss: 0.821\n",
            "epoch: [15/20] -> loss: 0.818\n",
            "epoch: [16/20] -> loss: 0.812\n",
            "epoch: [17/20] -> loss: 0.808\n",
            "epoch: [18/20] -> loss: 0.802\n",
            "epoch: [19/20] -> loss: 0.792\n",
            "epoch: [20/20] -> loss: 0.788\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.788\n",
            "* Train accuracy: 79.07%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.912\n",
            "epoch: [2/20] -> loss: 0.824\n",
            "epoch: [3/20] -> loss: 0.775\n",
            "epoch: [4/20] -> loss: 0.737\n",
            "epoch: [5/20] -> loss: 0.705\n",
            "epoch: [6/20] -> loss: 0.684\n",
            "epoch: [7/20] -> loss: 0.665\n",
            "epoch: [8/20] -> loss: 0.649\n",
            "epoch: [9/20] -> loss: 0.638\n",
            "epoch: [10/20] -> loss: 0.627\n",
            "epoch: [11/20] -> loss: 0.616\n",
            "epoch: [12/20] -> loss: 0.608\n",
            "epoch: [13/20] -> loss: 0.605\n",
            "epoch: [14/20] -> loss: 0.588\n",
            "epoch: [15/20] -> loss: 0.586\n",
            "epoch: [16/20] -> loss: 0.580\n",
            "epoch: [17/20] -> loss: 0.570\n",
            "epoch: [18/20] -> loss: 0.574\n",
            "epoch: [19/20] -> loss: 0.568\n",
            "epoch: [20/20] -> loss: 0.565\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.565\n",
            "* Train accuracy: 80.04%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 3.614\n",
            "epoch: [2/20] -> loss: 3.175\n",
            "epoch: [3/20] -> loss: 2.696\n",
            "epoch: [4/20] -> loss: 2.239\n",
            "epoch: [5/20] -> loss: 1.813\n",
            "epoch: [6/20] -> loss: 1.441\n",
            "epoch: [7/20] -> loss: 1.173\n",
            "epoch: [8/20] -> loss: 1.067\n",
            "epoch: [9/20] -> loss: 1.035\n",
            "epoch: [10/20] -> loss: 1.032\n",
            "epoch: [11/20] -> loss: 1.032\n",
            "epoch: [12/20] -> loss: 1.032\n",
            "epoch: [13/20] -> loss: 1.032\n",
            "epoch: [14/20] -> loss: 1.033\n",
            "epoch: [15/20] -> loss: 1.033\n",
            "epoch: [16/20] -> loss: 1.032\n",
            "epoch: [17/20] -> loss: 1.032\n",
            "epoch: [18/20] -> loss: 1.032\n",
            "epoch: [19/20] -> loss: 1.032\n",
            "epoch: [20/20] -> loss: 1.032\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.032\n",
            "* Train accuracy: 55.39%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.180\n",
            "epoch: [2/20] -> loss: 1.132\n",
            "epoch: [3/20] -> loss: 1.092\n",
            "epoch: [4/20] -> loss: 1.064\n",
            "epoch: [5/20] -> loss: 1.040\n",
            "epoch: [6/20] -> loss: 1.019\n",
            "epoch: [7/20] -> loss: 0.995\n",
            "epoch: [8/20] -> loss: 0.980\n",
            "epoch: [9/20] -> loss: 0.968\n",
            "epoch: [10/20] -> loss: 0.952\n",
            "epoch: [11/20] -> loss: 0.940\n",
            "epoch: [12/20] -> loss: 0.924\n",
            "epoch: [13/20] -> loss: 0.917\n",
            "epoch: [14/20] -> loss: 0.903\n",
            "epoch: [15/20] -> loss: 0.898\n",
            "epoch: [16/20] -> loss: 0.883\n",
            "epoch: [17/20] -> loss: 0.878\n",
            "epoch: [18/20] -> loss: 0.871\n",
            "epoch: [19/20] -> loss: 0.866\n",
            "epoch: [20/20] -> loss: 0.861\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.861\n",
            "* Train accuracy: 76.03%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.967\n",
            "epoch: [2/20] -> loss: 0.873\n",
            "epoch: [3/20] -> loss: 0.835\n",
            "epoch: [4/20] -> loss: 0.808\n",
            "epoch: [5/20] -> loss: 0.780\n",
            "epoch: [6/20] -> loss: 0.758\n",
            "epoch: [7/20] -> loss: 0.746\n",
            "epoch: [8/20] -> loss: 0.728\n",
            "epoch: [9/20] -> loss: 0.714\n",
            "epoch: [10/20] -> loss: 0.702\n",
            "epoch: [11/20] -> loss: 0.686\n",
            "epoch: [12/20] -> loss: 0.681\n",
            "epoch: [13/20] -> loss: 0.672\n",
            "epoch: [14/20] -> loss: 0.662\n",
            "epoch: [15/20] -> loss: 0.657\n",
            "epoch: [16/20] -> loss: 0.647\n",
            "epoch: [17/20] -> loss: 0.643\n",
            "epoch: [18/20] -> loss: 0.634\n",
            "epoch: [19/20] -> loss: 0.628\n",
            "epoch: [20/20] -> loss: 0.619\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.619\n",
            "* Train accuracy: 77.20%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 3.789\n",
            "epoch: [2/20] -> loss: 3.758\n",
            "epoch: [3/20] -> loss: 3.636\n",
            "epoch: [4/20] -> loss: 3.526\n",
            "epoch: [5/20] -> loss: 3.422\n",
            "epoch: [6/20] -> loss: 3.323\n",
            "epoch: [7/20] -> loss: 3.218\n",
            "epoch: [8/20] -> loss: 3.119\n",
            "epoch: [9/20] -> loss: 3.021\n",
            "epoch: [10/20] -> loss: 2.929\n",
            "epoch: [11/20] -> loss: 2.828\n",
            "epoch: [12/20] -> loss: 2.738\n",
            "epoch: [13/20] -> loss: 2.636\n",
            "epoch: [14/20] -> loss: 2.551\n",
            "epoch: [15/20] -> loss: 2.459\n",
            "epoch: [16/20] -> loss: 2.366\n",
            "epoch: [17/20] -> loss: 2.280\n",
            "epoch: [18/20] -> loss: 2.191\n",
            "epoch: [19/20] -> loss: 2.101\n",
            "epoch: [20/20] -> loss: 2.018\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 2.018\n",
            "* Train accuracy: 65.52%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.316\n",
            "epoch: [2/20] -> loss: 1.305\n",
            "epoch: [3/20] -> loss: 1.254\n",
            "epoch: [4/20] -> loss: 1.213\n",
            "epoch: [5/20] -> loss: 1.183\n",
            "epoch: [6/20] -> loss: 1.171\n",
            "epoch: [7/20] -> loss: 1.158\n",
            "epoch: [8/20] -> loss: 1.147\n",
            "epoch: [9/20] -> loss: 1.141\n",
            "epoch: [10/20] -> loss: 1.129\n",
            "epoch: [11/20] -> loss: 1.124\n",
            "epoch: [12/20] -> loss: 1.118\n",
            "epoch: [13/20] -> loss: 1.113\n",
            "epoch: [14/20] -> loss: 1.104\n",
            "epoch: [15/20] -> loss: 1.094\n",
            "epoch: [16/20] -> loss: 1.090\n",
            "epoch: [17/20] -> loss: 1.082\n",
            "epoch: [18/20] -> loss: 1.078\n",
            "epoch: [19/20] -> loss: 1.071\n",
            "epoch: [20/20] -> loss: 1.066\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.066\n",
            "* Train accuracy: 66.66%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.017\n",
            "epoch: [2/20] -> loss: 0.997\n",
            "epoch: [3/20] -> loss: 0.951\n",
            "epoch: [4/20] -> loss: 0.909\n",
            "epoch: [5/20] -> loss: 0.887\n",
            "epoch: [6/20] -> loss: 0.872\n",
            "epoch: [7/20] -> loss: 0.864\n",
            "epoch: [8/20] -> loss: 0.853\n",
            "epoch: [9/20] -> loss: 0.850\n",
            "epoch: [10/20] -> loss: 0.843\n",
            "epoch: [11/20] -> loss: 0.837\n",
            "epoch: [12/20] -> loss: 0.828\n",
            "epoch: [13/20] -> loss: 0.821\n",
            "epoch: [14/20] -> loss: 0.818\n",
            "epoch: [15/20] -> loss: 0.811\n",
            "epoch: [16/20] -> loss: 0.808\n",
            "epoch: [17/20] -> loss: 0.805\n",
            "epoch: [18/20] -> loss: 0.796\n",
            "epoch: [19/20] -> loss: 0.790\n",
            "epoch: [20/20] -> loss: 0.788\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.788\n",
            "* Train accuracy: 68.18%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.520\n",
            "epoch: [2/30] -> loss: 1.126\n",
            "epoch: [3/30] -> loss: 1.108\n",
            "epoch: [4/30] -> loss: 1.118\n",
            "epoch: [5/30] -> loss: 1.110\n",
            "epoch: [6/30] -> loss: 1.103\n",
            "epoch: [7/30] -> loss: 1.123\n",
            "epoch: [8/30] -> loss: 1.117\n",
            "epoch: [9/30] -> loss: 1.106\n",
            "epoch: [10/30] -> loss: 1.113\n",
            "epoch: [11/30] -> loss: 1.122\n",
            "epoch: [12/30] -> loss: 1.109\n",
            "epoch: [13/30] -> loss: 1.117\n",
            "epoch: [14/30] -> loss: 1.102\n",
            "epoch: [15/30] -> loss: 1.110\n",
            "epoch: [16/30] -> loss: 1.108\n",
            "epoch: [17/30] -> loss: 1.105\n",
            "epoch: [18/30] -> loss: 1.110\n",
            "epoch: [19/30] -> loss: 1.109\n",
            "epoch: [20/30] -> loss: 1.113\n",
            "epoch: [21/30] -> loss: 1.112\n",
            "epoch: [22/30] -> loss: 1.110\n",
            "epoch: [23/30] -> loss: 1.106\n",
            "epoch: [24/30] -> loss: 1.112\n",
            "epoch: [25/30] -> loss: 1.117\n",
            "epoch: [26/30] -> loss: 1.112\n",
            "epoch: [27/30] -> loss: 1.116\n",
            "epoch: [28/30] -> loss: 1.107\n",
            "epoch: [29/30] -> loss: 1.110\n",
            "epoch: [30/30] -> loss: 1.108\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.108\n",
            "* Train accuracy: 60.82%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.965\n",
            "epoch: [2/30] -> loss: 0.835\n",
            "epoch: [3/30] -> loss: 0.781\n",
            "epoch: [4/30] -> loss: 0.757\n",
            "epoch: [5/30] -> loss: 0.750\n",
            "epoch: [6/30] -> loss: 0.751\n",
            "epoch: [7/30] -> loss: 0.744\n",
            "epoch: [8/30] -> loss: 0.743\n",
            "epoch: [9/30] -> loss: 0.743\n",
            "epoch: [10/30] -> loss: 0.738\n",
            "epoch: [11/30] -> loss: 0.741\n",
            "epoch: [12/30] -> loss: 0.747\n",
            "epoch: [13/30] -> loss: 0.740\n",
            "epoch: [14/30] -> loss: 0.741\n",
            "epoch: [15/30] -> loss: 0.742\n",
            "epoch: [16/30] -> loss: 0.741\n",
            "epoch: [17/30] -> loss: 0.740\n",
            "epoch: [18/30] -> loss: 0.741\n",
            "epoch: [19/30] -> loss: 0.741\n",
            "epoch: [20/30] -> loss: 0.744\n",
            "epoch: [21/30] -> loss: 0.739\n",
            "epoch: [22/30] -> loss: 0.739\n",
            "epoch: [23/30] -> loss: 0.744\n",
            "epoch: [24/30] -> loss: 0.735\n",
            "epoch: [25/30] -> loss: 0.741\n",
            "epoch: [26/30] -> loss: 0.743\n",
            "epoch: [27/30] -> loss: 0.739\n",
            "epoch: [28/30] -> loss: 0.744\n",
            "epoch: [29/30] -> loss: 0.741\n",
            "epoch: [30/30] -> loss: 0.743\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.743\n",
            "* Train accuracy: 78.57%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.690\n",
            "epoch: [2/30] -> loss: 0.592\n",
            "epoch: [3/30] -> loss: 0.554\n",
            "epoch: [4/30] -> loss: 0.532\n",
            "epoch: [5/30] -> loss: 0.521\n",
            "epoch: [6/30] -> loss: 0.509\n",
            "epoch: [7/30] -> loss: 0.505\n",
            "epoch: [8/30] -> loss: 0.499\n",
            "epoch: [9/30] -> loss: 0.489\n",
            "epoch: [10/30] -> loss: 0.487\n",
            "epoch: [11/30] -> loss: 0.483\n",
            "epoch: [12/30] -> loss: 0.480\n",
            "epoch: [13/30] -> loss: 0.474\n",
            "epoch: [14/30] -> loss: 0.475\n",
            "epoch: [15/30] -> loss: 0.476\n",
            "epoch: [16/30] -> loss: 0.476\n",
            "epoch: [17/30] -> loss: 0.472\n",
            "epoch: [18/30] -> loss: 0.467\n",
            "epoch: [19/30] -> loss: 0.469\n",
            "epoch: [20/30] -> loss: 0.467\n",
            "epoch: [21/30] -> loss: 0.467\n",
            "epoch: [22/30] -> loss: 0.470\n",
            "epoch: [23/30] -> loss: 0.465\n",
            "epoch: [24/30] -> loss: 0.466\n",
            "epoch: [25/30] -> loss: 0.460\n",
            "epoch: [26/30] -> loss: 0.460\n",
            "epoch: [27/30] -> loss: 0.463\n",
            "epoch: [28/30] -> loss: 0.462\n",
            "epoch: [29/30] -> loss: 0.462\n",
            "epoch: [30/30] -> loss: 0.462\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.462\n",
            "* Train accuracy: 84.57%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.930\n",
            "epoch: [2/30] -> loss: 1.090\n",
            "epoch: [3/30] -> loss: 1.064\n",
            "epoch: [4/30] -> loss: 1.066\n",
            "epoch: [5/30] -> loss: 1.066\n",
            "epoch: [6/30] -> loss: 1.067\n",
            "epoch: [7/30] -> loss: 1.064\n",
            "epoch: [8/30] -> loss: 1.069\n",
            "epoch: [9/30] -> loss: 1.067\n",
            "epoch: [10/30] -> loss: 1.067\n",
            "epoch: [11/30] -> loss: 1.063\n",
            "epoch: [12/30] -> loss: 1.069\n",
            "epoch: [13/30] -> loss: 1.068\n",
            "epoch: [14/30] -> loss: 1.066\n",
            "epoch: [15/30] -> loss: 1.067\n",
            "epoch: [16/30] -> loss: 1.066\n",
            "epoch: [17/30] -> loss: 1.064\n",
            "epoch: [18/30] -> loss: 1.067\n",
            "epoch: [19/30] -> loss: 1.065\n",
            "epoch: [20/30] -> loss: 1.066\n",
            "epoch: [21/30] -> loss: 1.069\n",
            "epoch: [22/30] -> loss: 1.063\n",
            "epoch: [23/30] -> loss: 1.064\n",
            "epoch: [24/30] -> loss: 1.066\n",
            "epoch: [25/30] -> loss: 1.066\n",
            "epoch: [26/30] -> loss: 1.066\n",
            "epoch: [27/30] -> loss: 1.067\n",
            "epoch: [28/30] -> loss: 1.065\n",
            "epoch: [29/30] -> loss: 1.067\n",
            "epoch: [30/30] -> loss: 1.065\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.065\n",
            "* Train accuracy: 58.96%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.021\n",
            "epoch: [2/30] -> loss: 0.907\n",
            "epoch: [3/30] -> loss: 0.839\n",
            "epoch: [4/30] -> loss: 0.805\n",
            "epoch: [5/30] -> loss: 0.780\n",
            "epoch: [6/30] -> loss: 0.765\n",
            "epoch: [7/30] -> loss: 0.759\n",
            "epoch: [8/30] -> loss: 0.748\n",
            "epoch: [9/30] -> loss: 0.748\n",
            "epoch: [10/30] -> loss: 0.740\n",
            "epoch: [11/30] -> loss: 0.740\n",
            "epoch: [12/30] -> loss: 0.736\n",
            "epoch: [13/30] -> loss: 0.737\n",
            "epoch: [14/30] -> loss: 0.737\n",
            "epoch: [15/30] -> loss: 0.741\n",
            "epoch: [16/30] -> loss: 0.736\n",
            "epoch: [17/30] -> loss: 0.739\n",
            "epoch: [18/30] -> loss: 0.738\n",
            "epoch: [19/30] -> loss: 0.735\n",
            "epoch: [20/30] -> loss: 0.737\n",
            "epoch: [21/30] -> loss: 0.734\n",
            "epoch: [22/30] -> loss: 0.736\n",
            "epoch: [23/30] -> loss: 0.735\n",
            "epoch: [24/30] -> loss: 0.739\n",
            "epoch: [25/30] -> loss: 0.737\n",
            "epoch: [26/30] -> loss: 0.736\n",
            "epoch: [27/30] -> loss: 0.736\n",
            "epoch: [28/30] -> loss: 0.737\n",
            "epoch: [29/30] -> loss: 0.738\n",
            "epoch: [30/30] -> loss: 0.734\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.734\n",
            "* Train accuracy: 77.96%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.782\n",
            "epoch: [2/30] -> loss: 0.664\n",
            "epoch: [3/30] -> loss: 0.605\n",
            "epoch: [4/30] -> loss: 0.577\n",
            "epoch: [5/30] -> loss: 0.556\n",
            "epoch: [6/30] -> loss: 0.543\n",
            "epoch: [7/30] -> loss: 0.531\n",
            "epoch: [8/30] -> loss: 0.523\n",
            "epoch: [9/30] -> loss: 0.520\n",
            "epoch: [10/30] -> loss: 0.515\n",
            "epoch: [11/30] -> loss: 0.512\n",
            "epoch: [12/30] -> loss: 0.505\n",
            "epoch: [13/30] -> loss: 0.501\n",
            "epoch: [14/30] -> loss: 0.493\n",
            "epoch: [15/30] -> loss: 0.499\n",
            "epoch: [16/30] -> loss: 0.493\n",
            "epoch: [17/30] -> loss: 0.489\n",
            "epoch: [18/30] -> loss: 0.488\n",
            "epoch: [19/30] -> loss: 0.482\n",
            "epoch: [20/30] -> loss: 0.482\n",
            "epoch: [21/30] -> loss: 0.485\n",
            "epoch: [22/30] -> loss: 0.481\n",
            "epoch: [23/30] -> loss: 0.480\n",
            "epoch: [24/30] -> loss: 0.483\n",
            "epoch: [25/30] -> loss: 0.477\n",
            "epoch: [26/30] -> loss: 0.479\n",
            "epoch: [27/30] -> loss: 0.476\n",
            "epoch: [28/30] -> loss: 0.475\n",
            "epoch: [29/30] -> loss: 0.474\n",
            "epoch: [30/30] -> loss: 0.469\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.469\n",
            "* Train accuracy: 83.49%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 3.332\n",
            "epoch: [2/30] -> loss: 2.483\n",
            "epoch: [3/30] -> loss: 1.656\n",
            "epoch: [4/30] -> loss: 1.138\n",
            "epoch: [5/30] -> loss: 1.042\n",
            "epoch: [6/30] -> loss: 1.036\n",
            "epoch: [7/30] -> loss: 1.036\n",
            "epoch: [8/30] -> loss: 1.036\n",
            "epoch: [9/30] -> loss: 1.036\n",
            "epoch: [10/30] -> loss: 1.036\n",
            "epoch: [11/30] -> loss: 1.035\n",
            "epoch: [12/30] -> loss: 1.036\n",
            "epoch: [13/30] -> loss: 1.036\n",
            "epoch: [14/30] -> loss: 1.036\n",
            "epoch: [15/30] -> loss: 1.037\n",
            "epoch: [16/30] -> loss: 1.036\n",
            "epoch: [17/30] -> loss: 1.036\n",
            "epoch: [18/30] -> loss: 1.036\n",
            "epoch: [19/30] -> loss: 1.036\n",
            "epoch: [20/30] -> loss: 1.036\n",
            "epoch: [21/30] -> loss: 1.036\n",
            "epoch: [22/30] -> loss: 1.036\n",
            "epoch: [23/30] -> loss: 1.036\n",
            "epoch: [24/30] -> loss: 1.036\n",
            "epoch: [25/30] -> loss: 1.036\n",
            "epoch: [26/30] -> loss: 1.036\n",
            "epoch: [27/30] -> loss: 1.036\n",
            "epoch: [28/30] -> loss: 1.036\n",
            "epoch: [29/30] -> loss: 1.036\n",
            "epoch: [30/30] -> loss: 1.036\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.036\n",
            "* Train accuracy: 41.12%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.161\n",
            "epoch: [2/30] -> loss: 1.102\n",
            "epoch: [3/30] -> loss: 1.040\n",
            "epoch: [4/30] -> loss: 0.999\n",
            "epoch: [5/30] -> loss: 0.962\n",
            "epoch: [6/30] -> loss: 0.941\n",
            "epoch: [7/30] -> loss: 0.918\n",
            "epoch: [8/30] -> loss: 0.899\n",
            "epoch: [9/30] -> loss: 0.881\n",
            "epoch: [10/30] -> loss: 0.867\n",
            "epoch: [11/30] -> loss: 0.857\n",
            "epoch: [12/30] -> loss: 0.848\n",
            "epoch: [13/30] -> loss: 0.834\n",
            "epoch: [14/30] -> loss: 0.830\n",
            "epoch: [15/30] -> loss: 0.817\n",
            "epoch: [16/30] -> loss: 0.811\n",
            "epoch: [17/30] -> loss: 0.804\n",
            "epoch: [18/30] -> loss: 0.797\n",
            "epoch: [19/30] -> loss: 0.795\n",
            "epoch: [20/30] -> loss: 0.790\n",
            "epoch: [21/30] -> loss: 0.781\n",
            "epoch: [22/30] -> loss: 0.781\n",
            "epoch: [23/30] -> loss: 0.775\n",
            "epoch: [24/30] -> loss: 0.776\n",
            "epoch: [25/30] -> loss: 0.770\n",
            "epoch: [26/30] -> loss: 0.770\n",
            "epoch: [27/30] -> loss: 0.761\n",
            "epoch: [28/30] -> loss: 0.760\n",
            "epoch: [29/30] -> loss: 0.758\n",
            "epoch: [30/30] -> loss: 0.756\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.756\n",
            "* Train accuracy: 79.60%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.922\n",
            "epoch: [2/30] -> loss: 0.858\n",
            "epoch: [3/30] -> loss: 0.800\n",
            "epoch: [4/30] -> loss: 0.758\n",
            "epoch: [5/30] -> loss: 0.726\n",
            "epoch: [6/30] -> loss: 0.701\n",
            "epoch: [7/30] -> loss: 0.681\n",
            "epoch: [8/30] -> loss: 0.662\n",
            "epoch: [9/30] -> loss: 0.647\n",
            "epoch: [10/30] -> loss: 0.632\n",
            "epoch: [11/30] -> loss: 0.622\n",
            "epoch: [12/30] -> loss: 0.613\n",
            "epoch: [13/30] -> loss: 0.605\n",
            "epoch: [14/30] -> loss: 0.596\n",
            "epoch: [15/30] -> loss: 0.591\n",
            "epoch: [16/30] -> loss: 0.582\n",
            "epoch: [17/30] -> loss: 0.575\n",
            "epoch: [18/30] -> loss: 0.575\n",
            "epoch: [19/30] -> loss: 0.566\n",
            "epoch: [20/30] -> loss: 0.563\n",
            "epoch: [21/30] -> loss: 0.562\n",
            "epoch: [22/30] -> loss: 0.562\n",
            "epoch: [23/30] -> loss: 0.551\n",
            "epoch: [24/30] -> loss: 0.553\n",
            "epoch: [25/30] -> loss: 0.552\n",
            "epoch: [26/30] -> loss: 0.544\n",
            "epoch: [27/30] -> loss: 0.542\n",
            "epoch: [28/30] -> loss: 0.540\n",
            "epoch: [29/30] -> loss: 0.536\n",
            "epoch: [30/30] -> loss: 0.537\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.537\n",
            "* Train accuracy: 81.12%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 3.578\n",
            "epoch: [2/30] -> loss: 3.171\n",
            "epoch: [3/30] -> loss: 2.704\n",
            "epoch: [4/30] -> loss: 2.260\n",
            "epoch: [5/30] -> loss: 1.841\n",
            "epoch: [6/30] -> loss: 1.472\n",
            "epoch: [7/30] -> loss: 1.197\n",
            "epoch: [8/30] -> loss: 1.072\n",
            "epoch: [9/30] -> loss: 1.038\n",
            "epoch: [10/30] -> loss: 1.032\n",
            "epoch: [11/30] -> loss: 1.032\n",
            "epoch: [12/30] -> loss: 1.032\n",
            "epoch: [13/30] -> loss: 1.032\n",
            "epoch: [14/30] -> loss: 1.032\n",
            "epoch: [15/30] -> loss: 1.032\n",
            "epoch: [16/30] -> loss: 1.032\n",
            "epoch: [17/30] -> loss: 1.032\n",
            "epoch: [18/30] -> loss: 1.032\n",
            "epoch: [19/30] -> loss: 1.032\n",
            "epoch: [20/30] -> loss: 1.032\n",
            "epoch: [21/30] -> loss: 1.032\n",
            "epoch: [22/30] -> loss: 1.032\n",
            "epoch: [23/30] -> loss: 1.032\n",
            "epoch: [24/30] -> loss: 1.032\n",
            "epoch: [25/30] -> loss: 1.032\n",
            "epoch: [26/30] -> loss: 1.032\n",
            "epoch: [27/30] -> loss: 1.032\n",
            "epoch: [28/30] -> loss: 1.032\n",
            "epoch: [29/30] -> loss: 1.033\n",
            "epoch: [30/30] -> loss: 1.032\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.032\n",
            "* Train accuracy: 53.47%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.198\n",
            "epoch: [2/30] -> loss: 1.117\n",
            "epoch: [3/30] -> loss: 1.081\n",
            "epoch: [4/30] -> loss: 1.048\n",
            "epoch: [5/30] -> loss: 1.025\n",
            "epoch: [6/30] -> loss: 1.004\n",
            "epoch: [7/30] -> loss: 0.984\n",
            "epoch: [8/30] -> loss: 0.968\n",
            "epoch: [9/30] -> loss: 0.953\n",
            "epoch: [10/30] -> loss: 0.937\n",
            "epoch: [11/30] -> loss: 0.928\n",
            "epoch: [12/30] -> loss: 0.913\n",
            "epoch: [13/30] -> loss: 0.904\n",
            "epoch: [14/30] -> loss: 0.901\n",
            "epoch: [15/30] -> loss: 0.890\n",
            "epoch: [16/30] -> loss: 0.882\n",
            "epoch: [17/30] -> loss: 0.871\n",
            "epoch: [18/30] -> loss: 0.868\n",
            "epoch: [19/30] -> loss: 0.861\n",
            "epoch: [20/30] -> loss: 0.859\n",
            "epoch: [21/30] -> loss: 0.850\n",
            "epoch: [22/30] -> loss: 0.844\n",
            "epoch: [23/30] -> loss: 0.840\n",
            "epoch: [24/30] -> loss: 0.836\n",
            "epoch: [25/30] -> loss: 0.829\n",
            "epoch: [26/30] -> loss: 0.824\n",
            "epoch: [27/30] -> loss: 0.819\n",
            "epoch: [28/30] -> loss: 0.821\n",
            "epoch: [29/30] -> loss: 0.814\n",
            "epoch: [30/30] -> loss: 0.813\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.813\n",
            "* Train accuracy: 78.76%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.903\n",
            "epoch: [2/30] -> loss: 0.854\n",
            "epoch: [3/30] -> loss: 0.826\n",
            "epoch: [4/30] -> loss: 0.797\n",
            "epoch: [5/30] -> loss: 0.773\n",
            "epoch: [6/30] -> loss: 0.752\n",
            "epoch: [7/30] -> loss: 0.733\n",
            "epoch: [8/30] -> loss: 0.719\n",
            "epoch: [9/30] -> loss: 0.706\n",
            "epoch: [10/30] -> loss: 0.693\n",
            "epoch: [11/30] -> loss: 0.684\n",
            "epoch: [12/30] -> loss: 0.673\n",
            "epoch: [13/30] -> loss: 0.668\n",
            "epoch: [14/30] -> loss: 0.659\n",
            "epoch: [15/30] -> loss: 0.655\n",
            "epoch: [16/30] -> loss: 0.644\n",
            "epoch: [17/30] -> loss: 0.634\n",
            "epoch: [18/30] -> loss: 0.634\n",
            "epoch: [19/30] -> loss: 0.627\n",
            "epoch: [20/30] -> loss: 0.627\n",
            "epoch: [21/30] -> loss: 0.618\n",
            "epoch: [22/30] -> loss: 0.613\n",
            "epoch: [23/30] -> loss: 0.606\n",
            "epoch: [24/30] -> loss: 0.604\n",
            "epoch: [25/30] -> loss: 0.600\n",
            "epoch: [26/30] -> loss: 0.597\n",
            "epoch: [27/30] -> loss: 0.592\n",
            "epoch: [28/30] -> loss: 0.593\n",
            "epoch: [29/30] -> loss: 0.592\n",
            "epoch: [30/30] -> loss: 0.580\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.580\n",
            "* Train accuracy: 79.16%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 3.843\n",
            "epoch: [2/30] -> loss: 3.811\n",
            "epoch: [3/30] -> loss: 3.686\n",
            "epoch: [4/30] -> loss: 3.564\n",
            "epoch: [5/30] -> loss: 3.462\n",
            "epoch: [6/30] -> loss: 3.357\n",
            "epoch: [7/30] -> loss: 3.253\n",
            "epoch: [8/30] -> loss: 3.153\n",
            "epoch: [9/30] -> loss: 3.056\n",
            "epoch: [10/30] -> loss: 2.963\n",
            "epoch: [11/30] -> loss: 2.867\n",
            "epoch: [12/30] -> loss: 2.771\n",
            "epoch: [13/30] -> loss: 2.675\n",
            "epoch: [14/30] -> loss: 2.585\n",
            "epoch: [15/30] -> loss: 2.491\n",
            "epoch: [16/30] -> loss: 2.404\n",
            "epoch: [17/30] -> loss: 2.314\n",
            "epoch: [18/30] -> loss: 2.227\n",
            "epoch: [19/30] -> loss: 2.142\n",
            "epoch: [20/30] -> loss: 2.054\n",
            "epoch: [21/30] -> loss: 1.972\n",
            "epoch: [22/30] -> loss: 1.889\n",
            "epoch: [23/30] -> loss: 1.811\n",
            "epoch: [24/30] -> loss: 1.730\n",
            "epoch: [25/30] -> loss: 1.660\n",
            "epoch: [26/30] -> loss: 1.580\n",
            "epoch: [27/30] -> loss: 1.509\n",
            "epoch: [28/30] -> loss: 1.439\n",
            "epoch: [29/30] -> loss: 1.378\n",
            "epoch: [30/30] -> loss: 1.315\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.315\n",
            "* Train accuracy: 64.77%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.251\n",
            "epoch: [2/30] -> loss: 1.236\n",
            "epoch: [3/30] -> loss: 1.191\n",
            "epoch: [4/30] -> loss: 1.166\n",
            "epoch: [5/30] -> loss: 1.146\n",
            "epoch: [6/30] -> loss: 1.138\n",
            "epoch: [7/30] -> loss: 1.128\n",
            "epoch: [8/30] -> loss: 1.117\n",
            "epoch: [9/30] -> loss: 1.112\n",
            "epoch: [10/30] -> loss: 1.107\n",
            "epoch: [11/30] -> loss: 1.103\n",
            "epoch: [12/30] -> loss: 1.098\n",
            "epoch: [13/30] -> loss: 1.090\n",
            "epoch: [14/30] -> loss: 1.089\n",
            "epoch: [15/30] -> loss: 1.076\n",
            "epoch: [16/30] -> loss: 1.070\n",
            "epoch: [17/30] -> loss: 1.064\n",
            "epoch: [18/30] -> loss: 1.059\n",
            "epoch: [19/30] -> loss: 1.054\n",
            "epoch: [20/30] -> loss: 1.053\n",
            "epoch: [21/30] -> loss: 1.047\n",
            "epoch: [22/30] -> loss: 1.039\n",
            "epoch: [23/30] -> loss: 1.041\n",
            "epoch: [24/30] -> loss: 1.034\n",
            "epoch: [25/30] -> loss: 1.029\n",
            "epoch: [26/30] -> loss: 1.023\n",
            "epoch: [27/30] -> loss: 1.014\n",
            "epoch: [28/30] -> loss: 1.015\n",
            "epoch: [29/30] -> loss: 1.013\n",
            "epoch: [30/30] -> loss: 1.011\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.011\n",
            "* Train accuracy: 69.90%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: SGD, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.996\n",
            "epoch: [2/30] -> loss: 0.985\n",
            "epoch: [3/30] -> loss: 0.961\n",
            "epoch: [4/30] -> loss: 0.941\n",
            "epoch: [5/30] -> loss: 0.930\n",
            "epoch: [6/30] -> loss: 0.917\n",
            "epoch: [7/30] -> loss: 0.908\n",
            "epoch: [8/30] -> loss: 0.894\n",
            "epoch: [9/30] -> loss: 0.891\n",
            "epoch: [10/30] -> loss: 0.874\n",
            "epoch: [11/30] -> loss: 0.870\n",
            "epoch: [12/30] -> loss: 0.861\n",
            "epoch: [13/30] -> loss: 0.855\n",
            "epoch: [14/30] -> loss: 0.846\n",
            "epoch: [15/30] -> loss: 0.837\n",
            "epoch: [16/30] -> loss: 0.833\n",
            "epoch: [17/30] -> loss: 0.827\n",
            "epoch: [18/30] -> loss: 0.820\n",
            "epoch: [19/30] -> loss: 0.814\n",
            "epoch: [20/30] -> loss: 0.812\n",
            "epoch: [21/30] -> loss: 0.804\n",
            "epoch: [22/30] -> loss: 0.804\n",
            "epoch: [23/30] -> loss: 0.793\n",
            "epoch: [24/30] -> loss: 0.790\n",
            "epoch: [25/30] -> loss: 0.791\n",
            "epoch: [26/30] -> loss: 0.784\n",
            "epoch: [27/30] -> loss: 0.777\n",
            "epoch: [28/30] -> loss: 0.776\n",
            "epoch: [29/30] -> loss: 0.770\n",
            "epoch: [30/30] -> loss: 0.765\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.765\n",
            "* Train accuracy: 68.96%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.667\n",
            "epoch: [2/10] -> loss: 1.710\n",
            "epoch: [3/10] -> loss: 1.612\n",
            "epoch: [4/10] -> loss: 1.555\n",
            "epoch: [5/10] -> loss: 1.627\n",
            "epoch: [6/10] -> loss: 1.657\n",
            "epoch: [7/10] -> loss: 1.559\n",
            "epoch: [8/10] -> loss: 1.589\n",
            "epoch: [9/10] -> loss: 1.553\n",
            "epoch: [10/10] -> loss: 1.595\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.595\n",
            "* Train accuracy: 50.23%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.265\n",
            "epoch: [2/10] -> loss: 1.222\n",
            "epoch: [3/10] -> loss: 1.247\n",
            "epoch: [4/10] -> loss: 1.208\n",
            "epoch: [5/10] -> loss: 1.379\n",
            "epoch: [6/10] -> loss: 1.184\n",
            "epoch: [7/10] -> loss: 1.232\n",
            "epoch: [8/10] -> loss: 1.258\n",
            "epoch: [9/10] -> loss: 1.196\n",
            "epoch: [10/10] -> loss: 1.148\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.148\n",
            "* Train accuracy: 68.46%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.908\n",
            "epoch: [2/10] -> loss: 0.894\n",
            "epoch: [3/10] -> loss: 0.900\n",
            "epoch: [4/10] -> loss: 0.890\n",
            "epoch: [5/10] -> loss: 0.958\n",
            "epoch: [6/10] -> loss: 0.906\n",
            "epoch: [7/10] -> loss: 0.898\n",
            "epoch: [8/10] -> loss: 0.859\n",
            "epoch: [9/10] -> loss: 0.955\n",
            "epoch: [10/10] -> loss: 1.046\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.046\n",
            "* Train accuracy: 75.14%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.379\n",
            "epoch: [2/10] -> loss: 1.355\n",
            "epoch: [3/10] -> loss: 1.305\n",
            "epoch: [4/10] -> loss: 1.323\n",
            "epoch: [5/10] -> loss: 1.321\n",
            "epoch: [6/10] -> loss: 1.343\n",
            "epoch: [7/10] -> loss: 1.326\n",
            "epoch: [8/10] -> loss: 1.316\n",
            "epoch: [9/10] -> loss: 1.336\n",
            "epoch: [10/10] -> loss: 1.328\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.328\n",
            "* Train accuracy: 63.20%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.021\n",
            "epoch: [2/10] -> loss: 0.962\n",
            "epoch: [3/10] -> loss: 0.940\n",
            "epoch: [4/10] -> loss: 0.978\n",
            "epoch: [5/10] -> loss: 0.979\n",
            "epoch: [6/10] -> loss: 0.967\n",
            "epoch: [7/10] -> loss: 0.988\n",
            "epoch: [8/10] -> loss: 0.993\n",
            "epoch: [9/10] -> loss: 0.990\n",
            "epoch: [10/10] -> loss: 1.019\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.019\n",
            "* Train accuracy: 75.24%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.709\n",
            "epoch: [2/10] -> loss: 0.651\n",
            "epoch: [3/10] -> loss: 0.640\n",
            "epoch: [4/10] -> loss: 0.655\n",
            "epoch: [5/10] -> loss: 0.707\n",
            "epoch: [6/10] -> loss: 0.647\n",
            "epoch: [7/10] -> loss: 0.636\n",
            "epoch: [8/10] -> loss: 0.667\n",
            "epoch: [9/10] -> loss: 0.641\n",
            "epoch: [10/10] -> loss: 0.704\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.704\n",
            "* Train accuracy: 82.09%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.196\n",
            "epoch: [2/10] -> loss: 1.091\n",
            "epoch: [3/10] -> loss: 1.082\n",
            "epoch: [4/10] -> loss: 1.098\n",
            "epoch: [5/10] -> loss: 1.090\n",
            "epoch: [6/10] -> loss: 1.090\n",
            "epoch: [7/10] -> loss: 1.093\n",
            "epoch: [8/10] -> loss: 1.094\n",
            "epoch: [9/10] -> loss: 1.089\n",
            "epoch: [10/10] -> loss: 1.087\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.087\n",
            "* Train accuracy: 63.51%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.822\n",
            "epoch: [2/10] -> loss: 0.769\n",
            "epoch: [3/10] -> loss: 0.770\n",
            "epoch: [4/10] -> loss: 0.772\n",
            "epoch: [5/10] -> loss: 0.764\n",
            "epoch: [6/10] -> loss: 0.768\n",
            "epoch: [7/10] -> loss: 0.771\n",
            "epoch: [8/10] -> loss: 0.769\n",
            "epoch: [9/10] -> loss: 0.770\n",
            "epoch: [10/10] -> loss: 0.767\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.767\n",
            "* Train accuracy: 76.92%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.588\n",
            "epoch: [2/10] -> loss: 0.508\n",
            "epoch: [3/10] -> loss: 0.496\n",
            "epoch: [4/10] -> loss: 0.488\n",
            "epoch: [5/10] -> loss: 0.488\n",
            "epoch: [6/10] -> loss: 0.489\n",
            "epoch: [7/10] -> loss: 0.477\n",
            "epoch: [8/10] -> loss: 0.482\n",
            "epoch: [9/10] -> loss: 0.487\n",
            "epoch: [10/10] -> loss: 0.489\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.489\n",
            "* Train accuracy: 82.24%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.245\n",
            "epoch: [2/10] -> loss: 1.055\n",
            "epoch: [3/10] -> loss: 1.050\n",
            "epoch: [4/10] -> loss: 1.055\n",
            "epoch: [5/10] -> loss: 1.055\n",
            "epoch: [6/10] -> loss: 1.049\n",
            "epoch: [7/10] -> loss: 1.057\n",
            "epoch: [8/10] -> loss: 1.059\n",
            "epoch: [9/10] -> loss: 1.054\n",
            "epoch: [10/10] -> loss: 1.056\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.056\n",
            "* Train accuracy: 63.22%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.820\n",
            "epoch: [2/10] -> loss: 0.747\n",
            "epoch: [3/10] -> loss: 0.749\n",
            "epoch: [4/10] -> loss: 0.747\n",
            "epoch: [5/10] -> loss: 0.745\n",
            "epoch: [6/10] -> loss: 0.749\n",
            "epoch: [7/10] -> loss: 0.745\n",
            "epoch: [8/10] -> loss: 0.748\n",
            "epoch: [9/10] -> loss: 0.747\n",
            "epoch: [10/10] -> loss: 0.747\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.747\n",
            "* Train accuracy: 78.71%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.600\n",
            "epoch: [2/10] -> loss: 0.508\n",
            "epoch: [3/10] -> loss: 0.486\n",
            "epoch: [4/10] -> loss: 0.479\n",
            "epoch: [5/10] -> loss: 0.472\n",
            "epoch: [6/10] -> loss: 0.473\n",
            "epoch: [7/10] -> loss: 0.467\n",
            "epoch: [8/10] -> loss: 0.468\n",
            "epoch: [9/10] -> loss: 0.467\n",
            "epoch: [10/10] -> loss: 0.462\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.462\n",
            "* Train accuracy: 83.21%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.893\n",
            "epoch: [2/10] -> loss: 1.018\n",
            "epoch: [3/10] -> loss: 1.013\n",
            "epoch: [4/10] -> loss: 1.015\n",
            "epoch: [5/10] -> loss: 1.015\n",
            "epoch: [6/10] -> loss: 1.016\n",
            "epoch: [7/10] -> loss: 1.014\n",
            "epoch: [8/10] -> loss: 1.016\n",
            "epoch: [9/10] -> loss: 1.015\n",
            "epoch: [10/10] -> loss: 1.016\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.016\n",
            "* Train accuracy: 63.90%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.985\n",
            "epoch: [2/10] -> loss: 0.813\n",
            "epoch: [3/10] -> loss: 0.760\n",
            "epoch: [4/10] -> loss: 0.739\n",
            "epoch: [5/10] -> loss: 0.729\n",
            "epoch: [6/10] -> loss: 0.727\n",
            "epoch: [7/10] -> loss: 0.724\n",
            "epoch: [8/10] -> loss: 0.723\n",
            "epoch: [9/10] -> loss: 0.722\n",
            "epoch: [10/10] -> loss: 0.723\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.723\n",
            "* Train accuracy: 79.91%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.728\n",
            "epoch: [2/10] -> loss: 0.587\n",
            "epoch: [3/10] -> loss: 0.541\n",
            "epoch: [4/10] -> loss: 0.518\n",
            "epoch: [5/10] -> loss: 0.505\n",
            "epoch: [6/10] -> loss: 0.494\n",
            "epoch: [7/10] -> loss: 0.485\n",
            "epoch: [8/10] -> loss: 0.481\n",
            "epoch: [9/10] -> loss: 0.477\n",
            "epoch: [10/10] -> loss: 0.472\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.472\n",
            "* Train accuracy: 83.33%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.712\n",
            "epoch: [2/20] -> loss: 1.538\n",
            "epoch: [3/20] -> loss: 1.567\n",
            "epoch: [4/20] -> loss: 1.540\n",
            "epoch: [5/20] -> loss: 1.594\n",
            "epoch: [6/20] -> loss: 1.602\n",
            "epoch: [7/20] -> loss: 1.613\n",
            "epoch: [8/20] -> loss: 1.577\n",
            "epoch: [9/20] -> loss: 1.600\n",
            "epoch: [10/20] -> loss: 1.557\n",
            "epoch: [11/20] -> loss: 1.610\n",
            "epoch: [12/20] -> loss: 1.617\n",
            "epoch: [13/20] -> loss: 1.578\n",
            "epoch: [14/20] -> loss: 1.625\n",
            "epoch: [15/20] -> loss: 1.540\n",
            "epoch: [16/20] -> loss: 1.610\n",
            "epoch: [17/20] -> loss: 1.631\n",
            "epoch: [18/20] -> loss: 1.538\n",
            "epoch: [19/20] -> loss: 1.642\n",
            "epoch: [20/20] -> loss: 1.608\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.608\n",
            "* Train accuracy: 62.20%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.287\n",
            "epoch: [2/20] -> loss: 1.314\n",
            "epoch: [3/20] -> loss: 1.316\n",
            "epoch: [4/20] -> loss: 1.163\n",
            "epoch: [5/20] -> loss: 1.218\n",
            "epoch: [6/20] -> loss: 1.216\n",
            "epoch: [7/20] -> loss: 1.229\n",
            "epoch: [8/20] -> loss: 1.156\n",
            "epoch: [9/20] -> loss: 1.271\n",
            "epoch: [10/20] -> loss: 1.198\n",
            "epoch: [11/20] -> loss: 1.234\n",
            "epoch: [12/20] -> loss: 1.213\n",
            "epoch: [13/20] -> loss: 1.218\n",
            "epoch: [14/20] -> loss: 1.260\n",
            "epoch: [15/20] -> loss: 1.230\n",
            "epoch: [16/20] -> loss: 1.228\n",
            "epoch: [17/20] -> loss: 1.312\n",
            "epoch: [18/20] -> loss: 1.311\n",
            "epoch: [19/20] -> loss: 1.219\n",
            "epoch: [20/20] -> loss: 1.181\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.181\n",
            "* Train accuracy: 59.06%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.980\n",
            "epoch: [2/20] -> loss: 0.885\n",
            "epoch: [3/20] -> loss: 1.000\n",
            "epoch: [4/20] -> loss: 0.920\n",
            "epoch: [5/20] -> loss: 0.947\n",
            "epoch: [6/20] -> loss: 0.910\n",
            "epoch: [7/20] -> loss: 0.924\n",
            "epoch: [8/20] -> loss: 0.958\n",
            "epoch: [9/20] -> loss: 0.876\n",
            "epoch: [10/20] -> loss: 0.920\n",
            "epoch: [11/20] -> loss: 0.835\n",
            "epoch: [12/20] -> loss: 0.909\n",
            "epoch: [13/20] -> loss: 0.878\n",
            "epoch: [14/20] -> loss: 0.969\n",
            "epoch: [15/20] -> loss: 0.891\n",
            "epoch: [16/20] -> loss: 0.959\n",
            "epoch: [17/20] -> loss: 0.907\n",
            "epoch: [18/20] -> loss: 0.909\n",
            "epoch: [19/20] -> loss: 0.875\n",
            "epoch: [20/20] -> loss: 0.854\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.854\n",
            "* Train accuracy: 79.69%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.395\n",
            "epoch: [2/20] -> loss: 1.331\n",
            "epoch: [3/20] -> loss: 1.332\n",
            "epoch: [4/20] -> loss: 1.341\n",
            "epoch: [5/20] -> loss: 1.319\n",
            "epoch: [6/20] -> loss: 1.330\n",
            "epoch: [7/20] -> loss: 1.283\n",
            "epoch: [8/20] -> loss: 1.348\n",
            "epoch: [9/20] -> loss: 1.325\n",
            "epoch: [10/20] -> loss: 1.355\n",
            "epoch: [11/20] -> loss: 1.311\n",
            "epoch: [12/20] -> loss: 1.360\n",
            "epoch: [13/20] -> loss: 1.311\n",
            "epoch: [14/20] -> loss: 1.315\n",
            "epoch: [15/20] -> loss: 1.311\n",
            "epoch: [16/20] -> loss: 1.316\n",
            "epoch: [17/20] -> loss: 1.328\n",
            "epoch: [18/20] -> loss: 1.352\n",
            "epoch: [19/20] -> loss: 1.296\n",
            "epoch: [20/20] -> loss: 1.365\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.365\n",
            "* Train accuracy: 48.93%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.991\n",
            "epoch: [2/20] -> loss: 0.931\n",
            "epoch: [3/20] -> loss: 0.971\n",
            "epoch: [4/20] -> loss: 0.942\n",
            "epoch: [5/20] -> loss: 1.024\n",
            "epoch: [6/20] -> loss: 1.033\n",
            "epoch: [7/20] -> loss: 0.976\n",
            "epoch: [8/20] -> loss: 0.975\n",
            "epoch: [9/20] -> loss: 1.006\n",
            "epoch: [10/20] -> loss: 0.945\n",
            "epoch: [11/20] -> loss: 0.940\n",
            "epoch: [12/20] -> loss: 0.990\n",
            "epoch: [13/20] -> loss: 0.991\n",
            "epoch: [14/20] -> loss: 1.005\n",
            "epoch: [15/20] -> loss: 0.974\n",
            "epoch: [16/20] -> loss: 0.973\n",
            "epoch: [17/20] -> loss: 0.976\n",
            "epoch: [18/20] -> loss: 0.992\n",
            "epoch: [19/20] -> loss: 0.980\n",
            "epoch: [20/20] -> loss: 1.005\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.005\n",
            "* Train accuracy: 77.53%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.724\n",
            "epoch: [2/20] -> loss: 0.680\n",
            "epoch: [3/20] -> loss: 0.672\n",
            "epoch: [4/20] -> loss: 0.655\n",
            "epoch: [5/20] -> loss: 0.651\n",
            "epoch: [6/20] -> loss: 0.686\n",
            "epoch: [7/20] -> loss: 0.648\n",
            "epoch: [8/20] -> loss: 0.664\n",
            "epoch: [9/20] -> loss: 0.669\n",
            "epoch: [10/20] -> loss: 0.670\n",
            "epoch: [11/20] -> loss: 0.720\n",
            "epoch: [12/20] -> loss: 0.664\n",
            "epoch: [13/20] -> loss: 0.657\n",
            "epoch: [14/20] -> loss: 0.642\n",
            "epoch: [15/20] -> loss: 0.687\n",
            "epoch: [16/20] -> loss: 0.666\n",
            "epoch: [17/20] -> loss: 0.667\n",
            "epoch: [18/20] -> loss: 0.662\n",
            "epoch: [19/20] -> loss: 0.676\n",
            "epoch: [20/20] -> loss: 0.678\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.678\n",
            "* Train accuracy: 74.41%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.204\n",
            "epoch: [2/20] -> loss: 1.087\n",
            "epoch: [3/20] -> loss: 1.096\n",
            "epoch: [4/20] -> loss: 1.091\n",
            "epoch: [5/20] -> loss: 1.092\n",
            "epoch: [6/20] -> loss: 1.095\n",
            "epoch: [7/20] -> loss: 1.091\n",
            "epoch: [8/20] -> loss: 1.094\n",
            "epoch: [9/20] -> loss: 1.092\n",
            "epoch: [10/20] -> loss: 1.107\n",
            "epoch: [11/20] -> loss: 1.092\n",
            "epoch: [12/20] -> loss: 1.088\n",
            "epoch: [13/20] -> loss: 1.094\n",
            "epoch: [14/20] -> loss: 1.090\n",
            "epoch: [15/20] -> loss: 1.086\n",
            "epoch: [16/20] -> loss: 1.094\n",
            "epoch: [17/20] -> loss: 1.093\n",
            "epoch: [18/20] -> loss: 1.089\n",
            "epoch: [19/20] -> loss: 1.102\n",
            "epoch: [20/20] -> loss: 1.093\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.093\n",
            "* Train accuracy: 63.84%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.810\n",
            "epoch: [2/20] -> loss: 0.770\n",
            "epoch: [3/20] -> loss: 0.770\n",
            "epoch: [4/20] -> loss: 0.769\n",
            "epoch: [5/20] -> loss: 0.768\n",
            "epoch: [6/20] -> loss: 0.773\n",
            "epoch: [7/20] -> loss: 0.763\n",
            "epoch: [8/20] -> loss: 0.788\n",
            "epoch: [9/20] -> loss: 0.771\n",
            "epoch: [10/20] -> loss: 0.773\n",
            "epoch: [11/20] -> loss: 0.769\n",
            "epoch: [12/20] -> loss: 0.770\n",
            "epoch: [13/20] -> loss: 0.768\n",
            "epoch: [14/20] -> loss: 0.764\n",
            "epoch: [15/20] -> loss: 0.769\n",
            "epoch: [16/20] -> loss: 0.763\n",
            "epoch: [17/20] -> loss: 0.769\n",
            "epoch: [18/20] -> loss: 0.773\n",
            "epoch: [19/20] -> loss: 0.772\n",
            "epoch: [20/20] -> loss: 0.766\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.766\n",
            "* Train accuracy: 77.67%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.581\n",
            "epoch: [2/20] -> loss: 0.506\n",
            "epoch: [3/20] -> loss: 0.491\n",
            "epoch: [4/20] -> loss: 0.488\n",
            "epoch: [5/20] -> loss: 0.493\n",
            "epoch: [6/20] -> loss: 0.487\n",
            "epoch: [7/20] -> loss: 0.482\n",
            "epoch: [8/20] -> loss: 0.487\n",
            "epoch: [9/20] -> loss: 0.486\n",
            "epoch: [10/20] -> loss: 0.489\n",
            "epoch: [11/20] -> loss: 0.488\n",
            "epoch: [12/20] -> loss: 0.479\n",
            "epoch: [13/20] -> loss: 0.482\n",
            "epoch: [14/20] -> loss: 0.484\n",
            "epoch: [15/20] -> loss: 0.489\n",
            "epoch: [16/20] -> loss: 0.481\n",
            "epoch: [17/20] -> loss: 0.482\n",
            "epoch: [18/20] -> loss: 0.483\n",
            "epoch: [19/20] -> loss: 0.487\n",
            "epoch: [20/20] -> loss: 0.485\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.485\n",
            "* Train accuracy: 85.07%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.238\n",
            "epoch: [2/20] -> loss: 1.056\n",
            "epoch: [3/20] -> loss: 1.053\n",
            "epoch: [4/20] -> loss: 1.050\n",
            "epoch: [5/20] -> loss: 1.054\n",
            "epoch: [6/20] -> loss: 1.056\n",
            "epoch: [7/20] -> loss: 1.054\n",
            "epoch: [8/20] -> loss: 1.053\n",
            "epoch: [9/20] -> loss: 1.058\n",
            "epoch: [10/20] -> loss: 1.056\n",
            "epoch: [11/20] -> loss: 1.052\n",
            "epoch: [12/20] -> loss: 1.055\n",
            "epoch: [13/20] -> loss: 1.052\n",
            "epoch: [14/20] -> loss: 1.057\n",
            "epoch: [15/20] -> loss: 1.058\n",
            "epoch: [16/20] -> loss: 1.054\n",
            "epoch: [17/20] -> loss: 1.054\n",
            "epoch: [18/20] -> loss: 1.055\n",
            "epoch: [19/20] -> loss: 1.055\n",
            "epoch: [20/20] -> loss: 1.057\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.057\n",
            "* Train accuracy: 60.74%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.827\n",
            "epoch: [2/20] -> loss: 0.748\n",
            "epoch: [3/20] -> loss: 0.742\n",
            "epoch: [4/20] -> loss: 0.746\n",
            "epoch: [5/20] -> loss: 0.746\n",
            "epoch: [6/20] -> loss: 0.744\n",
            "epoch: [7/20] -> loss: 0.745\n",
            "epoch: [8/20] -> loss: 0.741\n",
            "epoch: [9/20] -> loss: 0.746\n",
            "epoch: [10/20] -> loss: 0.741\n",
            "epoch: [11/20] -> loss: 0.740\n",
            "epoch: [12/20] -> loss: 0.741\n",
            "epoch: [13/20] -> loss: 0.744\n",
            "epoch: [14/20] -> loss: 0.742\n",
            "epoch: [15/20] -> loss: 0.744\n",
            "epoch: [16/20] -> loss: 0.745\n",
            "epoch: [17/20] -> loss: 0.743\n",
            "epoch: [18/20] -> loss: 0.747\n",
            "epoch: [19/20] -> loss: 0.746\n",
            "epoch: [20/20] -> loss: 0.743\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.743\n",
            "* Train accuracy: 77.71%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.592\n",
            "epoch: [2/20] -> loss: 0.504\n",
            "epoch: [3/20] -> loss: 0.485\n",
            "epoch: [4/20] -> loss: 0.478\n",
            "epoch: [5/20] -> loss: 0.476\n",
            "epoch: [6/20] -> loss: 0.465\n",
            "epoch: [7/20] -> loss: 0.467\n",
            "epoch: [8/20] -> loss: 0.463\n",
            "epoch: [9/20] -> loss: 0.460\n",
            "epoch: [10/20] -> loss: 0.460\n",
            "epoch: [11/20] -> loss: 0.460\n",
            "epoch: [12/20] -> loss: 0.459\n",
            "epoch: [13/20] -> loss: 0.459\n",
            "epoch: [14/20] -> loss: 0.460\n",
            "epoch: [15/20] -> loss: 0.457\n",
            "epoch: [16/20] -> loss: 0.458\n",
            "epoch: [17/20] -> loss: 0.459\n",
            "epoch: [18/20] -> loss: 0.461\n",
            "epoch: [19/20] -> loss: 0.460\n",
            "epoch: [20/20] -> loss: 0.459\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.459\n",
            "* Train accuracy: 85.22%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.867\n",
            "epoch: [2/20] -> loss: 1.019\n",
            "epoch: [3/20] -> loss: 1.014\n",
            "epoch: [4/20] -> loss: 1.015\n",
            "epoch: [5/20] -> loss: 1.015\n",
            "epoch: [6/20] -> loss: 1.014\n",
            "epoch: [7/20] -> loss: 1.013\n",
            "epoch: [8/20] -> loss: 1.015\n",
            "epoch: [9/20] -> loss: 1.015\n",
            "epoch: [10/20] -> loss: 1.015\n",
            "epoch: [11/20] -> loss: 1.016\n",
            "epoch: [12/20] -> loss: 1.015\n",
            "epoch: [13/20] -> loss: 1.014\n",
            "epoch: [14/20] -> loss: 1.017\n",
            "epoch: [15/20] -> loss: 1.015\n",
            "epoch: [16/20] -> loss: 1.016\n",
            "epoch: [17/20] -> loss: 1.016\n",
            "epoch: [18/20] -> loss: 1.014\n",
            "epoch: [19/20] -> loss: 1.013\n",
            "epoch: [20/20] -> loss: 1.014\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.014\n",
            "* Train accuracy: 61.24%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.978\n",
            "epoch: [2/20] -> loss: 0.811\n",
            "epoch: [3/20] -> loss: 0.761\n",
            "epoch: [4/20] -> loss: 0.739\n",
            "epoch: [5/20] -> loss: 0.732\n",
            "epoch: [6/20] -> loss: 0.726\n",
            "epoch: [7/20] -> loss: 0.724\n",
            "epoch: [8/20] -> loss: 0.723\n",
            "epoch: [9/20] -> loss: 0.722\n",
            "epoch: [10/20] -> loss: 0.722\n",
            "epoch: [11/20] -> loss: 0.723\n",
            "epoch: [12/20] -> loss: 0.723\n",
            "epoch: [13/20] -> loss: 0.723\n",
            "epoch: [14/20] -> loss: 0.724\n",
            "epoch: [15/20] -> loss: 0.724\n",
            "epoch: [16/20] -> loss: 0.723\n",
            "epoch: [17/20] -> loss: 0.724\n",
            "epoch: [18/20] -> loss: 0.724\n",
            "epoch: [19/20] -> loss: 0.722\n",
            "epoch: [20/20] -> loss: 0.722\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.722\n",
            "* Train accuracy: 79.23%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.713\n",
            "epoch: [2/20] -> loss: 0.581\n",
            "epoch: [3/20] -> loss: 0.537\n",
            "epoch: [4/20] -> loss: 0.514\n",
            "epoch: [5/20] -> loss: 0.500\n",
            "epoch: [6/20] -> loss: 0.491\n",
            "epoch: [7/20] -> loss: 0.485\n",
            "epoch: [8/20] -> loss: 0.480\n",
            "epoch: [9/20] -> loss: 0.475\n",
            "epoch: [10/20] -> loss: 0.469\n",
            "epoch: [11/20] -> loss: 0.469\n",
            "epoch: [12/20] -> loss: 0.466\n",
            "epoch: [13/20] -> loss: 0.463\n",
            "epoch: [14/20] -> loss: 0.463\n",
            "epoch: [15/20] -> loss: 0.460\n",
            "epoch: [16/20] -> loss: 0.459\n",
            "epoch: [17/20] -> loss: 0.459\n",
            "epoch: [18/20] -> loss: 0.456\n",
            "epoch: [19/20] -> loss: 0.455\n",
            "epoch: [20/20] -> loss: 0.454\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.454\n",
            "* Train accuracy: 84.51%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.682\n",
            "epoch: [2/30] -> loss: 1.631\n",
            "epoch: [3/30] -> loss: 1.592\n",
            "epoch: [4/30] -> loss: 1.624\n",
            "epoch: [5/30] -> loss: 1.593\n",
            "epoch: [6/30] -> loss: 1.551\n",
            "epoch: [7/30] -> loss: 1.545\n",
            "epoch: [8/30] -> loss: 1.599\n",
            "epoch: [9/30] -> loss: 1.578\n",
            "epoch: [10/30] -> loss: 1.605\n",
            "epoch: [11/30] -> loss: 1.536\n",
            "epoch: [12/30] -> loss: 1.599\n",
            "epoch: [13/30] -> loss: 1.681\n",
            "epoch: [14/30] -> loss: 1.587\n",
            "epoch: [15/30] -> loss: 1.621\n",
            "epoch: [16/30] -> loss: 1.618\n",
            "epoch: [17/30] -> loss: 1.558\n",
            "epoch: [18/30] -> loss: 1.598\n",
            "epoch: [19/30] -> loss: 1.584\n",
            "epoch: [20/30] -> loss: 1.571\n",
            "epoch: [21/30] -> loss: 1.620\n",
            "epoch: [22/30] -> loss: 1.605\n",
            "epoch: [23/30] -> loss: 1.550\n",
            "epoch: [24/30] -> loss: 1.584\n",
            "epoch: [25/30] -> loss: 1.604\n",
            "epoch: [26/30] -> loss: 1.552\n",
            "epoch: [27/30] -> loss: 1.665\n",
            "epoch: [28/30] -> loss: 1.586\n",
            "epoch: [29/30] -> loss: 1.558\n",
            "epoch: [30/30] -> loss: 1.596\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.596\n",
            "* Train accuracy: 58.48%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.305\n",
            "epoch: [2/30] -> loss: 1.193\n",
            "epoch: [3/30] -> loss: 1.221\n",
            "epoch: [4/30] -> loss: 1.242\n",
            "epoch: [5/30] -> loss: 1.289\n",
            "epoch: [6/30] -> loss: 1.142\n",
            "epoch: [7/30] -> loss: 1.251\n",
            "epoch: [8/30] -> loss: 1.215\n",
            "epoch: [9/30] -> loss: 1.167\n",
            "epoch: [10/30] -> loss: 1.294\n",
            "epoch: [11/30] -> loss: 1.239\n",
            "epoch: [12/30] -> loss: 1.212\n",
            "epoch: [13/30] -> loss: 1.307\n",
            "epoch: [14/30] -> loss: 1.198\n",
            "epoch: [15/30] -> loss: 1.167\n",
            "epoch: [16/30] -> loss: 1.210\n",
            "epoch: [17/30] -> loss: 1.142\n",
            "epoch: [18/30] -> loss: 1.193\n",
            "epoch: [19/30] -> loss: 1.207\n",
            "epoch: [20/30] -> loss: 1.298\n",
            "epoch: [21/30] -> loss: 1.198\n",
            "epoch: [22/30] -> loss: 1.242\n",
            "epoch: [23/30] -> loss: 1.217\n",
            "epoch: [24/30] -> loss: 1.144\n",
            "epoch: [25/30] -> loss: 1.239\n",
            "epoch: [26/30] -> loss: 1.237\n",
            "epoch: [27/30] -> loss: 1.205\n",
            "epoch: [28/30] -> loss: 1.296\n",
            "epoch: [29/30] -> loss: 1.260\n",
            "epoch: [30/30] -> loss: 1.254\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.254\n",
            "* Train accuracy: 74.23%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.906\n",
            "epoch: [2/30] -> loss: 0.877\n",
            "epoch: [3/30] -> loss: 0.889\n",
            "epoch: [4/30] -> loss: 0.905\n",
            "epoch: [5/30] -> loss: 0.908\n",
            "epoch: [6/30] -> loss: 0.943\n",
            "epoch: [7/30] -> loss: 0.948\n",
            "epoch: [8/30] -> loss: 0.910\n",
            "epoch: [9/30] -> loss: 1.033\n",
            "epoch: [10/30] -> loss: 0.872\n",
            "epoch: [11/30] -> loss: 1.016\n",
            "epoch: [12/30] -> loss: 0.884\n",
            "epoch: [13/30] -> loss: 0.907\n",
            "epoch: [14/30] -> loss: 0.864\n",
            "epoch: [15/30] -> loss: 0.877\n",
            "epoch: [16/30] -> loss: 0.878\n",
            "epoch: [17/30] -> loss: 0.930\n",
            "epoch: [18/30] -> loss: 0.954\n",
            "epoch: [19/30] -> loss: 0.923\n",
            "epoch: [20/30] -> loss: 0.914\n",
            "epoch: [21/30] -> loss: 0.948\n",
            "epoch: [22/30] -> loss: 0.914\n",
            "epoch: [23/30] -> loss: 0.902\n",
            "epoch: [24/30] -> loss: 0.922\n",
            "epoch: [25/30] -> loss: 0.940\n",
            "epoch: [26/30] -> loss: 0.906\n",
            "epoch: [27/30] -> loss: 1.037\n",
            "epoch: [28/30] -> loss: 0.934\n",
            "epoch: [29/30] -> loss: 0.887\n",
            "epoch: [30/30] -> loss: 0.899\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.899\n",
            "* Train accuracy: 75.88%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.385\n",
            "epoch: [2/30] -> loss: 1.305\n",
            "epoch: [3/30] -> loss: 1.341\n",
            "epoch: [4/30] -> loss: 1.328\n",
            "epoch: [5/30] -> loss: 1.335\n",
            "epoch: [6/30] -> loss: 1.319\n",
            "epoch: [7/30] -> loss: 1.337\n",
            "epoch: [8/30] -> loss: 1.338\n",
            "epoch: [9/30] -> loss: 1.328\n",
            "epoch: [10/30] -> loss: 1.352\n",
            "epoch: [11/30] -> loss: 1.340\n",
            "epoch: [12/30] -> loss: 1.321\n",
            "epoch: [13/30] -> loss: 1.306\n",
            "epoch: [14/30] -> loss: 1.313\n",
            "epoch: [15/30] -> loss: 1.324\n",
            "epoch: [16/30] -> loss: 1.341\n",
            "epoch: [17/30] -> loss: 1.325\n",
            "epoch: [18/30] -> loss: 1.328\n",
            "epoch: [19/30] -> loss: 1.331\n",
            "epoch: [20/30] -> loss: 1.330\n",
            "epoch: [21/30] -> loss: 1.331\n",
            "epoch: [22/30] -> loss: 1.306\n",
            "epoch: [23/30] -> loss: 1.337\n",
            "epoch: [24/30] -> loss: 1.312\n",
            "epoch: [25/30] -> loss: 1.331\n",
            "epoch: [26/30] -> loss: 1.322\n",
            "epoch: [27/30] -> loss: 1.333\n",
            "epoch: [28/30] -> loss: 1.306\n",
            "epoch: [29/30] -> loss: 1.323\n",
            "epoch: [30/30] -> loss: 1.323\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.323\n",
            "* Train accuracy: 61.09%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.980\n",
            "epoch: [2/30] -> loss: 0.997\n",
            "epoch: [3/30] -> loss: 0.953\n",
            "epoch: [4/30] -> loss: 0.946\n",
            "epoch: [5/30] -> loss: 0.952\n",
            "epoch: [6/30] -> loss: 0.966\n",
            "epoch: [7/30] -> loss: 0.993\n",
            "epoch: [8/30] -> loss: 0.960\n",
            "epoch: [9/30] -> loss: 0.944\n",
            "epoch: [10/30] -> loss: 1.006\n",
            "epoch: [11/30] -> loss: 0.995\n",
            "epoch: [12/30] -> loss: 0.990\n",
            "epoch: [13/30] -> loss: 0.967\n",
            "epoch: [14/30] -> loss: 0.934\n",
            "epoch: [15/30] -> loss: 0.937\n",
            "epoch: [16/30] -> loss: 0.954\n",
            "epoch: [17/30] -> loss: 1.013\n",
            "epoch: [18/30] -> loss: 0.979\n",
            "epoch: [19/30] -> loss: 0.967\n",
            "epoch: [20/30] -> loss: 0.946\n",
            "epoch: [21/30] -> loss: 0.976\n",
            "epoch: [22/30] -> loss: 0.967\n",
            "epoch: [23/30] -> loss: 0.974\n",
            "epoch: [24/30] -> loss: 0.971\n",
            "epoch: [25/30] -> loss: 0.969\n",
            "epoch: [26/30] -> loss: 0.987\n",
            "epoch: [27/30] -> loss: 1.019\n",
            "epoch: [28/30] -> loss: 0.993\n",
            "epoch: [29/30] -> loss: 0.968\n",
            "epoch: [30/30] -> loss: 0.964\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.964\n",
            "* Train accuracy: 72.77%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.750\n",
            "epoch: [2/30] -> loss: 0.634\n",
            "epoch: [3/30] -> loss: 0.639\n",
            "epoch: [4/30] -> loss: 0.664\n",
            "epoch: [5/30] -> loss: 0.636\n",
            "epoch: [6/30] -> loss: 0.672\n",
            "epoch: [7/30] -> loss: 0.678\n",
            "epoch: [8/30] -> loss: 0.661\n",
            "epoch: [9/30] -> loss: 0.672\n",
            "epoch: [10/30] -> loss: 0.671\n",
            "epoch: [11/30] -> loss: 0.686\n",
            "epoch: [12/30] -> loss: 0.650\n",
            "epoch: [13/30] -> loss: 0.660\n",
            "epoch: [14/30] -> loss: 0.672\n",
            "epoch: [15/30] -> loss: 0.711\n",
            "epoch: [16/30] -> loss: 0.695\n",
            "epoch: [17/30] -> loss: 0.671\n",
            "epoch: [18/30] -> loss: 0.689\n",
            "epoch: [19/30] -> loss: 0.668\n",
            "epoch: [20/30] -> loss: 0.701\n",
            "epoch: [21/30] -> loss: 0.676\n",
            "epoch: [22/30] -> loss: 0.677\n",
            "epoch: [23/30] -> loss: 0.657\n",
            "epoch: [24/30] -> loss: 0.730\n",
            "epoch: [25/30] -> loss: 0.654\n",
            "epoch: [26/30] -> loss: 0.669\n",
            "epoch: [27/30] -> loss: 0.666\n",
            "epoch: [28/30] -> loss: 0.658\n",
            "epoch: [29/30] -> loss: 0.678\n",
            "epoch: [30/30] -> loss: 0.692\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.692\n",
            "* Train accuracy: 82.89%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.181\n",
            "epoch: [2/30] -> loss: 1.089\n",
            "epoch: [3/30] -> loss: 1.094\n",
            "epoch: [4/30] -> loss: 1.092\n",
            "epoch: [5/30] -> loss: 1.093\n",
            "epoch: [6/30] -> loss: 1.094\n",
            "epoch: [7/30] -> loss: 1.092\n",
            "epoch: [8/30] -> loss: 1.092\n",
            "epoch: [9/30] -> loss: 1.093\n",
            "epoch: [10/30] -> loss: 1.101\n",
            "epoch: [11/30] -> loss: 1.089\n",
            "epoch: [12/30] -> loss: 1.091\n",
            "epoch: [13/30] -> loss: 1.096\n",
            "epoch: [14/30] -> loss: 1.093\n",
            "epoch: [15/30] -> loss: 1.088\n",
            "epoch: [16/30] -> loss: 1.094\n",
            "epoch: [17/30] -> loss: 1.099\n",
            "epoch: [18/30] -> loss: 1.087\n",
            "epoch: [19/30] -> loss: 1.107\n",
            "epoch: [20/30] -> loss: 1.095\n",
            "epoch: [21/30] -> loss: 1.097\n",
            "epoch: [22/30] -> loss: 1.088\n",
            "epoch: [23/30] -> loss: 1.089\n",
            "epoch: [24/30] -> loss: 1.088\n",
            "epoch: [25/30] -> loss: 1.097\n",
            "epoch: [26/30] -> loss: 1.098\n",
            "epoch: [27/30] -> loss: 1.103\n",
            "epoch: [28/30] -> loss: 1.091\n",
            "epoch: [29/30] -> loss: 1.088\n",
            "epoch: [30/30] -> loss: 1.101\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.101\n",
            "* Train accuracy: 54.27%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.815\n",
            "epoch: [2/30] -> loss: 0.769\n",
            "epoch: [3/30] -> loss: 0.774\n",
            "epoch: [4/30] -> loss: 0.772\n",
            "epoch: [5/30] -> loss: 0.769\n",
            "epoch: [6/30] -> loss: 0.774\n",
            "epoch: [7/30] -> loss: 0.774\n",
            "epoch: [8/30] -> loss: 0.770\n",
            "epoch: [9/30] -> loss: 0.779\n",
            "epoch: [10/30] -> loss: 0.764\n",
            "epoch: [11/30] -> loss: 0.771\n",
            "epoch: [12/30] -> loss: 0.776\n",
            "epoch: [13/30] -> loss: 0.776\n",
            "epoch: [14/30] -> loss: 0.774\n",
            "epoch: [15/30] -> loss: 0.774\n",
            "epoch: [16/30] -> loss: 0.774\n",
            "epoch: [17/30] -> loss: 0.771\n",
            "epoch: [18/30] -> loss: 0.772\n",
            "epoch: [19/30] -> loss: 0.766\n",
            "epoch: [20/30] -> loss: 0.766\n",
            "epoch: [21/30] -> loss: 0.769\n",
            "epoch: [22/30] -> loss: 0.765\n",
            "epoch: [23/30] -> loss: 0.774\n",
            "epoch: [24/30] -> loss: 0.769\n",
            "epoch: [25/30] -> loss: 0.767\n",
            "epoch: [26/30] -> loss: 0.765\n",
            "epoch: [27/30] -> loss: 0.765\n",
            "epoch: [28/30] -> loss: 0.766\n",
            "epoch: [29/30] -> loss: 0.767\n",
            "epoch: [30/30] -> loss: 0.774\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.774\n",
            "* Train accuracy: 77.54%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.583\n",
            "epoch: [2/30] -> loss: 0.503\n",
            "epoch: [3/30] -> loss: 0.499\n",
            "epoch: [4/30] -> loss: 0.496\n",
            "epoch: [5/30] -> loss: 0.484\n",
            "epoch: [6/30] -> loss: 0.481\n",
            "epoch: [7/30] -> loss: 0.482\n",
            "epoch: [8/30] -> loss: 0.484\n",
            "epoch: [9/30] -> loss: 0.486\n",
            "epoch: [10/30] -> loss: 0.484\n",
            "epoch: [11/30] -> loss: 0.486\n",
            "epoch: [12/30] -> loss: 0.482\n",
            "epoch: [13/30] -> loss: 0.481\n",
            "epoch: [14/30] -> loss: 0.483\n",
            "epoch: [15/30] -> loss: 0.477\n",
            "epoch: [16/30] -> loss: 0.485\n",
            "epoch: [17/30] -> loss: 0.481\n",
            "epoch: [18/30] -> loss: 0.484\n",
            "epoch: [19/30] -> loss: 0.483\n",
            "epoch: [20/30] -> loss: 0.488\n",
            "epoch: [21/30] -> loss: 0.473\n",
            "epoch: [22/30] -> loss: 0.484\n",
            "epoch: [23/30] -> loss: 0.477\n",
            "epoch: [24/30] -> loss: 0.475\n",
            "epoch: [25/30] -> loss: 0.481\n",
            "epoch: [26/30] -> loss: 0.482\n",
            "epoch: [27/30] -> loss: 0.483\n",
            "epoch: [28/30] -> loss: 0.484\n",
            "epoch: [29/30] -> loss: 0.481\n",
            "epoch: [30/30] -> loss: 0.487\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.487\n",
            "* Train accuracy: 84.64%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.239\n",
            "epoch: [2/30] -> loss: 1.052\n",
            "epoch: [3/30] -> loss: 1.056\n",
            "epoch: [4/30] -> loss: 1.057\n",
            "epoch: [5/30] -> loss: 1.055\n",
            "epoch: [6/30] -> loss: 1.049\n",
            "epoch: [7/30] -> loss: 1.057\n",
            "epoch: [8/30] -> loss: 1.053\n",
            "epoch: [9/30] -> loss: 1.055\n",
            "epoch: [10/30] -> loss: 1.048\n",
            "epoch: [11/30] -> loss: 1.051\n",
            "epoch: [12/30] -> loss: 1.054\n",
            "epoch: [13/30] -> loss: 1.057\n",
            "epoch: [14/30] -> loss: 1.055\n",
            "epoch: [15/30] -> loss: 1.055\n",
            "epoch: [16/30] -> loss: 1.060\n",
            "epoch: [17/30] -> loss: 1.055\n",
            "epoch: [18/30] -> loss: 1.055\n",
            "epoch: [19/30] -> loss: 1.054\n",
            "epoch: [20/30] -> loss: 1.056\n",
            "epoch: [21/30] -> loss: 1.056\n",
            "epoch: [22/30] -> loss: 1.056\n",
            "epoch: [23/30] -> loss: 1.056\n",
            "epoch: [24/30] -> loss: 1.057\n",
            "epoch: [25/30] -> loss: 1.057\n",
            "epoch: [26/30] -> loss: 1.050\n",
            "epoch: [27/30] -> loss: 1.055\n",
            "epoch: [28/30] -> loss: 1.053\n",
            "epoch: [29/30] -> loss: 1.047\n",
            "epoch: [30/30] -> loss: 1.053\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.053\n",
            "* Train accuracy: 61.90%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.825\n",
            "epoch: [2/30] -> loss: 0.746\n",
            "epoch: [3/30] -> loss: 0.742\n",
            "epoch: [4/30] -> loss: 0.748\n",
            "epoch: [5/30] -> loss: 0.746\n",
            "epoch: [6/30] -> loss: 0.744\n",
            "epoch: [7/30] -> loss: 0.748\n",
            "epoch: [8/30] -> loss: 0.740\n",
            "epoch: [9/30] -> loss: 0.746\n",
            "epoch: [10/30] -> loss: 0.752\n",
            "epoch: [11/30] -> loss: 0.741\n",
            "epoch: [12/30] -> loss: 0.740\n",
            "epoch: [13/30] -> loss: 0.745\n",
            "epoch: [14/30] -> loss: 0.746\n",
            "epoch: [15/30] -> loss: 0.743\n",
            "epoch: [16/30] -> loss: 0.744\n",
            "epoch: [17/30] -> loss: 0.745\n",
            "epoch: [18/30] -> loss: 0.742\n",
            "epoch: [19/30] -> loss: 0.740\n",
            "epoch: [20/30] -> loss: 0.744\n",
            "epoch: [21/30] -> loss: 0.744\n",
            "epoch: [22/30] -> loss: 0.745\n",
            "epoch: [23/30] -> loss: 0.740\n",
            "epoch: [24/30] -> loss: 0.741\n",
            "epoch: [25/30] -> loss: 0.743\n",
            "epoch: [26/30] -> loss: 0.744\n",
            "epoch: [27/30] -> loss: 0.742\n",
            "epoch: [28/30] -> loss: 0.747\n",
            "epoch: [29/30] -> loss: 0.753\n",
            "epoch: [30/30] -> loss: 0.740\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.740\n",
            "* Train accuracy: 77.94%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.596\n",
            "epoch: [2/30] -> loss: 0.506\n",
            "epoch: [3/30] -> loss: 0.488\n",
            "epoch: [4/30] -> loss: 0.483\n",
            "epoch: [5/30] -> loss: 0.470\n",
            "epoch: [6/30] -> loss: 0.468\n",
            "epoch: [7/30] -> loss: 0.469\n",
            "epoch: [8/30] -> loss: 0.467\n",
            "epoch: [9/30] -> loss: 0.462\n",
            "epoch: [10/30] -> loss: 0.461\n",
            "epoch: [11/30] -> loss: 0.460\n",
            "epoch: [12/30] -> loss: 0.462\n",
            "epoch: [13/30] -> loss: 0.459\n",
            "epoch: [14/30] -> loss: 0.460\n",
            "epoch: [15/30] -> loss: 0.459\n",
            "epoch: [16/30] -> loss: 0.458\n",
            "epoch: [17/30] -> loss: 0.459\n",
            "epoch: [18/30] -> loss: 0.455\n",
            "epoch: [19/30] -> loss: 0.460\n",
            "epoch: [20/30] -> loss: 0.463\n",
            "epoch: [21/30] -> loss: 0.457\n",
            "epoch: [22/30] -> loss: 0.462\n",
            "epoch: [23/30] -> loss: 0.459\n",
            "epoch: [24/30] -> loss: 0.458\n",
            "epoch: [25/30] -> loss: 0.460\n",
            "epoch: [26/30] -> loss: 0.464\n",
            "epoch: [27/30] -> loss: 0.465\n",
            "epoch: [28/30] -> loss: 0.458\n",
            "epoch: [29/30] -> loss: 0.455\n",
            "epoch: [30/30] -> loss: 0.457\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.457\n",
            "* Train accuracy: 86.12%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.876\n",
            "epoch: [2/30] -> loss: 1.017\n",
            "epoch: [3/30] -> loss: 1.015\n",
            "epoch: [4/30] -> loss: 1.014\n",
            "epoch: [5/30] -> loss: 1.015\n",
            "epoch: [6/30] -> loss: 1.013\n",
            "epoch: [7/30] -> loss: 1.014\n",
            "epoch: [8/30] -> loss: 1.014\n",
            "epoch: [9/30] -> loss: 1.015\n",
            "epoch: [10/30] -> loss: 1.015\n",
            "epoch: [11/30] -> loss: 1.015\n",
            "epoch: [12/30] -> loss: 1.013\n",
            "epoch: [13/30] -> loss: 1.014\n",
            "epoch: [14/30] -> loss: 1.017\n",
            "epoch: [15/30] -> loss: 1.015\n",
            "epoch: [16/30] -> loss: 1.015\n",
            "epoch: [17/30] -> loss: 1.015\n",
            "epoch: [18/30] -> loss: 1.016\n",
            "epoch: [19/30] -> loss: 1.015\n",
            "epoch: [20/30] -> loss: 1.015\n",
            "epoch: [21/30] -> loss: 1.014\n",
            "epoch: [22/30] -> loss: 1.018\n",
            "epoch: [23/30] -> loss: 1.015\n",
            "epoch: [24/30] -> loss: 1.015\n",
            "epoch: [25/30] -> loss: 1.015\n",
            "epoch: [26/30] -> loss: 1.016\n",
            "epoch: [27/30] -> loss: 1.013\n",
            "epoch: [28/30] -> loss: 1.014\n",
            "epoch: [29/30] -> loss: 1.014\n",
            "epoch: [30/30] -> loss: 1.015\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.015\n",
            "* Train accuracy: 62.74%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.976\n",
            "epoch: [2/30] -> loss: 0.812\n",
            "epoch: [3/30] -> loss: 0.758\n",
            "epoch: [4/30] -> loss: 0.738\n",
            "epoch: [5/30] -> loss: 0.729\n",
            "epoch: [6/30] -> loss: 0.724\n",
            "epoch: [7/30] -> loss: 0.725\n",
            "epoch: [8/30] -> loss: 0.724\n",
            "epoch: [9/30] -> loss: 0.724\n",
            "epoch: [10/30] -> loss: 0.723\n",
            "epoch: [11/30] -> loss: 0.723\n",
            "epoch: [12/30] -> loss: 0.723\n",
            "epoch: [13/30] -> loss: 0.723\n",
            "epoch: [14/30] -> loss: 0.722\n",
            "epoch: [15/30] -> loss: 0.723\n",
            "epoch: [16/30] -> loss: 0.722\n",
            "epoch: [17/30] -> loss: 0.722\n",
            "epoch: [18/30] -> loss: 0.721\n",
            "epoch: [19/30] -> loss: 0.722\n",
            "epoch: [20/30] -> loss: 0.722\n",
            "epoch: [21/30] -> loss: 0.724\n",
            "epoch: [22/30] -> loss: 0.722\n",
            "epoch: [23/30] -> loss: 0.723\n",
            "epoch: [24/30] -> loss: 0.723\n",
            "epoch: [25/30] -> loss: 0.721\n",
            "epoch: [26/30] -> loss: 0.720\n",
            "epoch: [27/30] -> loss: 0.724\n",
            "epoch: [28/30] -> loss: 0.723\n",
            "epoch: [29/30] -> loss: 0.722\n",
            "epoch: [30/30] -> loss: 0.720\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.720\n",
            "* Train accuracy: 79.56%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.746\n",
            "epoch: [2/30] -> loss: 0.591\n",
            "epoch: [3/30] -> loss: 0.543\n",
            "epoch: [4/30] -> loss: 0.520\n",
            "epoch: [5/30] -> loss: 0.505\n",
            "epoch: [6/30] -> loss: 0.497\n",
            "epoch: [7/30] -> loss: 0.490\n",
            "epoch: [8/30] -> loss: 0.483\n",
            "epoch: [9/30] -> loss: 0.479\n",
            "epoch: [10/30] -> loss: 0.474\n",
            "epoch: [11/30] -> loss: 0.471\n",
            "epoch: [12/30] -> loss: 0.469\n",
            "epoch: [13/30] -> loss: 0.467\n",
            "epoch: [14/30] -> loss: 0.463\n",
            "epoch: [15/30] -> loss: 0.462\n",
            "epoch: [16/30] -> loss: 0.461\n",
            "epoch: [17/30] -> loss: 0.458\n",
            "epoch: [18/30] -> loss: 0.459\n",
            "epoch: [19/30] -> loss: 0.456\n",
            "epoch: [20/30] -> loss: 0.455\n",
            "epoch: [21/30] -> loss: 0.454\n",
            "epoch: [22/30] -> loss: 0.453\n",
            "epoch: [23/30] -> loss: 0.453\n",
            "epoch: [24/30] -> loss: 0.451\n",
            "epoch: [25/30] -> loss: 0.450\n",
            "epoch: [26/30] -> loss: 0.450\n",
            "epoch: [27/30] -> loss: 0.450\n",
            "epoch: [28/30] -> loss: 0.449\n",
            "epoch: [29/30] -> loss: 0.449\n",
            "epoch: [30/30] -> loss: 0.447\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.447\n",
            "* Train accuracy: 85.14%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.581\n",
            "epoch: [2/10] -> loss: 1.401\n",
            "epoch: [3/10] -> loss: 1.397\n",
            "epoch: [4/10] -> loss: 1.366\n",
            "epoch: [5/10] -> loss: 1.361\n",
            "epoch: [6/10] -> loss: 1.374\n",
            "epoch: [7/10] -> loss: 1.406\n",
            "epoch: [8/10] -> loss: 1.376\n",
            "epoch: [9/10] -> loss: 1.382\n",
            "epoch: [10/10] -> loss: 1.397\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.397\n",
            "* Train accuracy: 61.57%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.215\n",
            "epoch: [2/10] -> loss: 1.008\n",
            "epoch: [3/10] -> loss: 0.971\n",
            "epoch: [4/10] -> loss: 1.010\n",
            "epoch: [5/10] -> loss: 1.109\n",
            "epoch: [6/10] -> loss: 0.975\n",
            "epoch: [7/10] -> loss: 1.020\n",
            "epoch: [8/10] -> loss: 1.053\n",
            "epoch: [9/10] -> loss: 1.025\n",
            "epoch: [10/10] -> loss: 1.014\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.014\n",
            "* Train accuracy: 74.61%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.791\n",
            "epoch: [2/10] -> loss: 0.802\n",
            "epoch: [3/10] -> loss: 0.681\n",
            "epoch: [4/10] -> loss: 0.724\n",
            "epoch: [5/10] -> loss: 0.718\n",
            "epoch: [6/10] -> loss: 0.714\n",
            "epoch: [7/10] -> loss: 0.700\n",
            "epoch: [8/10] -> loss: 0.708\n",
            "epoch: [9/10] -> loss: 0.758\n",
            "epoch: [10/10] -> loss: 0.727\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.727\n",
            "* Train accuracy: 83.88%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.329\n",
            "epoch: [2/10] -> loss: 1.231\n",
            "epoch: [3/10] -> loss: 1.234\n",
            "epoch: [4/10] -> loss: 1.244\n",
            "epoch: [5/10] -> loss: 1.253\n",
            "epoch: [6/10] -> loss: 1.206\n",
            "epoch: [7/10] -> loss: 1.213\n",
            "epoch: [8/10] -> loss: 1.222\n",
            "epoch: [9/10] -> loss: 1.215\n",
            "epoch: [10/10] -> loss: 1.213\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.213\n",
            "* Train accuracy: 57.34%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.971\n",
            "epoch: [2/10] -> loss: 0.884\n",
            "epoch: [3/10] -> loss: 0.911\n",
            "epoch: [4/10] -> loss: 0.849\n",
            "epoch: [5/10] -> loss: 0.901\n",
            "epoch: [6/10] -> loss: 0.888\n",
            "epoch: [7/10] -> loss: 0.879\n",
            "epoch: [8/10] -> loss: 0.877\n",
            "epoch: [9/10] -> loss: 0.887\n",
            "epoch: [10/10] -> loss: 0.881\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.881\n",
            "* Train accuracy: 75.67%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.649\n",
            "epoch: [2/10] -> loss: 0.586\n",
            "epoch: [3/10] -> loss: 0.631\n",
            "epoch: [4/10] -> loss: 0.601\n",
            "epoch: [5/10] -> loss: 0.585\n",
            "epoch: [6/10] -> loss: 0.585\n",
            "epoch: [7/10] -> loss: 0.582\n",
            "epoch: [8/10] -> loss: 0.562\n",
            "epoch: [9/10] -> loss: 0.572\n",
            "epoch: [10/10] -> loss: 0.568\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.568\n",
            "* Train accuracy: 82.56%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.261\n",
            "epoch: [2/10] -> loss: 1.068\n",
            "epoch: [3/10] -> loss: 1.063\n",
            "epoch: [4/10] -> loss: 1.063\n",
            "epoch: [5/10] -> loss: 1.063\n",
            "epoch: [6/10] -> loss: 1.078\n",
            "epoch: [7/10] -> loss: 1.068\n",
            "epoch: [8/10] -> loss: 1.071\n",
            "epoch: [9/10] -> loss: 1.062\n",
            "epoch: [10/10] -> loss: 1.072\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.072\n",
            "* Train accuracy: 66.07%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.822\n",
            "epoch: [2/10] -> loss: 0.752\n",
            "epoch: [3/10] -> loss: 0.755\n",
            "epoch: [4/10] -> loss: 0.751\n",
            "epoch: [5/10] -> loss: 0.762\n",
            "epoch: [6/10] -> loss: 0.755\n",
            "epoch: [7/10] -> loss: 0.750\n",
            "epoch: [8/10] -> loss: 0.752\n",
            "epoch: [9/10] -> loss: 0.753\n",
            "epoch: [10/10] -> loss: 0.744\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.744\n",
            "* Train accuracy: 77.83%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.581\n",
            "epoch: [2/10] -> loss: 0.494\n",
            "epoch: [3/10] -> loss: 0.483\n",
            "epoch: [4/10] -> loss: 0.479\n",
            "epoch: [5/10] -> loss: 0.468\n",
            "epoch: [6/10] -> loss: 0.467\n",
            "epoch: [7/10] -> loss: 0.471\n",
            "epoch: [8/10] -> loss: 0.468\n",
            "epoch: [9/10] -> loss: 0.467\n",
            "epoch: [10/10] -> loss: 0.464\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.464\n",
            "* Train accuracy: 85.09%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.371\n",
            "epoch: [2/10] -> loss: 1.040\n",
            "epoch: [3/10] -> loss: 1.045\n",
            "epoch: [4/10] -> loss: 1.044\n",
            "epoch: [5/10] -> loss: 1.037\n",
            "epoch: [6/10] -> loss: 1.042\n",
            "epoch: [7/10] -> loss: 1.043\n",
            "epoch: [8/10] -> loss: 1.041\n",
            "epoch: [9/10] -> loss: 1.036\n",
            "epoch: [10/10] -> loss: 1.045\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.045\n",
            "* Train accuracy: 60.93%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.872\n",
            "epoch: [2/10] -> loss: 0.742\n",
            "epoch: [3/10] -> loss: 0.737\n",
            "epoch: [4/10] -> loss: 0.740\n",
            "epoch: [5/10] -> loss: 0.733\n",
            "epoch: [6/10] -> loss: 0.736\n",
            "epoch: [7/10] -> loss: 0.737\n",
            "epoch: [8/10] -> loss: 0.737\n",
            "epoch: [9/10] -> loss: 0.736\n",
            "epoch: [10/10] -> loss: 0.736\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.736\n",
            "* Train accuracy: 79.57%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.623\n",
            "epoch: [2/10] -> loss: 0.513\n",
            "epoch: [3/10] -> loss: 0.493\n",
            "epoch: [4/10] -> loss: 0.477\n",
            "epoch: [5/10] -> loss: 0.471\n",
            "epoch: [6/10] -> loss: 0.469\n",
            "epoch: [7/10] -> loss: 0.462\n",
            "epoch: [8/10] -> loss: 0.461\n",
            "epoch: [9/10] -> loss: 0.460\n",
            "epoch: [10/10] -> loss: 0.460\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.460\n",
            "* Train accuracy: 84.61%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 2.528\n",
            "epoch: [2/10] -> loss: 1.075\n",
            "epoch: [3/10] -> loss: 1.015\n",
            "epoch: [4/10] -> loss: 1.015\n",
            "epoch: [5/10] -> loss: 1.013\n",
            "epoch: [6/10] -> loss: 1.016\n",
            "epoch: [7/10] -> loss: 1.013\n",
            "epoch: [8/10] -> loss: 1.014\n",
            "epoch: [9/10] -> loss: 1.014\n",
            "epoch: [10/10] -> loss: 1.015\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.015\n",
            "* Train accuracy: 62.62%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.025\n",
            "epoch: [2/10] -> loss: 0.863\n",
            "epoch: [3/10] -> loss: 0.796\n",
            "epoch: [4/10] -> loss: 0.761\n",
            "epoch: [5/10] -> loss: 0.742\n",
            "epoch: [6/10] -> loss: 0.732\n",
            "epoch: [7/10] -> loss: 0.726\n",
            "epoch: [8/10] -> loss: 0.725\n",
            "epoch: [9/10] -> loss: 0.723\n",
            "epoch: [10/10] -> loss: 0.721\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.721\n",
            "* Train accuracy: 80.26%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.781\n",
            "epoch: [2/10] -> loss: 0.635\n",
            "epoch: [3/10] -> loss: 0.576\n",
            "epoch: [4/10] -> loss: 0.544\n",
            "epoch: [5/10] -> loss: 0.526\n",
            "epoch: [6/10] -> loss: 0.512\n",
            "epoch: [7/10] -> loss: 0.501\n",
            "epoch: [8/10] -> loss: 0.495\n",
            "epoch: [9/10] -> loss: 0.489\n",
            "epoch: [10/10] -> loss: 0.484\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.484\n",
            "* Train accuracy: 82.80%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.619\n",
            "epoch: [2/20] -> loss: 1.408\n",
            "epoch: [3/20] -> loss: 1.385\n",
            "epoch: [4/20] -> loss: 1.435\n",
            "epoch: [5/20] -> loss: 1.376\n",
            "epoch: [6/20] -> loss: 1.382\n",
            "epoch: [7/20] -> loss: 1.375\n",
            "epoch: [8/20] -> loss: 1.402\n",
            "epoch: [9/20] -> loss: 1.440\n",
            "epoch: [10/20] -> loss: 1.367\n",
            "epoch: [11/20] -> loss: 1.386\n",
            "epoch: [12/20] -> loss: 1.355\n",
            "epoch: [13/20] -> loss: 1.346\n",
            "epoch: [14/20] -> loss: 1.393\n",
            "epoch: [15/20] -> loss: 1.407\n",
            "epoch: [16/20] -> loss: 1.356\n",
            "epoch: [17/20] -> loss: 1.340\n",
            "epoch: [18/20] -> loss: 1.365\n",
            "epoch: [19/20] -> loss: 1.362\n",
            "epoch: [20/20] -> loss: 1.381\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.381\n",
            "* Train accuracy: 60.71%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.136\n",
            "epoch: [2/20] -> loss: 1.036\n",
            "epoch: [3/20] -> loss: 1.094\n",
            "epoch: [4/20] -> loss: 0.986\n",
            "epoch: [5/20] -> loss: 1.096\n",
            "epoch: [6/20] -> loss: 0.981\n",
            "epoch: [7/20] -> loss: 1.056\n",
            "epoch: [8/20] -> loss: 1.011\n",
            "epoch: [9/20] -> loss: 1.094\n",
            "epoch: [10/20] -> loss: 1.072\n",
            "epoch: [11/20] -> loss: 1.045\n",
            "epoch: [12/20] -> loss: 1.027\n",
            "epoch: [13/20] -> loss: 1.006\n",
            "epoch: [14/20] -> loss: 1.021\n",
            "epoch: [15/20] -> loss: 1.023\n",
            "epoch: [16/20] -> loss: 1.023\n",
            "epoch: [17/20] -> loss: 1.051\n",
            "epoch: [18/20] -> loss: 1.031\n",
            "epoch: [19/20] -> loss: 1.027\n",
            "epoch: [20/20] -> loss: 1.000\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.000\n",
            "* Train accuracy: 72.03%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.777\n",
            "epoch: [2/20] -> loss: 0.734\n",
            "epoch: [3/20] -> loss: 0.713\n",
            "epoch: [4/20] -> loss: 0.763\n",
            "epoch: [5/20] -> loss: 0.740\n",
            "epoch: [6/20] -> loss: 0.689\n",
            "epoch: [7/20] -> loss: 0.735\n",
            "epoch: [8/20] -> loss: 0.747\n",
            "epoch: [9/20] -> loss: 0.706\n",
            "epoch: [10/20] -> loss: 0.746\n",
            "epoch: [11/20] -> loss: 0.726\n",
            "epoch: [12/20] -> loss: 0.712\n",
            "epoch: [13/20] -> loss: 0.725\n",
            "epoch: [14/20] -> loss: 0.687\n",
            "epoch: [15/20] -> loss: 0.719\n",
            "epoch: [16/20] -> loss: 0.712\n",
            "epoch: [17/20] -> loss: 0.722\n",
            "epoch: [18/20] -> loss: 0.772\n",
            "epoch: [19/20] -> loss: 0.770\n",
            "epoch: [20/20] -> loss: 0.741\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.741\n",
            "* Train accuracy: 81.93%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.358\n",
            "epoch: [2/20] -> loss: 1.206\n",
            "epoch: [3/20] -> loss: 1.250\n",
            "epoch: [4/20] -> loss: 1.208\n",
            "epoch: [5/20] -> loss: 1.248\n",
            "epoch: [6/20] -> loss: 1.213\n",
            "epoch: [7/20] -> loss: 1.205\n",
            "epoch: [8/20] -> loss: 1.225\n",
            "epoch: [9/20] -> loss: 1.201\n",
            "epoch: [10/20] -> loss: 1.202\n",
            "epoch: [11/20] -> loss: 1.202\n",
            "epoch: [12/20] -> loss: 1.215\n",
            "epoch: [13/20] -> loss: 1.226\n",
            "epoch: [14/20] -> loss: 1.226\n",
            "epoch: [15/20] -> loss: 1.216\n",
            "epoch: [16/20] -> loss: 1.241\n",
            "epoch: [17/20] -> loss: 1.230\n",
            "epoch: [18/20] -> loss: 1.223\n",
            "epoch: [19/20] -> loss: 1.230\n",
            "epoch: [20/20] -> loss: 1.224\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.224\n",
            "* Train accuracy: 53.48%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.917\n",
            "epoch: [2/20] -> loss: 0.915\n",
            "epoch: [3/20] -> loss: 0.873\n",
            "epoch: [4/20] -> loss: 0.869\n",
            "epoch: [5/20] -> loss: 0.868\n",
            "epoch: [6/20] -> loss: 0.860\n",
            "epoch: [7/20] -> loss: 0.910\n",
            "epoch: [8/20] -> loss: 0.855\n",
            "epoch: [9/20] -> loss: 0.903\n",
            "epoch: [10/20] -> loss: 0.897\n",
            "epoch: [11/20] -> loss: 0.869\n",
            "epoch: [12/20] -> loss: 0.876\n",
            "epoch: [13/20] -> loss: 0.871\n",
            "epoch: [14/20] -> loss: 0.921\n",
            "epoch: [15/20] -> loss: 0.891\n",
            "epoch: [16/20] -> loss: 0.838\n",
            "epoch: [17/20] -> loss: 0.884\n",
            "epoch: [18/20] -> loss: 0.918\n",
            "epoch: [19/20] -> loss: 0.891\n",
            "epoch: [20/20] -> loss: 0.857\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.857\n",
            "* Train accuracy: 70.33%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.613\n",
            "epoch: [2/20] -> loss: 0.597\n",
            "epoch: [3/20] -> loss: 0.622\n",
            "epoch: [4/20] -> loss: 0.584\n",
            "epoch: [5/20] -> loss: 0.583\n",
            "epoch: [6/20] -> loss: 0.571\n",
            "epoch: [7/20] -> loss: 0.605\n",
            "epoch: [8/20] -> loss: 0.566\n",
            "epoch: [9/20] -> loss: 0.600\n",
            "epoch: [10/20] -> loss: 0.600\n",
            "epoch: [11/20] -> loss: 0.595\n",
            "epoch: [12/20] -> loss: 0.586\n",
            "epoch: [13/20] -> loss: 0.597\n",
            "epoch: [14/20] -> loss: 0.591\n",
            "epoch: [15/20] -> loss: 0.573\n",
            "epoch: [16/20] -> loss: 0.590\n",
            "epoch: [17/20] -> loss: 0.593\n",
            "epoch: [18/20] -> loss: 0.574\n",
            "epoch: [19/20] -> loss: 0.568\n",
            "epoch: [20/20] -> loss: 0.565\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.565\n",
            "* Train accuracy: 78.89%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.255\n",
            "epoch: [2/20] -> loss: 1.076\n",
            "epoch: [3/20] -> loss: 1.064\n",
            "epoch: [4/20] -> loss: 1.067\n",
            "epoch: [5/20] -> loss: 1.070\n",
            "epoch: [6/20] -> loss: 1.070\n",
            "epoch: [7/20] -> loss: 1.065\n",
            "epoch: [8/20] -> loss: 1.068\n",
            "epoch: [9/20] -> loss: 1.070\n",
            "epoch: [10/20] -> loss: 1.070\n",
            "epoch: [11/20] -> loss: 1.061\n",
            "epoch: [12/20] -> loss: 1.068\n",
            "epoch: [13/20] -> loss: 1.067\n",
            "epoch: [14/20] -> loss: 1.070\n",
            "epoch: [15/20] -> loss: 1.067\n",
            "epoch: [16/20] -> loss: 1.072\n",
            "epoch: [17/20] -> loss: 1.074\n",
            "epoch: [18/20] -> loss: 1.075\n",
            "epoch: [19/20] -> loss: 1.073\n",
            "epoch: [20/20] -> loss: 1.068\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.068\n",
            "* Train accuracy: 64.33%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.830\n",
            "epoch: [2/20] -> loss: 0.758\n",
            "epoch: [3/20] -> loss: 0.757\n",
            "epoch: [4/20] -> loss: 0.755\n",
            "epoch: [5/20] -> loss: 0.752\n",
            "epoch: [6/20] -> loss: 0.762\n",
            "epoch: [7/20] -> loss: 0.759\n",
            "epoch: [8/20] -> loss: 0.753\n",
            "epoch: [9/20] -> loss: 0.753\n",
            "epoch: [10/20] -> loss: 0.747\n",
            "epoch: [11/20] -> loss: 0.749\n",
            "epoch: [12/20] -> loss: 0.751\n",
            "epoch: [13/20] -> loss: 0.755\n",
            "epoch: [14/20] -> loss: 0.755\n",
            "epoch: [15/20] -> loss: 0.754\n",
            "epoch: [16/20] -> loss: 0.745\n",
            "epoch: [17/20] -> loss: 0.745\n",
            "epoch: [18/20] -> loss: 0.748\n",
            "epoch: [19/20] -> loss: 0.757\n",
            "epoch: [20/20] -> loss: 0.753\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.753\n",
            "* Train accuracy: 78.86%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.588\n",
            "epoch: [2/20] -> loss: 0.495\n",
            "epoch: [3/20] -> loss: 0.490\n",
            "epoch: [4/20] -> loss: 0.477\n",
            "epoch: [5/20] -> loss: 0.469\n",
            "epoch: [6/20] -> loss: 0.469\n",
            "epoch: [7/20] -> loss: 0.472\n",
            "epoch: [8/20] -> loss: 0.467\n",
            "epoch: [9/20] -> loss: 0.467\n",
            "epoch: [10/20] -> loss: 0.466\n",
            "epoch: [11/20] -> loss: 0.468\n",
            "epoch: [12/20] -> loss: 0.466\n",
            "epoch: [13/20] -> loss: 0.469\n",
            "epoch: [14/20] -> loss: 0.463\n",
            "epoch: [15/20] -> loss: 0.466\n",
            "epoch: [16/20] -> loss: 0.471\n",
            "epoch: [17/20] -> loss: 0.465\n",
            "epoch: [18/20] -> loss: 0.465\n",
            "epoch: [19/20] -> loss: 0.462\n",
            "epoch: [20/20] -> loss: 0.471\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.471\n",
            "* Train accuracy: 85.89%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.372\n",
            "epoch: [2/20] -> loss: 1.042\n",
            "epoch: [3/20] -> loss: 1.038\n",
            "epoch: [4/20] -> loss: 1.041\n",
            "epoch: [5/20] -> loss: 1.043\n",
            "epoch: [6/20] -> loss: 1.039\n",
            "epoch: [7/20] -> loss: 1.039\n",
            "epoch: [8/20] -> loss: 1.044\n",
            "epoch: [9/20] -> loss: 1.037\n",
            "epoch: [10/20] -> loss: 1.043\n",
            "epoch: [11/20] -> loss: 1.039\n",
            "epoch: [12/20] -> loss: 1.041\n",
            "epoch: [13/20] -> loss: 1.044\n",
            "epoch: [14/20] -> loss: 1.039\n",
            "epoch: [15/20] -> loss: 1.042\n",
            "epoch: [16/20] -> loss: 1.048\n",
            "epoch: [17/20] -> loss: 1.044\n",
            "epoch: [18/20] -> loss: 1.042\n",
            "epoch: [19/20] -> loss: 1.037\n",
            "epoch: [20/20] -> loss: 1.043\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.043\n",
            "* Train accuracy: 58.51%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.853\n",
            "epoch: [2/20] -> loss: 0.742\n",
            "epoch: [3/20] -> loss: 0.741\n",
            "epoch: [4/20] -> loss: 0.733\n",
            "epoch: [5/20] -> loss: 0.736\n",
            "epoch: [6/20] -> loss: 0.737\n",
            "epoch: [7/20] -> loss: 0.734\n",
            "epoch: [8/20] -> loss: 0.735\n",
            "epoch: [9/20] -> loss: 0.731\n",
            "epoch: [10/20] -> loss: 0.734\n",
            "epoch: [11/20] -> loss: 0.736\n",
            "epoch: [12/20] -> loss: 0.733\n",
            "epoch: [13/20] -> loss: 0.735\n",
            "epoch: [14/20] -> loss: 0.732\n",
            "epoch: [15/20] -> loss: 0.738\n",
            "epoch: [16/20] -> loss: 0.734\n",
            "epoch: [17/20] -> loss: 0.732\n",
            "epoch: [18/20] -> loss: 0.731\n",
            "epoch: [19/20] -> loss: 0.733\n",
            "epoch: [20/20] -> loss: 0.734\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.734\n",
            "* Train accuracy: 79.61%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.628\n",
            "epoch: [2/20] -> loss: 0.514\n",
            "epoch: [3/20] -> loss: 0.491\n",
            "epoch: [4/20] -> loss: 0.481\n",
            "epoch: [5/20] -> loss: 0.472\n",
            "epoch: [6/20] -> loss: 0.464\n",
            "epoch: [7/20] -> loss: 0.463\n",
            "epoch: [8/20] -> loss: 0.460\n",
            "epoch: [9/20] -> loss: 0.458\n",
            "epoch: [10/20] -> loss: 0.457\n",
            "epoch: [11/20] -> loss: 0.459\n",
            "epoch: [12/20] -> loss: 0.456\n",
            "epoch: [13/20] -> loss: 0.454\n",
            "epoch: [14/20] -> loss: 0.452\n",
            "epoch: [15/20] -> loss: 0.452\n",
            "epoch: [16/20] -> loss: 0.453\n",
            "epoch: [17/20] -> loss: 0.451\n",
            "epoch: [18/20] -> loss: 0.453\n",
            "epoch: [19/20] -> loss: 0.450\n",
            "epoch: [20/20] -> loss: 0.452\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.452\n",
            "* Train accuracy: 85.21%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 2.513\n",
            "epoch: [2/20] -> loss: 1.079\n",
            "epoch: [3/20] -> loss: 1.015\n",
            "epoch: [4/20] -> loss: 1.014\n",
            "epoch: [5/20] -> loss: 1.014\n",
            "epoch: [6/20] -> loss: 1.013\n",
            "epoch: [7/20] -> loss: 1.015\n",
            "epoch: [8/20] -> loss: 1.015\n",
            "epoch: [9/20] -> loss: 1.015\n",
            "epoch: [10/20] -> loss: 1.015\n",
            "epoch: [11/20] -> loss: 1.014\n",
            "epoch: [12/20] -> loss: 1.014\n",
            "epoch: [13/20] -> loss: 1.014\n",
            "epoch: [14/20] -> loss: 1.015\n",
            "epoch: [15/20] -> loss: 1.014\n",
            "epoch: [16/20] -> loss: 1.013\n",
            "epoch: [17/20] -> loss: 1.014\n",
            "epoch: [18/20] -> loss: 1.014\n",
            "epoch: [19/20] -> loss: 1.014\n",
            "epoch: [20/20] -> loss: 1.014\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.014\n",
            "* Train accuracy: 61.93%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.043\n",
            "epoch: [2/20] -> loss: 0.870\n",
            "epoch: [3/20] -> loss: 0.801\n",
            "epoch: [4/20] -> loss: 0.765\n",
            "epoch: [5/20] -> loss: 0.744\n",
            "epoch: [6/20] -> loss: 0.734\n",
            "epoch: [7/20] -> loss: 0.727\n",
            "epoch: [8/20] -> loss: 0.726\n",
            "epoch: [9/20] -> loss: 0.724\n",
            "epoch: [10/20] -> loss: 0.723\n",
            "epoch: [11/20] -> loss: 0.722\n",
            "epoch: [12/20] -> loss: 0.722\n",
            "epoch: [13/20] -> loss: 0.723\n",
            "epoch: [14/20] -> loss: 0.722\n",
            "epoch: [15/20] -> loss: 0.720\n",
            "epoch: [16/20] -> loss: 0.721\n",
            "epoch: [17/20] -> loss: 0.722\n",
            "epoch: [18/20] -> loss: 0.722\n",
            "epoch: [19/20] -> loss: 0.720\n",
            "epoch: [20/20] -> loss: 0.721\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.721\n",
            "* Train accuracy: 79.50%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.786\n",
            "epoch: [2/20] -> loss: 0.637\n",
            "epoch: [3/20] -> loss: 0.576\n",
            "epoch: [4/20] -> loss: 0.545\n",
            "epoch: [5/20] -> loss: 0.526\n",
            "epoch: [6/20] -> loss: 0.513\n",
            "epoch: [7/20] -> loss: 0.504\n",
            "epoch: [8/20] -> loss: 0.496\n",
            "epoch: [9/20] -> loss: 0.490\n",
            "epoch: [10/20] -> loss: 0.486\n",
            "epoch: [11/20] -> loss: 0.482\n",
            "epoch: [12/20] -> loss: 0.478\n",
            "epoch: [13/20] -> loss: 0.475\n",
            "epoch: [14/20] -> loss: 0.473\n",
            "epoch: [15/20] -> loss: 0.470\n",
            "epoch: [16/20] -> loss: 0.467\n",
            "epoch: [17/20] -> loss: 0.467\n",
            "epoch: [18/20] -> loss: 0.465\n",
            "epoch: [19/20] -> loss: 0.463\n",
            "epoch: [20/20] -> loss: 0.463\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.463\n",
            "* Train accuracy: 83.96%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.580\n",
            "epoch: [2/30] -> loss: 1.434\n",
            "epoch: [3/30] -> loss: 1.335\n",
            "epoch: [4/30] -> loss: 1.387\n",
            "epoch: [5/30] -> loss: 1.363\n",
            "epoch: [6/30] -> loss: 1.424\n",
            "epoch: [7/30] -> loss: 1.369\n",
            "epoch: [8/30] -> loss: 1.415\n",
            "epoch: [9/30] -> loss: 1.391\n",
            "epoch: [10/30] -> loss: 1.380\n",
            "epoch: [11/30] -> loss: 1.348\n",
            "epoch: [12/30] -> loss: 1.348\n",
            "epoch: [13/30] -> loss: 1.377\n",
            "epoch: [14/30] -> loss: 1.353\n",
            "epoch: [15/30] -> loss: 1.430\n",
            "epoch: [16/30] -> loss: 1.372\n",
            "epoch: [17/30] -> loss: 1.341\n",
            "epoch: [18/30] -> loss: 1.378\n",
            "epoch: [19/30] -> loss: 1.336\n",
            "epoch: [20/30] -> loss: 1.437\n",
            "epoch: [21/30] -> loss: 1.394\n",
            "epoch: [22/30] -> loss: 1.395\n",
            "epoch: [23/30] -> loss: 1.393\n",
            "epoch: [24/30] -> loss: 1.387\n",
            "epoch: [25/30] -> loss: 1.406\n",
            "epoch: [26/30] -> loss: 1.409\n",
            "epoch: [27/30] -> loss: 1.474\n",
            "epoch: [28/30] -> loss: 1.445\n",
            "epoch: [29/30] -> loss: 1.364\n",
            "epoch: [30/30] -> loss: 1.381\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.381\n",
            "* Train accuracy: 61.66%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.102\n",
            "epoch: [2/30] -> loss: 1.060\n",
            "epoch: [3/30] -> loss: 0.997\n",
            "epoch: [4/30] -> loss: 1.006\n",
            "epoch: [5/30] -> loss: 1.033\n",
            "epoch: [6/30] -> loss: 1.018\n",
            "epoch: [7/30] -> loss: 1.052\n",
            "epoch: [8/30] -> loss: 1.044\n",
            "epoch: [9/30] -> loss: 1.158\n",
            "epoch: [10/30] -> loss: 0.983\n",
            "epoch: [11/30] -> loss: 1.040\n",
            "epoch: [12/30] -> loss: 1.011\n",
            "epoch: [13/30] -> loss: 1.008\n",
            "epoch: [14/30] -> loss: 1.058\n",
            "epoch: [15/30] -> loss: 1.016\n",
            "epoch: [16/30] -> loss: 1.057\n",
            "epoch: [17/30] -> loss: 1.019\n",
            "epoch: [18/30] -> loss: 1.072\n",
            "epoch: [19/30] -> loss: 1.030\n",
            "epoch: [20/30] -> loss: 1.041\n",
            "epoch: [21/30] -> loss: 1.052\n",
            "epoch: [22/30] -> loss: 1.037\n",
            "epoch: [23/30] -> loss: 1.026\n",
            "epoch: [24/30] -> loss: 1.058\n",
            "epoch: [25/30] -> loss: 1.011\n",
            "epoch: [26/30] -> loss: 1.040\n",
            "epoch: [27/30] -> loss: 1.056\n",
            "epoch: [28/30] -> loss: 0.999\n",
            "epoch: [29/30] -> loss: 1.050\n",
            "epoch: [30/30] -> loss: 0.979\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.979\n",
            "* Train accuracy: 74.74%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.785\n",
            "epoch: [2/30] -> loss: 0.710\n",
            "epoch: [3/30] -> loss: 0.735\n",
            "epoch: [4/30] -> loss: 0.793\n",
            "epoch: [5/30] -> loss: 0.703\n",
            "epoch: [6/30] -> loss: 0.687\n",
            "epoch: [7/30] -> loss: 0.714\n",
            "epoch: [8/30] -> loss: 0.734\n",
            "epoch: [9/30] -> loss: 0.685\n",
            "epoch: [10/30] -> loss: 0.733\n",
            "epoch: [11/30] -> loss: 0.797\n",
            "epoch: [12/30] -> loss: 0.789\n",
            "epoch: [13/30] -> loss: 0.740\n",
            "epoch: [14/30] -> loss: 0.709\n",
            "epoch: [15/30] -> loss: 0.717\n",
            "epoch: [16/30] -> loss: 0.732\n",
            "epoch: [17/30] -> loss: 0.724\n",
            "epoch: [18/30] -> loss: 0.748\n",
            "epoch: [19/30] -> loss: 0.707\n",
            "epoch: [20/30] -> loss: 0.706\n",
            "epoch: [21/30] -> loss: 0.744\n",
            "epoch: [22/30] -> loss: 0.691\n",
            "epoch: [23/30] -> loss: 0.709\n",
            "epoch: [24/30] -> loss: 0.726\n",
            "epoch: [25/30] -> loss: 0.706\n",
            "epoch: [26/30] -> loss: 0.806\n",
            "epoch: [27/30] -> loss: 0.704\n",
            "epoch: [28/30] -> loss: 0.722\n",
            "epoch: [29/30] -> loss: 0.717\n",
            "epoch: [30/30] -> loss: 0.744\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.744\n",
            "* Train accuracy: 81.03%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.331\n",
            "epoch: [2/30] -> loss: 1.225\n",
            "epoch: [3/30] -> loss: 1.230\n",
            "epoch: [4/30] -> loss: 1.208\n",
            "epoch: [5/30] -> loss: 1.209\n",
            "epoch: [6/30] -> loss: 1.231\n",
            "epoch: [7/30] -> loss: 1.303\n",
            "epoch: [8/30] -> loss: 1.218\n",
            "epoch: [9/30] -> loss: 1.216\n",
            "epoch: [10/30] -> loss: 1.213\n",
            "epoch: [11/30] -> loss: 1.238\n",
            "epoch: [12/30] -> loss: 1.207\n",
            "epoch: [13/30] -> loss: 1.244\n",
            "epoch: [14/30] -> loss: 1.219\n",
            "epoch: [15/30] -> loss: 1.230\n",
            "epoch: [16/30] -> loss: 1.237\n",
            "epoch: [17/30] -> loss: 1.218\n",
            "epoch: [18/30] -> loss: 1.260\n",
            "epoch: [19/30] -> loss: 1.235\n",
            "epoch: [20/30] -> loss: 1.227\n",
            "epoch: [21/30] -> loss: 1.221\n",
            "epoch: [22/30] -> loss: 1.220\n",
            "epoch: [23/30] -> loss: 1.293\n",
            "epoch: [24/30] -> loss: 1.205\n",
            "epoch: [25/30] -> loss: 1.201\n",
            "epoch: [26/30] -> loss: 1.215\n",
            "epoch: [27/30] -> loss: 1.267\n",
            "epoch: [28/30] -> loss: 1.184\n",
            "epoch: [29/30] -> loss: 1.237\n",
            "epoch: [30/30] -> loss: 1.200\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.200\n",
            "* Train accuracy: 61.92%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.894\n",
            "epoch: [2/30] -> loss: 0.886\n",
            "epoch: [3/30] -> loss: 0.864\n",
            "epoch: [4/30] -> loss: 0.867\n",
            "epoch: [5/30] -> loss: 0.859\n",
            "epoch: [6/30] -> loss: 0.917\n",
            "epoch: [7/30] -> loss: 0.859\n",
            "epoch: [8/30] -> loss: 0.878\n",
            "epoch: [9/30] -> loss: 0.870\n",
            "epoch: [10/30] -> loss: 0.854\n",
            "epoch: [11/30] -> loss: 0.872\n",
            "epoch: [12/30] -> loss: 0.897\n",
            "epoch: [13/30] -> loss: 0.890\n",
            "epoch: [14/30] -> loss: 0.884\n",
            "epoch: [15/30] -> loss: 0.860\n",
            "epoch: [16/30] -> loss: 0.881\n",
            "epoch: [17/30] -> loss: 0.892\n",
            "epoch: [18/30] -> loss: 0.870\n",
            "epoch: [19/30] -> loss: 0.910\n",
            "epoch: [20/30] -> loss: 0.887\n",
            "epoch: [21/30] -> loss: 0.915\n",
            "epoch: [22/30] -> loss: 0.891\n",
            "epoch: [23/30] -> loss: 0.853\n",
            "epoch: [24/30] -> loss: 0.870\n",
            "epoch: [25/30] -> loss: 0.882\n",
            "epoch: [26/30] -> loss: 0.888\n",
            "epoch: [27/30] -> loss: 0.874\n",
            "epoch: [28/30] -> loss: 0.875\n",
            "epoch: [29/30] -> loss: 0.841\n",
            "epoch: [30/30] -> loss: 0.881\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.881\n",
            "* Train accuracy: 73.71%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.637\n",
            "epoch: [2/30] -> loss: 0.580\n",
            "epoch: [3/30] -> loss: 0.545\n",
            "epoch: [4/30] -> loss: 0.565\n",
            "epoch: [5/30] -> loss: 0.584\n",
            "epoch: [6/30] -> loss: 0.565\n",
            "epoch: [7/30] -> loss: 0.580\n",
            "epoch: [8/30] -> loss: 0.583\n",
            "epoch: [9/30] -> loss: 0.588\n",
            "epoch: [10/30] -> loss: 0.590\n",
            "epoch: [11/30] -> loss: 0.595\n",
            "epoch: [12/30] -> loss: 0.566\n",
            "epoch: [13/30] -> loss: 0.585\n",
            "epoch: [14/30] -> loss: 0.603\n",
            "epoch: [15/30] -> loss: 0.568\n",
            "epoch: [16/30] -> loss: 0.600\n",
            "epoch: [17/30] -> loss: 0.580\n",
            "epoch: [18/30] -> loss: 0.603\n",
            "epoch: [19/30] -> loss: 0.623\n",
            "epoch: [20/30] -> loss: 0.590\n",
            "epoch: [21/30] -> loss: 0.597\n",
            "epoch: [22/30] -> loss: 0.597\n",
            "epoch: [23/30] -> loss: 0.575\n",
            "epoch: [24/30] -> loss: 0.545\n",
            "epoch: [25/30] -> loss: 0.576\n",
            "epoch: [26/30] -> loss: 0.624\n",
            "epoch: [27/30] -> loss: 0.615\n",
            "epoch: [28/30] -> loss: 0.601\n",
            "epoch: [29/30] -> loss: 0.563\n",
            "epoch: [30/30] -> loss: 0.571\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.571\n",
            "* Train accuracy: 82.04%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.263\n",
            "epoch: [2/30] -> loss: 1.070\n",
            "epoch: [3/30] -> loss: 1.067\n",
            "epoch: [4/30] -> loss: 1.068\n",
            "epoch: [5/30] -> loss: 1.068\n",
            "epoch: [6/30] -> loss: 1.064\n",
            "epoch: [7/30] -> loss: 1.075\n",
            "epoch: [8/30] -> loss: 1.079\n",
            "epoch: [9/30] -> loss: 1.064\n",
            "epoch: [10/30] -> loss: 1.068\n",
            "epoch: [11/30] -> loss: 1.064\n",
            "epoch: [12/30] -> loss: 1.070\n",
            "epoch: [13/30] -> loss: 1.071\n",
            "epoch: [14/30] -> loss: 1.077\n",
            "epoch: [15/30] -> loss: 1.066\n",
            "epoch: [16/30] -> loss: 1.062\n",
            "epoch: [17/30] -> loss: 1.067\n",
            "epoch: [18/30] -> loss: 1.064\n",
            "epoch: [19/30] -> loss: 1.066\n",
            "epoch: [20/30] -> loss: 1.074\n",
            "epoch: [21/30] -> loss: 1.075\n",
            "epoch: [22/30] -> loss: 1.066\n",
            "epoch: [23/30] -> loss: 1.066\n",
            "epoch: [24/30] -> loss: 1.069\n",
            "epoch: [25/30] -> loss: 1.075\n",
            "epoch: [26/30] -> loss: 1.072\n",
            "epoch: [27/30] -> loss: 1.072\n",
            "epoch: [28/30] -> loss: 1.071\n",
            "epoch: [29/30] -> loss: 1.084\n",
            "epoch: [30/30] -> loss: 1.075\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.075\n",
            "* Train accuracy: 62.04%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.818\n",
            "epoch: [2/30] -> loss: 0.758\n",
            "epoch: [3/30] -> loss: 0.757\n",
            "epoch: [4/30] -> loss: 0.756\n",
            "epoch: [5/30] -> loss: 0.747\n",
            "epoch: [6/30] -> loss: 0.749\n",
            "epoch: [7/30] -> loss: 0.757\n",
            "epoch: [8/30] -> loss: 0.752\n",
            "epoch: [9/30] -> loss: 0.753\n",
            "epoch: [10/30] -> loss: 0.750\n",
            "epoch: [11/30] -> loss: 0.762\n",
            "epoch: [12/30] -> loss: 0.753\n",
            "epoch: [13/30] -> loss: 0.747\n",
            "epoch: [14/30] -> loss: 0.744\n",
            "epoch: [15/30] -> loss: 0.754\n",
            "epoch: [16/30] -> loss: 0.755\n",
            "epoch: [17/30] -> loss: 0.748\n",
            "epoch: [18/30] -> loss: 0.750\n",
            "epoch: [19/30] -> loss: 0.755\n",
            "epoch: [20/30] -> loss: 0.754\n",
            "epoch: [21/30] -> loss: 0.746\n",
            "epoch: [22/30] -> loss: 0.752\n",
            "epoch: [23/30] -> loss: 0.749\n",
            "epoch: [24/30] -> loss: 0.750\n",
            "epoch: [25/30] -> loss: 0.756\n",
            "epoch: [26/30] -> loss: 0.750\n",
            "epoch: [27/30] -> loss: 0.750\n",
            "epoch: [28/30] -> loss: 0.754\n",
            "epoch: [29/30] -> loss: 0.752\n",
            "epoch: [30/30] -> loss: 0.751\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.751\n",
            "* Train accuracy: 77.76%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.582\n",
            "epoch: [2/30] -> loss: 0.499\n",
            "epoch: [3/30] -> loss: 0.485\n",
            "epoch: [4/30] -> loss: 0.482\n",
            "epoch: [5/30] -> loss: 0.470\n",
            "epoch: [6/30] -> loss: 0.473\n",
            "epoch: [7/30] -> loss: 0.472\n",
            "epoch: [8/30] -> loss: 0.468\n",
            "epoch: [9/30] -> loss: 0.473\n",
            "epoch: [10/30] -> loss: 0.469\n",
            "epoch: [11/30] -> loss: 0.465\n",
            "epoch: [12/30] -> loss: 0.470\n",
            "epoch: [13/30] -> loss: 0.464\n",
            "epoch: [14/30] -> loss: 0.459\n",
            "epoch: [15/30] -> loss: 0.464\n",
            "epoch: [16/30] -> loss: 0.461\n",
            "epoch: [17/30] -> loss: 0.464\n",
            "epoch: [18/30] -> loss: 0.469\n",
            "epoch: [19/30] -> loss: 0.466\n",
            "epoch: [20/30] -> loss: 0.468\n",
            "epoch: [21/30] -> loss: 0.459\n",
            "epoch: [22/30] -> loss: 0.469\n",
            "epoch: [23/30] -> loss: 0.459\n",
            "epoch: [24/30] -> loss: 0.463\n",
            "epoch: [25/30] -> loss: 0.472\n",
            "epoch: [26/30] -> loss: 0.463\n",
            "epoch: [27/30] -> loss: 0.459\n",
            "epoch: [28/30] -> loss: 0.468\n",
            "epoch: [29/30] -> loss: 0.463\n",
            "epoch: [30/30] -> loss: 0.463\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.463\n",
            "* Train accuracy: 85.84%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.384\n",
            "epoch: [2/30] -> loss: 1.042\n",
            "epoch: [3/30] -> loss: 1.042\n",
            "epoch: [4/30] -> loss: 1.046\n",
            "epoch: [5/30] -> loss: 1.041\n",
            "epoch: [6/30] -> loss: 1.039\n",
            "epoch: [7/30] -> loss: 1.044\n",
            "epoch: [8/30] -> loss: 1.040\n",
            "epoch: [9/30] -> loss: 1.045\n",
            "epoch: [10/30] -> loss: 1.043\n",
            "epoch: [11/30] -> loss: 1.038\n",
            "epoch: [12/30] -> loss: 1.041\n",
            "epoch: [13/30] -> loss: 1.044\n",
            "epoch: [14/30] -> loss: 1.042\n",
            "epoch: [15/30] -> loss: 1.043\n",
            "epoch: [16/30] -> loss: 1.039\n",
            "epoch: [17/30] -> loss: 1.038\n",
            "epoch: [18/30] -> loss: 1.044\n",
            "epoch: [19/30] -> loss: 1.050\n",
            "epoch: [20/30] -> loss: 1.039\n",
            "epoch: [21/30] -> loss: 1.042\n",
            "epoch: [22/30] -> loss: 1.040\n",
            "epoch: [23/30] -> loss: 1.037\n",
            "epoch: [24/30] -> loss: 1.041\n",
            "epoch: [25/30] -> loss: 1.041\n",
            "epoch: [26/30] -> loss: 1.039\n",
            "epoch: [27/30] -> loss: 1.045\n",
            "epoch: [28/30] -> loss: 1.044\n",
            "epoch: [29/30] -> loss: 1.039\n",
            "epoch: [30/30] -> loss: 1.041\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.041\n",
            "* Train accuracy: 65.67%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.858\n",
            "epoch: [2/30] -> loss: 0.744\n",
            "epoch: [3/30] -> loss: 0.743\n",
            "epoch: [4/30] -> loss: 0.737\n",
            "epoch: [5/30] -> loss: 0.737\n",
            "epoch: [6/30] -> loss: 0.737\n",
            "epoch: [7/30] -> loss: 0.741\n",
            "epoch: [8/30] -> loss: 0.733\n",
            "epoch: [9/30] -> loss: 0.742\n",
            "epoch: [10/30] -> loss: 0.740\n",
            "epoch: [11/30] -> loss: 0.733\n",
            "epoch: [12/30] -> loss: 0.737\n",
            "epoch: [13/30] -> loss: 0.735\n",
            "epoch: [14/30] -> loss: 0.734\n",
            "epoch: [15/30] -> loss: 0.738\n",
            "epoch: [16/30] -> loss: 0.735\n",
            "epoch: [17/30] -> loss: 0.736\n",
            "epoch: [18/30] -> loss: 0.737\n",
            "epoch: [19/30] -> loss: 0.731\n",
            "epoch: [20/30] -> loss: 0.738\n",
            "epoch: [21/30] -> loss: 0.732\n",
            "epoch: [22/30] -> loss: 0.736\n",
            "epoch: [23/30] -> loss: 0.734\n",
            "epoch: [24/30] -> loss: 0.733\n",
            "epoch: [25/30] -> loss: 0.737\n",
            "epoch: [26/30] -> loss: 0.732\n",
            "epoch: [27/30] -> loss: 0.732\n",
            "epoch: [28/30] -> loss: 0.731\n",
            "epoch: [29/30] -> loss: 0.733\n",
            "epoch: [30/30] -> loss: 0.731\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.731\n",
            "* Train accuracy: 78.77%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.638\n",
            "epoch: [2/30] -> loss: 0.518\n",
            "epoch: [3/30] -> loss: 0.492\n",
            "epoch: [4/30] -> loss: 0.482\n",
            "epoch: [5/30] -> loss: 0.471\n",
            "epoch: [6/30] -> loss: 0.471\n",
            "epoch: [7/30] -> loss: 0.464\n",
            "epoch: [8/30] -> loss: 0.465\n",
            "epoch: [9/30] -> loss: 0.459\n",
            "epoch: [10/30] -> loss: 0.458\n",
            "epoch: [11/30] -> loss: 0.456\n",
            "epoch: [12/30] -> loss: 0.461\n",
            "epoch: [13/30] -> loss: 0.455\n",
            "epoch: [14/30] -> loss: 0.454\n",
            "epoch: [15/30] -> loss: 0.456\n",
            "epoch: [16/30] -> loss: 0.451\n",
            "epoch: [17/30] -> loss: 0.454\n",
            "epoch: [18/30] -> loss: 0.455\n",
            "epoch: [19/30] -> loss: 0.448\n",
            "epoch: [20/30] -> loss: 0.449\n",
            "epoch: [21/30] -> loss: 0.451\n",
            "epoch: [22/30] -> loss: 0.450\n",
            "epoch: [23/30] -> loss: 0.449\n",
            "epoch: [24/30] -> loss: 0.448\n",
            "epoch: [25/30] -> loss: 0.450\n",
            "epoch: [26/30] -> loss: 0.451\n",
            "epoch: [27/30] -> loss: 0.452\n",
            "epoch: [28/30] -> loss: 0.448\n",
            "epoch: [29/30] -> loss: 0.453\n",
            "epoch: [30/30] -> loss: 0.450\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.450\n",
            "* Train accuracy: 85.69%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 2.542\n",
            "epoch: [2/30] -> loss: 1.078\n",
            "epoch: [3/30] -> loss: 1.015\n",
            "epoch: [4/30] -> loss: 1.013\n",
            "epoch: [5/30] -> loss: 1.014\n",
            "epoch: [6/30] -> loss: 1.014\n",
            "epoch: [7/30] -> loss: 1.014\n",
            "epoch: [8/30] -> loss: 1.014\n",
            "epoch: [9/30] -> loss: 1.014\n",
            "epoch: [10/30] -> loss: 1.015\n",
            "epoch: [11/30] -> loss: 1.014\n",
            "epoch: [12/30] -> loss: 1.014\n",
            "epoch: [13/30] -> loss: 1.014\n",
            "epoch: [14/30] -> loss: 1.015\n",
            "epoch: [15/30] -> loss: 1.013\n",
            "epoch: [16/30] -> loss: 1.015\n",
            "epoch: [17/30] -> loss: 1.014\n",
            "epoch: [18/30] -> loss: 1.015\n",
            "epoch: [19/30] -> loss: 1.013\n",
            "epoch: [20/30] -> loss: 1.014\n",
            "epoch: [21/30] -> loss: 1.014\n",
            "epoch: [22/30] -> loss: 1.014\n",
            "epoch: [23/30] -> loss: 1.014\n",
            "epoch: [24/30] -> loss: 1.016\n",
            "epoch: [25/30] -> loss: 1.016\n",
            "epoch: [26/30] -> loss: 1.015\n",
            "epoch: [27/30] -> loss: 1.015\n",
            "epoch: [28/30] -> loss: 1.014\n",
            "epoch: [29/30] -> loss: 1.014\n",
            "epoch: [30/30] -> loss: 1.014\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.014\n",
            "* Train accuracy: 57.51%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.040\n",
            "epoch: [2/30] -> loss: 0.876\n",
            "epoch: [3/30] -> loss: 0.806\n",
            "epoch: [4/30] -> loss: 0.768\n",
            "epoch: [5/30] -> loss: 0.748\n",
            "epoch: [6/30] -> loss: 0.735\n",
            "epoch: [7/30] -> loss: 0.728\n",
            "epoch: [8/30] -> loss: 0.725\n",
            "epoch: [9/30] -> loss: 0.725\n",
            "epoch: [10/30] -> loss: 0.722\n",
            "epoch: [11/30] -> loss: 0.721\n",
            "epoch: [12/30] -> loss: 0.721\n",
            "epoch: [13/30] -> loss: 0.721\n",
            "epoch: [14/30] -> loss: 0.721\n",
            "epoch: [15/30] -> loss: 0.721\n",
            "epoch: [16/30] -> loss: 0.720\n",
            "epoch: [17/30] -> loss: 0.722\n",
            "epoch: [18/30] -> loss: 0.721\n",
            "epoch: [19/30] -> loss: 0.720\n",
            "epoch: [20/30] -> loss: 0.722\n",
            "epoch: [21/30] -> loss: 0.720\n",
            "epoch: [22/30] -> loss: 0.721\n",
            "epoch: [23/30] -> loss: 0.721\n",
            "epoch: [24/30] -> loss: 0.721\n",
            "epoch: [25/30] -> loss: 0.720\n",
            "epoch: [26/30] -> loss: 0.720\n",
            "epoch: [27/30] -> loss: 0.720\n",
            "epoch: [28/30] -> loss: 0.720\n",
            "epoch: [29/30] -> loss: 0.719\n",
            "epoch: [30/30] -> loss: 0.720\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.720\n",
            "* Train accuracy: 79.59%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.784\n",
            "epoch: [2/30] -> loss: 0.633\n",
            "epoch: [3/30] -> loss: 0.574\n",
            "epoch: [4/30] -> loss: 0.544\n",
            "epoch: [5/30] -> loss: 0.525\n",
            "epoch: [6/30] -> loss: 0.513\n",
            "epoch: [7/30] -> loss: 0.504\n",
            "epoch: [8/30] -> loss: 0.495\n",
            "epoch: [9/30] -> loss: 0.489\n",
            "epoch: [10/30] -> loss: 0.485\n",
            "epoch: [11/30] -> loss: 0.481\n",
            "epoch: [12/30] -> loss: 0.477\n",
            "epoch: [13/30] -> loss: 0.474\n",
            "epoch: [14/30] -> loss: 0.472\n",
            "epoch: [15/30] -> loss: 0.470\n",
            "epoch: [16/30] -> loss: 0.468\n",
            "epoch: [17/30] -> loss: 0.466\n",
            "epoch: [18/30] -> loss: 0.464\n",
            "epoch: [19/30] -> loss: 0.462\n",
            "epoch: [20/30] -> loss: 0.461\n",
            "epoch: [21/30] -> loss: 0.460\n",
            "epoch: [22/30] -> loss: 0.458\n",
            "epoch: [23/30] -> loss: 0.458\n",
            "epoch: [24/30] -> loss: 0.456\n",
            "epoch: [25/30] -> loss: 0.455\n",
            "epoch: [26/30] -> loss: 0.454\n",
            "epoch: [27/30] -> loss: 0.453\n",
            "epoch: [28/30] -> loss: 0.452\n",
            "epoch: [29/30] -> loss: 0.452\n",
            "epoch: [30/30] -> loss: 0.451\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.451\n",
            "* Train accuracy: 84.64%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.558\n",
            "epoch: [2/10] -> loss: 1.346\n",
            "epoch: [3/10] -> loss: 1.291\n",
            "epoch: [4/10] -> loss: 1.248\n",
            "epoch: [5/10] -> loss: 1.246\n",
            "epoch: [6/10] -> loss: 1.316\n",
            "epoch: [7/10] -> loss: 1.268\n",
            "epoch: [8/10] -> loss: 1.272\n",
            "epoch: [9/10] -> loss: 1.229\n",
            "epoch: [10/10] -> loss: 1.269\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.269\n",
            "* Train accuracy: 51.30%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.114\n",
            "epoch: [2/10] -> loss: 0.885\n",
            "epoch: [3/10] -> loss: 0.945\n",
            "epoch: [4/10] -> loss: 0.932\n",
            "epoch: [5/10] -> loss: 0.953\n",
            "epoch: [6/10] -> loss: 0.976\n",
            "epoch: [7/10] -> loss: 0.909\n",
            "epoch: [8/10] -> loss: 0.891\n",
            "epoch: [9/10] -> loss: 0.904\n",
            "epoch: [10/10] -> loss: 0.899\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.899\n",
            "* Train accuracy: 74.24%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.737\n",
            "epoch: [2/10] -> loss: 0.629\n",
            "epoch: [3/10] -> loss: 0.610\n",
            "epoch: [4/10] -> loss: 0.637\n",
            "epoch: [5/10] -> loss: 0.634\n",
            "epoch: [6/10] -> loss: 0.583\n",
            "epoch: [7/10] -> loss: 0.585\n",
            "epoch: [8/10] -> loss: 0.632\n",
            "epoch: [9/10] -> loss: 0.589\n",
            "epoch: [10/10] -> loss: 0.631\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.631\n",
            "* Train accuracy: 82.66%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.411\n",
            "epoch: [2/10] -> loss: 1.155\n",
            "epoch: [3/10] -> loss: 1.184\n",
            "epoch: [4/10] -> loss: 1.154\n",
            "epoch: [5/10] -> loss: 1.161\n",
            "epoch: [6/10] -> loss: 1.178\n",
            "epoch: [7/10] -> loss: 1.157\n",
            "epoch: [8/10] -> loss: 1.161\n",
            "epoch: [9/10] -> loss: 1.140\n",
            "epoch: [10/10] -> loss: 1.155\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.155\n",
            "* Train accuracy: 48.06%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.951\n",
            "epoch: [2/10] -> loss: 0.792\n",
            "epoch: [3/10] -> loss: 0.819\n",
            "epoch: [4/10] -> loss: 0.813\n",
            "epoch: [5/10] -> loss: 0.848\n",
            "epoch: [6/10] -> loss: 0.799\n",
            "epoch: [7/10] -> loss: 0.847\n",
            "epoch: [8/10] -> loss: 0.841\n",
            "epoch: [9/10] -> loss: 0.825\n",
            "epoch: [10/10] -> loss: 0.825\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.825\n",
            "* Train accuracy: 75.53%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.611\n",
            "epoch: [2/10] -> loss: 0.559\n",
            "epoch: [3/10] -> loss: 0.552\n",
            "epoch: [4/10] -> loss: 0.545\n",
            "epoch: [5/10] -> loss: 0.528\n",
            "epoch: [6/10] -> loss: 0.562\n",
            "epoch: [7/10] -> loss: 0.555\n",
            "epoch: [8/10] -> loss: 0.552\n",
            "epoch: [9/10] -> loss: 0.546\n",
            "epoch: [10/10] -> loss: 0.531\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.531\n",
            "* Train accuracy: 82.19%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.431\n",
            "epoch: [2/10] -> loss: 1.060\n",
            "epoch: [3/10] -> loss: 1.056\n",
            "epoch: [4/10] -> loss: 1.061\n",
            "epoch: [5/10] -> loss: 1.053\n",
            "epoch: [6/10] -> loss: 1.052\n",
            "epoch: [7/10] -> loss: 1.053\n",
            "epoch: [8/10] -> loss: 1.053\n",
            "epoch: [9/10] -> loss: 1.055\n",
            "epoch: [10/10] -> loss: 1.053\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.053\n",
            "* Train accuracy: 64.13%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.855\n",
            "epoch: [2/10] -> loss: 0.749\n",
            "epoch: [3/10] -> loss: 0.764\n",
            "epoch: [4/10] -> loss: 0.748\n",
            "epoch: [5/10] -> loss: 0.748\n",
            "epoch: [6/10] -> loss: 0.747\n",
            "epoch: [7/10] -> loss: 0.751\n",
            "epoch: [8/10] -> loss: 0.751\n",
            "epoch: [9/10] -> loss: 0.746\n",
            "epoch: [10/10] -> loss: 0.748\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.748\n",
            "* Train accuracy: 79.00%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.634\n",
            "epoch: [2/10] -> loss: 0.519\n",
            "epoch: [3/10] -> loss: 0.498\n",
            "epoch: [4/10] -> loss: 0.486\n",
            "epoch: [5/10] -> loss: 0.480\n",
            "epoch: [6/10] -> loss: 0.475\n",
            "epoch: [7/10] -> loss: 0.468\n",
            "epoch: [8/10] -> loss: 0.476\n",
            "epoch: [9/10] -> loss: 0.466\n",
            "epoch: [10/10] -> loss: 0.467\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.467\n",
            "* Train accuracy: 85.19%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.674\n",
            "epoch: [2/10] -> loss: 1.048\n",
            "epoch: [3/10] -> loss: 1.033\n",
            "epoch: [4/10] -> loss: 1.033\n",
            "epoch: [5/10] -> loss: 1.035\n",
            "epoch: [6/10] -> loss: 1.034\n",
            "epoch: [7/10] -> loss: 1.039\n",
            "epoch: [8/10] -> loss: 1.038\n",
            "epoch: [9/10] -> loss: 1.039\n",
            "epoch: [10/10] -> loss: 1.037\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.037\n",
            "* Train accuracy: 61.12%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.923\n",
            "epoch: [2/10] -> loss: 0.767\n",
            "epoch: [3/10] -> loss: 0.741\n",
            "epoch: [4/10] -> loss: 0.743\n",
            "epoch: [5/10] -> loss: 0.746\n",
            "epoch: [6/10] -> loss: 0.740\n",
            "epoch: [7/10] -> loss: 0.739\n",
            "epoch: [8/10] -> loss: 0.735\n",
            "epoch: [9/10] -> loss: 0.738\n",
            "epoch: [10/10] -> loss: 0.738\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.738\n",
            "* Train accuracy: 78.97%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.670\n",
            "epoch: [2/10] -> loss: 0.537\n",
            "epoch: [3/10] -> loss: 0.513\n",
            "epoch: [4/10] -> loss: 0.494\n",
            "epoch: [5/10] -> loss: 0.486\n",
            "epoch: [6/10] -> loss: 0.479\n",
            "epoch: [7/10] -> loss: 0.475\n",
            "epoch: [8/10] -> loss: 0.469\n",
            "epoch: [9/10] -> loss: 0.468\n",
            "epoch: [10/10] -> loss: 0.464\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.464\n",
            "* Train accuracy: 84.40%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 3.137\n",
            "epoch: [2/10] -> loss: 1.872\n",
            "epoch: [3/10] -> loss: 1.103\n",
            "epoch: [4/10] -> loss: 1.020\n",
            "epoch: [5/10] -> loss: 1.019\n",
            "epoch: [6/10] -> loss: 1.019\n",
            "epoch: [7/10] -> loss: 1.018\n",
            "epoch: [8/10] -> loss: 1.019\n",
            "epoch: [9/10] -> loss: 1.019\n",
            "epoch: [10/10] -> loss: 1.019\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.019\n",
            "* Train accuracy: 53.70%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.107\n",
            "epoch: [2/10] -> loss: 0.961\n",
            "epoch: [3/10] -> loss: 0.878\n",
            "epoch: [4/10] -> loss: 0.830\n",
            "epoch: [5/10] -> loss: 0.795\n",
            "epoch: [6/10] -> loss: 0.773\n",
            "epoch: [7/10] -> loss: 0.758\n",
            "epoch: [8/10] -> loss: 0.746\n",
            "epoch: [9/10] -> loss: 0.740\n",
            "epoch: [10/10] -> loss: 0.735\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.735\n",
            "* Train accuracy: 78.92%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.840\n",
            "epoch: [2/10] -> loss: 0.705\n",
            "epoch: [3/10] -> loss: 0.636\n",
            "epoch: [4/10] -> loss: 0.595\n",
            "epoch: [5/10] -> loss: 0.570\n",
            "epoch: [6/10] -> loss: 0.552\n",
            "epoch: [7/10] -> loss: 0.536\n",
            "epoch: [8/10] -> loss: 0.526\n",
            "epoch: [9/10] -> loss: 0.517\n",
            "epoch: [10/10] -> loss: 0.512\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.512\n",
            "* Train accuracy: 81.49%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.615\n",
            "epoch: [2/20] -> loss: 1.239\n",
            "epoch: [3/20] -> loss: 1.243\n",
            "epoch: [4/20] -> loss: 1.387\n",
            "epoch: [5/20] -> loss: 1.322\n",
            "epoch: [6/20] -> loss: 1.310\n",
            "epoch: [7/20] -> loss: 1.247\n",
            "epoch: [8/20] -> loss: 1.281\n",
            "epoch: [9/20] -> loss: 1.271\n",
            "epoch: [10/20] -> loss: 1.259\n",
            "epoch: [11/20] -> loss: 1.250\n",
            "epoch: [12/20] -> loss: 1.315\n",
            "epoch: [13/20] -> loss: 1.282\n",
            "epoch: [14/20] -> loss: 1.269\n",
            "epoch: [15/20] -> loss: 1.286\n",
            "epoch: [16/20] -> loss: 1.263\n",
            "epoch: [17/20] -> loss: 1.222\n",
            "epoch: [18/20] -> loss: 1.248\n",
            "epoch: [19/20] -> loss: 1.275\n",
            "epoch: [20/20] -> loss: 1.280\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.280\n",
            "* Train accuracy: 63.30%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.057\n",
            "epoch: [2/20] -> loss: 0.899\n",
            "epoch: [3/20] -> loss: 0.970\n",
            "epoch: [4/20] -> loss: 0.884\n",
            "epoch: [5/20] -> loss: 0.959\n",
            "epoch: [6/20] -> loss: 0.929\n",
            "epoch: [7/20] -> loss: 0.924\n",
            "epoch: [8/20] -> loss: 0.963\n",
            "epoch: [9/20] -> loss: 0.963\n",
            "epoch: [10/20] -> loss: 0.904\n",
            "epoch: [11/20] -> loss: 0.911\n",
            "epoch: [12/20] -> loss: 0.891\n",
            "epoch: [13/20] -> loss: 0.890\n",
            "epoch: [14/20] -> loss: 0.899\n",
            "epoch: [15/20] -> loss: 0.946\n",
            "epoch: [16/20] -> loss: 0.877\n",
            "epoch: [17/20] -> loss: 0.931\n",
            "epoch: [18/20] -> loss: 0.952\n",
            "epoch: [19/20] -> loss: 0.903\n",
            "epoch: [20/20] -> loss: 0.959\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.959\n",
            "* Train accuracy: 75.69%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.779\n",
            "epoch: [2/20] -> loss: 0.636\n",
            "epoch: [3/20] -> loss: 0.634\n",
            "epoch: [4/20] -> loss: 0.701\n",
            "epoch: [5/20] -> loss: 0.657\n",
            "epoch: [6/20] -> loss: 0.632\n",
            "epoch: [7/20] -> loss: 0.633\n",
            "epoch: [8/20] -> loss: 0.614\n",
            "epoch: [9/20] -> loss: 0.601\n",
            "epoch: [10/20] -> loss: 0.616\n",
            "epoch: [11/20] -> loss: 0.612\n",
            "epoch: [12/20] -> loss: 0.640\n",
            "epoch: [13/20] -> loss: 0.592\n",
            "epoch: [14/20] -> loss: 0.617\n",
            "epoch: [15/20] -> loss: 0.639\n",
            "epoch: [16/20] -> loss: 0.603\n",
            "epoch: [17/20] -> loss: 0.690\n",
            "epoch: [18/20] -> loss: 0.622\n",
            "epoch: [19/20] -> loss: 0.629\n",
            "epoch: [20/20] -> loss: 0.629\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.629\n",
            "* Train accuracy: 80.90%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.378\n",
            "epoch: [2/20] -> loss: 1.160\n",
            "epoch: [3/20] -> loss: 1.174\n",
            "epoch: [4/20] -> loss: 1.149\n",
            "epoch: [5/20] -> loss: 1.157\n",
            "epoch: [6/20] -> loss: 1.164\n",
            "epoch: [7/20] -> loss: 1.189\n",
            "epoch: [8/20] -> loss: 1.154\n",
            "epoch: [9/20] -> loss: 1.171\n",
            "epoch: [10/20] -> loss: 1.159\n",
            "epoch: [11/20] -> loss: 1.167\n",
            "epoch: [12/20] -> loss: 1.160\n",
            "epoch: [13/20] -> loss: 1.200\n",
            "epoch: [14/20] -> loss: 1.145\n",
            "epoch: [15/20] -> loss: 1.142\n",
            "epoch: [16/20] -> loss: 1.166\n",
            "epoch: [17/20] -> loss: 1.149\n",
            "epoch: [18/20] -> loss: 1.158\n",
            "epoch: [19/20] -> loss: 1.181\n",
            "epoch: [20/20] -> loss: 1.176\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.176\n",
            "* Train accuracy: 49.92%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.955\n",
            "epoch: [2/20] -> loss: 0.825\n",
            "epoch: [3/20] -> loss: 0.821\n",
            "epoch: [4/20] -> loss: 0.835\n",
            "epoch: [5/20] -> loss: 0.860\n",
            "epoch: [6/20] -> loss: 0.825\n",
            "epoch: [7/20] -> loss: 0.805\n",
            "epoch: [8/20] -> loss: 0.835\n",
            "epoch: [9/20] -> loss: 0.814\n",
            "epoch: [10/20] -> loss: 0.828\n",
            "epoch: [11/20] -> loss: 0.815\n",
            "epoch: [12/20] -> loss: 0.828\n",
            "epoch: [13/20] -> loss: 0.826\n",
            "epoch: [14/20] -> loss: 0.849\n",
            "epoch: [15/20] -> loss: 0.847\n",
            "epoch: [16/20] -> loss: 0.837\n",
            "epoch: [17/20] -> loss: 0.851\n",
            "epoch: [18/20] -> loss: 0.817\n",
            "epoch: [19/20] -> loss: 0.837\n",
            "epoch: [20/20] -> loss: 0.827\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.827\n",
            "* Train accuracy: 76.46%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.672\n",
            "epoch: [2/20] -> loss: 0.539\n",
            "epoch: [3/20] -> loss: 0.538\n",
            "epoch: [4/20] -> loss: 0.548\n",
            "epoch: [5/20] -> loss: 0.564\n",
            "epoch: [6/20] -> loss: 0.530\n",
            "epoch: [7/20] -> loss: 0.516\n",
            "epoch: [8/20] -> loss: 0.536\n",
            "epoch: [9/20] -> loss: 0.520\n",
            "epoch: [10/20] -> loss: 0.535\n",
            "epoch: [11/20] -> loss: 0.539\n",
            "epoch: [12/20] -> loss: 0.542\n",
            "epoch: [13/20] -> loss: 0.539\n",
            "epoch: [14/20] -> loss: 0.553\n",
            "epoch: [15/20] -> loss: 0.582\n",
            "epoch: [16/20] -> loss: 0.544\n",
            "epoch: [17/20] -> loss: 0.539\n",
            "epoch: [18/20] -> loss: 0.531\n",
            "epoch: [19/20] -> loss: 0.526\n",
            "epoch: [20/20] -> loss: 0.577\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.577\n",
            "* Train accuracy: 83.52%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.424\n",
            "epoch: [2/20] -> loss: 1.061\n",
            "epoch: [3/20] -> loss: 1.052\n",
            "epoch: [4/20] -> loss: 1.061\n",
            "epoch: [5/20] -> loss: 1.057\n",
            "epoch: [6/20] -> loss: 1.054\n",
            "epoch: [7/20] -> loss: 1.053\n",
            "epoch: [8/20] -> loss: 1.058\n",
            "epoch: [9/20] -> loss: 1.059\n",
            "epoch: [10/20] -> loss: 1.058\n",
            "epoch: [11/20] -> loss: 1.053\n",
            "epoch: [12/20] -> loss: 1.050\n",
            "epoch: [13/20] -> loss: 1.054\n",
            "epoch: [14/20] -> loss: 1.055\n",
            "epoch: [15/20] -> loss: 1.061\n",
            "epoch: [16/20] -> loss: 1.052\n",
            "epoch: [17/20] -> loss: 1.067\n",
            "epoch: [18/20] -> loss: 1.051\n",
            "epoch: [19/20] -> loss: 1.054\n",
            "epoch: [20/20] -> loss: 1.052\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.052\n",
            "* Train accuracy: 63.66%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.841\n",
            "epoch: [2/20] -> loss: 0.750\n",
            "epoch: [3/20] -> loss: 0.747\n",
            "epoch: [4/20] -> loss: 0.774\n",
            "epoch: [5/20] -> loss: 0.750\n",
            "epoch: [6/20] -> loss: 0.749\n",
            "epoch: [7/20] -> loss: 0.742\n",
            "epoch: [8/20] -> loss: 0.750\n",
            "epoch: [9/20] -> loss: 0.746\n",
            "epoch: [10/20] -> loss: 0.747\n",
            "epoch: [11/20] -> loss: 0.743\n",
            "epoch: [12/20] -> loss: 0.743\n",
            "epoch: [13/20] -> loss: 0.758\n",
            "epoch: [14/20] -> loss: 0.748\n",
            "epoch: [15/20] -> loss: 0.745\n",
            "epoch: [16/20] -> loss: 0.744\n",
            "epoch: [17/20] -> loss: 0.746\n",
            "epoch: [18/20] -> loss: 0.747\n",
            "epoch: [19/20] -> loss: 0.746\n",
            "epoch: [20/20] -> loss: 0.745\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.745\n",
            "* Train accuracy: 79.30%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.620\n",
            "epoch: [2/20] -> loss: 0.518\n",
            "epoch: [3/20] -> loss: 0.494\n",
            "epoch: [4/20] -> loss: 0.489\n",
            "epoch: [5/20] -> loss: 0.477\n",
            "epoch: [6/20] -> loss: 0.473\n",
            "epoch: [7/20] -> loss: 0.475\n",
            "epoch: [8/20] -> loss: 0.467\n",
            "epoch: [9/20] -> loss: 0.470\n",
            "epoch: [10/20] -> loss: 0.463\n",
            "epoch: [11/20] -> loss: 0.463\n",
            "epoch: [12/20] -> loss: 0.471\n",
            "epoch: [13/20] -> loss: 0.462\n",
            "epoch: [14/20] -> loss: 0.462\n",
            "epoch: [15/20] -> loss: 0.458\n",
            "epoch: [16/20] -> loss: 0.469\n",
            "epoch: [17/20] -> loss: 0.466\n",
            "epoch: [18/20] -> loss: 0.460\n",
            "epoch: [19/20] -> loss: 0.459\n",
            "epoch: [20/20] -> loss: 0.464\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.464\n",
            "* Train accuracy: 84.76%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.669\n",
            "epoch: [2/20] -> loss: 1.043\n",
            "epoch: [3/20] -> loss: 1.038\n",
            "epoch: [4/20] -> loss: 1.036\n",
            "epoch: [5/20] -> loss: 1.036\n",
            "epoch: [6/20] -> loss: 1.034\n",
            "epoch: [7/20] -> loss: 1.033\n",
            "epoch: [8/20] -> loss: 1.034\n",
            "epoch: [9/20] -> loss: 1.035\n",
            "epoch: [10/20] -> loss: 1.039\n",
            "epoch: [11/20] -> loss: 1.034\n",
            "epoch: [12/20] -> loss: 1.033\n",
            "epoch: [13/20] -> loss: 1.034\n",
            "epoch: [14/20] -> loss: 1.032\n",
            "epoch: [15/20] -> loss: 1.040\n",
            "epoch: [16/20] -> loss: 1.035\n",
            "epoch: [17/20] -> loss: 1.037\n",
            "epoch: [18/20] -> loss: 1.036\n",
            "epoch: [19/20] -> loss: 1.038\n",
            "epoch: [20/20] -> loss: 1.039\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.039\n",
            "* Train accuracy: 64.53%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.909\n",
            "epoch: [2/20] -> loss: 0.762\n",
            "epoch: [3/20] -> loss: 0.739\n",
            "epoch: [4/20] -> loss: 0.743\n",
            "epoch: [5/20] -> loss: 0.737\n",
            "epoch: [6/20] -> loss: 0.736\n",
            "epoch: [7/20] -> loss: 0.738\n",
            "epoch: [8/20] -> loss: 0.734\n",
            "epoch: [9/20] -> loss: 0.741\n",
            "epoch: [10/20] -> loss: 0.737\n",
            "epoch: [11/20] -> loss: 0.737\n",
            "epoch: [12/20] -> loss: 0.732\n",
            "epoch: [13/20] -> loss: 0.738\n",
            "epoch: [14/20] -> loss: 0.741\n",
            "epoch: [15/20] -> loss: 0.736\n",
            "epoch: [16/20] -> loss: 0.737\n",
            "epoch: [17/20] -> loss: 0.738\n",
            "epoch: [18/20] -> loss: 0.733\n",
            "epoch: [19/20] -> loss: 0.735\n",
            "epoch: [20/20] -> loss: 0.735\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.735\n",
            "* Train accuracy: 79.96%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.667\n",
            "epoch: [2/20] -> loss: 0.539\n",
            "epoch: [3/20] -> loss: 0.507\n",
            "epoch: [4/20] -> loss: 0.493\n",
            "epoch: [5/20] -> loss: 0.483\n",
            "epoch: [6/20] -> loss: 0.479\n",
            "epoch: [7/20] -> loss: 0.472\n",
            "epoch: [8/20] -> loss: 0.468\n",
            "epoch: [9/20] -> loss: 0.468\n",
            "epoch: [10/20] -> loss: 0.466\n",
            "epoch: [11/20] -> loss: 0.462\n",
            "epoch: [12/20] -> loss: 0.463\n",
            "epoch: [13/20] -> loss: 0.464\n",
            "epoch: [14/20] -> loss: 0.464\n",
            "epoch: [15/20] -> loss: 0.456\n",
            "epoch: [16/20] -> loss: 0.454\n",
            "epoch: [17/20] -> loss: 0.456\n",
            "epoch: [18/20] -> loss: 0.457\n",
            "epoch: [19/20] -> loss: 0.459\n",
            "epoch: [20/20] -> loss: 0.456\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.456\n",
            "* Train accuracy: 85.31%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 3.117\n",
            "epoch: [2/20] -> loss: 1.838\n",
            "epoch: [3/20] -> loss: 1.091\n",
            "epoch: [4/20] -> loss: 1.020\n",
            "epoch: [5/20] -> loss: 1.019\n",
            "epoch: [6/20] -> loss: 1.019\n",
            "epoch: [7/20] -> loss: 1.018\n",
            "epoch: [8/20] -> loss: 1.018\n",
            "epoch: [9/20] -> loss: 1.018\n",
            "epoch: [10/20] -> loss: 1.018\n",
            "epoch: [11/20] -> loss: 1.020\n",
            "epoch: [12/20] -> loss: 1.019\n",
            "epoch: [13/20] -> loss: 1.020\n",
            "epoch: [14/20] -> loss: 1.018\n",
            "epoch: [15/20] -> loss: 1.018\n",
            "epoch: [16/20] -> loss: 1.019\n",
            "epoch: [17/20] -> loss: 1.018\n",
            "epoch: [18/20] -> loss: 1.019\n",
            "epoch: [19/20] -> loss: 1.018\n",
            "epoch: [20/20] -> loss: 1.019\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.019\n",
            "* Train accuracy: 64.04%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.068\n",
            "epoch: [2/20] -> loss: 0.936\n",
            "epoch: [3/20] -> loss: 0.861\n",
            "epoch: [4/20] -> loss: 0.818\n",
            "epoch: [5/20] -> loss: 0.787\n",
            "epoch: [6/20] -> loss: 0.767\n",
            "epoch: [7/20] -> loss: 0.753\n",
            "epoch: [8/20] -> loss: 0.744\n",
            "epoch: [9/20] -> loss: 0.737\n",
            "epoch: [10/20] -> loss: 0.734\n",
            "epoch: [11/20] -> loss: 0.732\n",
            "epoch: [12/20] -> loss: 0.729\n",
            "epoch: [13/20] -> loss: 0.729\n",
            "epoch: [14/20] -> loss: 0.726\n",
            "epoch: [15/20] -> loss: 0.728\n",
            "epoch: [16/20] -> loss: 0.727\n",
            "epoch: [17/20] -> loss: 0.727\n",
            "epoch: [18/20] -> loss: 0.726\n",
            "epoch: [19/20] -> loss: 0.725\n",
            "epoch: [20/20] -> loss: 0.727\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.727\n",
            "* Train accuracy: 78.73%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.805\n",
            "epoch: [2/20] -> loss: 0.682\n",
            "epoch: [3/20] -> loss: 0.620\n",
            "epoch: [4/20] -> loss: 0.582\n",
            "epoch: [5/20] -> loss: 0.560\n",
            "epoch: [6/20] -> loss: 0.543\n",
            "epoch: [7/20] -> loss: 0.529\n",
            "epoch: [8/20] -> loss: 0.523\n",
            "epoch: [9/20] -> loss: 0.515\n",
            "epoch: [10/20] -> loss: 0.509\n",
            "epoch: [11/20] -> loss: 0.503\n",
            "epoch: [12/20] -> loss: 0.499\n",
            "epoch: [13/20] -> loss: 0.495\n",
            "epoch: [14/20] -> loss: 0.490\n",
            "epoch: [15/20] -> loss: 0.487\n",
            "epoch: [16/20] -> loss: 0.486\n",
            "epoch: [17/20] -> loss: 0.483\n",
            "epoch: [18/20] -> loss: 0.480\n",
            "epoch: [19/20] -> loss: 0.478\n",
            "epoch: [20/20] -> loss: 0.478\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.478\n",
            "* Train accuracy: 83.27%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.563\n",
            "epoch: [2/30] -> loss: 1.286\n",
            "epoch: [3/30] -> loss: 1.276\n",
            "epoch: [4/30] -> loss: 1.238\n",
            "epoch: [5/30] -> loss: 1.333\n",
            "epoch: [6/30] -> loss: 1.354\n",
            "epoch: [7/30] -> loss: 1.264\n",
            "epoch: [8/30] -> loss: 1.320\n",
            "epoch: [9/30] -> loss: 1.281\n",
            "epoch: [10/30] -> loss: 1.245\n",
            "epoch: [11/30] -> loss: 1.237\n",
            "epoch: [12/30] -> loss: 1.275\n",
            "epoch: [13/30] -> loss: 1.259\n",
            "epoch: [14/30] -> loss: 1.239\n",
            "epoch: [15/30] -> loss: 1.353\n",
            "epoch: [16/30] -> loss: 1.260\n",
            "epoch: [17/30] -> loss: 1.277\n",
            "epoch: [18/30] -> loss: 1.258\n",
            "epoch: [19/30] -> loss: 1.288\n",
            "epoch: [20/30] -> loss: 1.232\n",
            "epoch: [21/30] -> loss: 1.300\n",
            "epoch: [22/30] -> loss: 1.227\n",
            "epoch: [23/30] -> loss: 1.293\n",
            "epoch: [24/30] -> loss: 1.243\n",
            "epoch: [25/30] -> loss: 1.297\n",
            "epoch: [26/30] -> loss: 1.223\n",
            "epoch: [27/30] -> loss: 1.274\n",
            "epoch: [28/30] -> loss: 1.271\n",
            "epoch: [29/30] -> loss: 1.262\n",
            "epoch: [30/30] -> loss: 1.254\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.254\n",
            "* Train accuracy: 48.61%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.057\n",
            "epoch: [2/30] -> loss: 0.897\n",
            "epoch: [3/30] -> loss: 0.914\n",
            "epoch: [4/30] -> loss: 0.957\n",
            "epoch: [5/30] -> loss: 0.957\n",
            "epoch: [6/30] -> loss: 0.936\n",
            "epoch: [7/30] -> loss: 0.939\n",
            "epoch: [8/30] -> loss: 0.889\n",
            "epoch: [9/30] -> loss: 0.906\n",
            "epoch: [10/30] -> loss: 0.970\n",
            "epoch: [11/30] -> loss: 0.915\n",
            "epoch: [12/30] -> loss: 0.918\n",
            "epoch: [13/30] -> loss: 0.923\n",
            "epoch: [14/30] -> loss: 0.941\n",
            "epoch: [15/30] -> loss: 0.915\n",
            "epoch: [16/30] -> loss: 0.890\n",
            "epoch: [17/30] -> loss: 0.885\n",
            "epoch: [18/30] -> loss: 0.907\n",
            "epoch: [19/30] -> loss: 0.943\n",
            "epoch: [20/30] -> loss: 0.885\n",
            "epoch: [21/30] -> loss: 0.891\n",
            "epoch: [22/30] -> loss: 1.017\n",
            "epoch: [23/30] -> loss: 0.951\n",
            "epoch: [24/30] -> loss: 0.940\n",
            "epoch: [25/30] -> loss: 0.997\n",
            "epoch: [26/30] -> loss: 0.945\n",
            "epoch: [27/30] -> loss: 0.873\n",
            "epoch: [28/30] -> loss: 0.890\n",
            "epoch: [29/30] -> loss: 0.883\n",
            "epoch: [30/30] -> loss: 0.928\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.928\n",
            "* Train accuracy: 71.56%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.769\n",
            "epoch: [2/30] -> loss: 0.604\n",
            "epoch: [3/30] -> loss: 0.650\n",
            "epoch: [4/30] -> loss: 0.722\n",
            "epoch: [5/30] -> loss: 0.647\n",
            "epoch: [6/30] -> loss: 0.664\n",
            "epoch: [7/30] -> loss: 0.629\n",
            "epoch: [8/30] -> loss: 0.647\n",
            "epoch: [9/30] -> loss: 0.661\n",
            "epoch: [10/30] -> loss: 0.578\n",
            "epoch: [11/30] -> loss: 0.591\n",
            "epoch: [12/30] -> loss: 0.661\n",
            "epoch: [13/30] -> loss: 0.706\n",
            "epoch: [14/30] -> loss: 0.616\n",
            "epoch: [15/30] -> loss: 0.571\n",
            "epoch: [16/30] -> loss: 0.619\n",
            "epoch: [17/30] -> loss: 0.613\n",
            "epoch: [18/30] -> loss: 0.591\n",
            "epoch: [19/30] -> loss: 0.690\n",
            "epoch: [20/30] -> loss: 0.596\n",
            "epoch: [21/30] -> loss: 0.601\n",
            "epoch: [22/30] -> loss: 0.578\n",
            "epoch: [23/30] -> loss: 0.598\n",
            "epoch: [24/30] -> loss: 0.629\n",
            "epoch: [25/30] -> loss: 0.717\n",
            "epoch: [26/30] -> loss: 0.593\n",
            "epoch: [27/30] -> loss: 0.653\n",
            "epoch: [28/30] -> loss: 0.627\n",
            "epoch: [29/30] -> loss: 0.639\n",
            "epoch: [30/30] -> loss: 0.578\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.578\n",
            "* Train accuracy: 81.26%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.376\n",
            "epoch: [2/30] -> loss: 1.182\n",
            "epoch: [3/30] -> loss: 1.153\n",
            "epoch: [4/30] -> loss: 1.153\n",
            "epoch: [5/30] -> loss: 1.154\n",
            "epoch: [6/30] -> loss: 1.177\n",
            "epoch: [7/30] -> loss: 1.163\n",
            "epoch: [8/30] -> loss: 1.158\n",
            "epoch: [9/30] -> loss: 1.164\n",
            "epoch: [10/30] -> loss: 1.155\n",
            "epoch: [11/30] -> loss: 1.182\n",
            "epoch: [12/30] -> loss: 1.153\n",
            "epoch: [13/30] -> loss: 1.158\n",
            "epoch: [14/30] -> loss: 1.172\n",
            "epoch: [15/30] -> loss: 1.148\n",
            "epoch: [16/30] -> loss: 1.140\n",
            "epoch: [17/30] -> loss: 1.176\n",
            "epoch: [18/30] -> loss: 1.159\n",
            "epoch: [19/30] -> loss: 1.146\n",
            "epoch: [20/30] -> loss: 1.145\n",
            "epoch: [21/30] -> loss: 1.156\n",
            "epoch: [22/30] -> loss: 1.165\n",
            "epoch: [23/30] -> loss: 1.168\n",
            "epoch: [24/30] -> loss: 1.139\n",
            "epoch: [25/30] -> loss: 1.150\n",
            "epoch: [26/30] -> loss: 1.139\n",
            "epoch: [27/30] -> loss: 1.186\n",
            "epoch: [28/30] -> loss: 1.177\n",
            "epoch: [29/30] -> loss: 1.186\n",
            "epoch: [30/30] -> loss: 1.154\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.154\n",
            "* Train accuracy: 62.89%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.880\n",
            "epoch: [2/30] -> loss: 0.881\n",
            "epoch: [3/30] -> loss: 0.840\n",
            "epoch: [4/30] -> loss: 0.850\n",
            "epoch: [5/30] -> loss: 0.809\n",
            "epoch: [6/30] -> loss: 0.803\n",
            "epoch: [7/30] -> loss: 0.840\n",
            "epoch: [8/30] -> loss: 0.827\n",
            "epoch: [9/30] -> loss: 0.806\n",
            "epoch: [10/30] -> loss: 0.820\n",
            "epoch: [11/30] -> loss: 0.805\n",
            "epoch: [12/30] -> loss: 0.868\n",
            "epoch: [13/30] -> loss: 0.812\n",
            "epoch: [14/30] -> loss: 0.860\n",
            "epoch: [15/30] -> loss: 0.794\n",
            "epoch: [16/30] -> loss: 0.828\n",
            "epoch: [17/30] -> loss: 0.821\n",
            "epoch: [18/30] -> loss: 0.828\n",
            "epoch: [19/30] -> loss: 0.818\n",
            "epoch: [20/30] -> loss: 0.818\n",
            "epoch: [21/30] -> loss: 0.827\n",
            "epoch: [22/30] -> loss: 0.809\n",
            "epoch: [23/30] -> loss: 0.839\n",
            "epoch: [24/30] -> loss: 0.860\n",
            "epoch: [25/30] -> loss: 0.822\n",
            "epoch: [26/30] -> loss: 0.801\n",
            "epoch: [27/30] -> loss: 0.810\n",
            "epoch: [28/30] -> loss: 0.837\n",
            "epoch: [29/30] -> loss: 0.828\n",
            "epoch: [30/30] -> loss: 0.834\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.834\n",
            "* Train accuracy: 65.89%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.622\n",
            "epoch: [2/30] -> loss: 0.572\n",
            "epoch: [3/30] -> loss: 0.525\n",
            "epoch: [4/30] -> loss: 0.530\n",
            "epoch: [5/30] -> loss: 0.524\n",
            "epoch: [6/30] -> loss: 0.533\n",
            "epoch: [7/30] -> loss: 0.519\n",
            "epoch: [8/30] -> loss: 0.529\n",
            "epoch: [9/30] -> loss: 0.516\n",
            "epoch: [10/30] -> loss: 0.546\n",
            "epoch: [11/30] -> loss: 0.547\n",
            "epoch: [12/30] -> loss: 0.529\n",
            "epoch: [13/30] -> loss: 0.550\n",
            "epoch: [14/30] -> loss: 0.526\n",
            "epoch: [15/30] -> loss: 0.516\n",
            "epoch: [16/30] -> loss: 0.558\n",
            "epoch: [17/30] -> loss: 0.516\n",
            "epoch: [18/30] -> loss: 0.516\n",
            "epoch: [19/30] -> loss: 0.516\n",
            "epoch: [20/30] -> loss: 0.520\n",
            "epoch: [21/30] -> loss: 0.534\n",
            "epoch: [22/30] -> loss: 0.531\n",
            "epoch: [23/30] -> loss: 0.533\n",
            "epoch: [24/30] -> loss: 0.540\n",
            "epoch: [25/30] -> loss: 0.543\n",
            "epoch: [26/30] -> loss: 0.537\n",
            "epoch: [27/30] -> loss: 0.534\n",
            "epoch: [28/30] -> loss: 0.533\n",
            "epoch: [29/30] -> loss: 0.535\n",
            "epoch: [30/30] -> loss: 0.548\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.548\n",
            "* Train accuracy: 83.07%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.419\n",
            "epoch: [2/30] -> loss: 1.058\n",
            "epoch: [3/30] -> loss: 1.058\n",
            "epoch: [4/30] -> loss: 1.058\n",
            "epoch: [5/30] -> loss: 1.061\n",
            "epoch: [6/30] -> loss: 1.056\n",
            "epoch: [7/30] -> loss: 1.052\n",
            "epoch: [8/30] -> loss: 1.059\n",
            "epoch: [9/30] -> loss: 1.062\n",
            "epoch: [10/30] -> loss: 1.063\n",
            "epoch: [11/30] -> loss: 1.057\n",
            "epoch: [12/30] -> loss: 1.052\n",
            "epoch: [13/30] -> loss: 1.053\n",
            "epoch: [14/30] -> loss: 1.052\n",
            "epoch: [15/30] -> loss: 1.050\n",
            "epoch: [16/30] -> loss: 1.059\n",
            "epoch: [17/30] -> loss: 1.063\n",
            "epoch: [18/30] -> loss: 1.055\n",
            "epoch: [19/30] -> loss: 1.056\n",
            "epoch: [20/30] -> loss: 1.059\n",
            "epoch: [21/30] -> loss: 1.057\n",
            "epoch: [22/30] -> loss: 1.061\n",
            "epoch: [23/30] -> loss: 1.056\n",
            "epoch: [24/30] -> loss: 1.057\n",
            "epoch: [25/30] -> loss: 1.062\n",
            "epoch: [26/30] -> loss: 1.058\n",
            "epoch: [27/30] -> loss: 1.059\n",
            "epoch: [28/30] -> loss: 1.055\n",
            "epoch: [29/30] -> loss: 1.057\n",
            "epoch: [30/30] -> loss: 1.064\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.064\n",
            "* Train accuracy: 60.99%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.863\n",
            "epoch: [2/30] -> loss: 0.751\n",
            "epoch: [3/30] -> loss: 0.753\n",
            "epoch: [4/30] -> loss: 0.749\n",
            "epoch: [5/30] -> loss: 0.744\n",
            "epoch: [6/30] -> loss: 0.753\n",
            "epoch: [7/30] -> loss: 0.756\n",
            "epoch: [8/30] -> loss: 0.754\n",
            "epoch: [9/30] -> loss: 0.744\n",
            "epoch: [10/30] -> loss: 0.747\n",
            "epoch: [11/30] -> loss: 0.754\n",
            "epoch: [12/30] -> loss: 0.744\n",
            "epoch: [13/30] -> loss: 0.744\n",
            "epoch: [14/30] -> loss: 0.745\n",
            "epoch: [15/30] -> loss: 0.745\n",
            "epoch: [16/30] -> loss: 0.741\n",
            "epoch: [17/30] -> loss: 0.745\n",
            "epoch: [18/30] -> loss: 0.746\n",
            "epoch: [19/30] -> loss: 0.748\n",
            "epoch: [20/30] -> loss: 0.759\n",
            "epoch: [21/30] -> loss: 0.746\n",
            "epoch: [22/30] -> loss: 0.760\n",
            "epoch: [23/30] -> loss: 0.754\n",
            "epoch: [24/30] -> loss: 0.747\n",
            "epoch: [25/30] -> loss: 0.747\n",
            "epoch: [26/30] -> loss: 0.747\n",
            "epoch: [27/30] -> loss: 0.745\n",
            "epoch: [28/30] -> loss: 0.741\n",
            "epoch: [29/30] -> loss: 0.749\n",
            "epoch: [30/30] -> loss: 0.738\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.738\n",
            "* Train accuracy: 79.31%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.623\n",
            "epoch: [2/30] -> loss: 0.514\n",
            "epoch: [3/30] -> loss: 0.497\n",
            "epoch: [4/30] -> loss: 0.491\n",
            "epoch: [5/30] -> loss: 0.479\n",
            "epoch: [6/30] -> loss: 0.479\n",
            "epoch: [7/30] -> loss: 0.471\n",
            "epoch: [8/30] -> loss: 0.471\n",
            "epoch: [9/30] -> loss: 0.464\n",
            "epoch: [10/30] -> loss: 0.471\n",
            "epoch: [11/30] -> loss: 0.467\n",
            "epoch: [12/30] -> loss: 0.462\n",
            "epoch: [13/30] -> loss: 0.463\n",
            "epoch: [14/30] -> loss: 0.464\n",
            "epoch: [15/30] -> loss: 0.463\n",
            "epoch: [16/30] -> loss: 0.462\n",
            "epoch: [17/30] -> loss: 0.460\n",
            "epoch: [18/30] -> loss: 0.462\n",
            "epoch: [19/30] -> loss: 0.468\n",
            "epoch: [20/30] -> loss: 0.461\n",
            "epoch: [21/30] -> loss: 0.459\n",
            "epoch: [22/30] -> loss: 0.460\n",
            "epoch: [23/30] -> loss: 0.462\n",
            "epoch: [24/30] -> loss: 0.458\n",
            "epoch: [25/30] -> loss: 0.467\n",
            "epoch: [26/30] -> loss: 0.467\n",
            "epoch: [27/30] -> loss: 0.457\n",
            "epoch: [28/30] -> loss: 0.466\n",
            "epoch: [29/30] -> loss: 0.460\n",
            "epoch: [30/30] -> loss: 0.458\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.458\n",
            "* Train accuracy: 85.89%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.633\n",
            "epoch: [2/30] -> loss: 1.047\n",
            "epoch: [3/30] -> loss: 1.035\n",
            "epoch: [4/30] -> loss: 1.040\n",
            "epoch: [5/30] -> loss: 1.033\n",
            "epoch: [6/30] -> loss: 1.037\n",
            "epoch: [7/30] -> loss: 1.034\n",
            "epoch: [8/30] -> loss: 1.036\n",
            "epoch: [9/30] -> loss: 1.033\n",
            "epoch: [10/30] -> loss: 1.035\n",
            "epoch: [11/30] -> loss: 1.043\n",
            "epoch: [12/30] -> loss: 1.036\n",
            "epoch: [13/30] -> loss: 1.037\n",
            "epoch: [14/30] -> loss: 1.033\n",
            "epoch: [15/30] -> loss: 1.040\n",
            "epoch: [16/30] -> loss: 1.040\n",
            "epoch: [17/30] -> loss: 1.037\n",
            "epoch: [18/30] -> loss: 1.037\n",
            "epoch: [19/30] -> loss: 1.034\n",
            "epoch: [20/30] -> loss: 1.033\n",
            "epoch: [21/30] -> loss: 1.038\n",
            "epoch: [22/30] -> loss: 1.036\n",
            "epoch: [23/30] -> loss: 1.034\n",
            "epoch: [24/30] -> loss: 1.036\n",
            "epoch: [25/30] -> loss: 1.032\n",
            "epoch: [26/30] -> loss: 1.035\n",
            "epoch: [27/30] -> loss: 1.038\n",
            "epoch: [28/30] -> loss: 1.039\n",
            "epoch: [29/30] -> loss: 1.040\n",
            "epoch: [30/30] -> loss: 1.044\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.044\n",
            "* Train accuracy: 63.80%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.900\n",
            "epoch: [2/30] -> loss: 0.760\n",
            "epoch: [3/30] -> loss: 0.741\n",
            "epoch: [4/30] -> loss: 0.739\n",
            "epoch: [5/30] -> loss: 0.741\n",
            "epoch: [6/30] -> loss: 0.737\n",
            "epoch: [7/30] -> loss: 0.736\n",
            "epoch: [8/30] -> loss: 0.741\n",
            "epoch: [9/30] -> loss: 0.737\n",
            "epoch: [10/30] -> loss: 0.738\n",
            "epoch: [11/30] -> loss: 0.737\n",
            "epoch: [12/30] -> loss: 0.738\n",
            "epoch: [13/30] -> loss: 0.737\n",
            "epoch: [14/30] -> loss: 0.739\n",
            "epoch: [15/30] -> loss: 0.736\n",
            "epoch: [16/30] -> loss: 0.734\n",
            "epoch: [17/30] -> loss: 0.737\n",
            "epoch: [18/30] -> loss: 0.737\n",
            "epoch: [19/30] -> loss: 0.739\n",
            "epoch: [20/30] -> loss: 0.734\n",
            "epoch: [21/30] -> loss: 0.732\n",
            "epoch: [22/30] -> loss: 0.737\n",
            "epoch: [23/30] -> loss: 0.733\n",
            "epoch: [24/30] -> loss: 0.736\n",
            "epoch: [25/30] -> loss: 0.731\n",
            "epoch: [26/30] -> loss: 0.729\n",
            "epoch: [27/30] -> loss: 0.743\n",
            "epoch: [28/30] -> loss: 0.738\n",
            "epoch: [29/30] -> loss: 0.733\n",
            "epoch: [30/30] -> loss: 0.733\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.733\n",
            "* Train accuracy: 79.72%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.654\n",
            "epoch: [2/30] -> loss: 0.540\n",
            "epoch: [3/30] -> loss: 0.506\n",
            "epoch: [4/30] -> loss: 0.494\n",
            "epoch: [5/30] -> loss: 0.484\n",
            "epoch: [6/30] -> loss: 0.477\n",
            "epoch: [7/30] -> loss: 0.473\n",
            "epoch: [8/30] -> loss: 0.470\n",
            "epoch: [9/30] -> loss: 0.472\n",
            "epoch: [10/30] -> loss: 0.467\n",
            "epoch: [11/30] -> loss: 0.462\n",
            "epoch: [12/30] -> loss: 0.465\n",
            "epoch: [13/30] -> loss: 0.459\n",
            "epoch: [14/30] -> loss: 0.460\n",
            "epoch: [15/30] -> loss: 0.456\n",
            "epoch: [16/30] -> loss: 0.454\n",
            "epoch: [17/30] -> loss: 0.456\n",
            "epoch: [18/30] -> loss: 0.455\n",
            "epoch: [19/30] -> loss: 0.458\n",
            "epoch: [20/30] -> loss: 0.454\n",
            "epoch: [21/30] -> loss: 0.453\n",
            "epoch: [22/30] -> loss: 0.456\n",
            "epoch: [23/30] -> loss: 0.453\n",
            "epoch: [24/30] -> loss: 0.459\n",
            "epoch: [25/30] -> loss: 0.453\n",
            "epoch: [26/30] -> loss: 0.454\n",
            "epoch: [27/30] -> loss: 0.453\n",
            "epoch: [28/30] -> loss: 0.453\n",
            "epoch: [29/30] -> loss: 0.450\n",
            "epoch: [30/30] -> loss: 0.449\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.449\n",
            "* Train accuracy: 85.74%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 3.146\n",
            "epoch: [2/30] -> loss: 1.864\n",
            "epoch: [3/30] -> loss: 1.096\n",
            "epoch: [4/30] -> loss: 1.021\n",
            "epoch: [5/30] -> loss: 1.019\n",
            "epoch: [6/30] -> loss: 1.019\n",
            "epoch: [7/30] -> loss: 1.018\n",
            "epoch: [8/30] -> loss: 1.019\n",
            "epoch: [9/30] -> loss: 1.019\n",
            "epoch: [10/30] -> loss: 1.019\n",
            "epoch: [11/30] -> loss: 1.019\n",
            "epoch: [12/30] -> loss: 1.019\n",
            "epoch: [13/30] -> loss: 1.018\n",
            "epoch: [14/30] -> loss: 1.018\n",
            "epoch: [15/30] -> loss: 1.018\n",
            "epoch: [16/30] -> loss: 1.018\n",
            "epoch: [17/30] -> loss: 1.018\n",
            "epoch: [18/30] -> loss: 1.018\n",
            "epoch: [19/30] -> loss: 1.018\n",
            "epoch: [20/30] -> loss: 1.019\n",
            "epoch: [21/30] -> loss: 1.019\n",
            "epoch: [22/30] -> loss: 1.019\n",
            "epoch: [23/30] -> loss: 1.018\n",
            "epoch: [24/30] -> loss: 1.018\n",
            "epoch: [25/30] -> loss: 1.019\n",
            "epoch: [26/30] -> loss: 1.019\n",
            "epoch: [27/30] -> loss: 1.018\n",
            "epoch: [28/30] -> loss: 1.019\n",
            "epoch: [29/30] -> loss: 1.018\n",
            "epoch: [30/30] -> loss: 1.018\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.018\n",
            "* Train accuracy: 61.24%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.090\n",
            "epoch: [2/30] -> loss: 0.948\n",
            "epoch: [3/30] -> loss: 0.870\n",
            "epoch: [4/30] -> loss: 0.823\n",
            "epoch: [5/30] -> loss: 0.792\n",
            "epoch: [6/30] -> loss: 0.769\n",
            "epoch: [7/30] -> loss: 0.755\n",
            "epoch: [8/30] -> loss: 0.745\n",
            "epoch: [9/30] -> loss: 0.739\n",
            "epoch: [10/30] -> loss: 0.736\n",
            "epoch: [11/30] -> loss: 0.731\n",
            "epoch: [12/30] -> loss: 0.729\n",
            "epoch: [13/30] -> loss: 0.729\n",
            "epoch: [14/30] -> loss: 0.726\n",
            "epoch: [15/30] -> loss: 0.727\n",
            "epoch: [16/30] -> loss: 0.728\n",
            "epoch: [17/30] -> loss: 0.726\n",
            "epoch: [18/30] -> loss: 0.729\n",
            "epoch: [19/30] -> loss: 0.725\n",
            "epoch: [20/30] -> loss: 0.727\n",
            "epoch: [21/30] -> loss: 0.726\n",
            "epoch: [22/30] -> loss: 0.725\n",
            "epoch: [23/30] -> loss: 0.727\n",
            "epoch: [24/30] -> loss: 0.725\n",
            "epoch: [25/30] -> loss: 0.726\n",
            "epoch: [26/30] -> loss: 0.726\n",
            "epoch: [27/30] -> loss: 0.724\n",
            "epoch: [28/30] -> loss: 0.726\n",
            "epoch: [29/30] -> loss: 0.724\n",
            "epoch: [30/30] -> loss: 0.725\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.725\n",
            "* Train accuracy: 79.47%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.828\n",
            "epoch: [2/30] -> loss: 0.697\n",
            "epoch: [3/30] -> loss: 0.628\n",
            "epoch: [4/30] -> loss: 0.592\n",
            "epoch: [5/30] -> loss: 0.566\n",
            "epoch: [6/30] -> loss: 0.548\n",
            "epoch: [7/30] -> loss: 0.534\n",
            "epoch: [8/30] -> loss: 0.526\n",
            "epoch: [9/30] -> loss: 0.518\n",
            "epoch: [10/30] -> loss: 0.510\n",
            "epoch: [11/30] -> loss: 0.504\n",
            "epoch: [12/30] -> loss: 0.498\n",
            "epoch: [13/30] -> loss: 0.496\n",
            "epoch: [14/30] -> loss: 0.492\n",
            "epoch: [15/30] -> loss: 0.490\n",
            "epoch: [16/30] -> loss: 0.487\n",
            "epoch: [17/30] -> loss: 0.484\n",
            "epoch: [18/30] -> loss: 0.483\n",
            "epoch: [19/30] -> loss: 0.480\n",
            "epoch: [20/30] -> loss: 0.477\n",
            "epoch: [21/30] -> loss: 0.475\n",
            "epoch: [22/30] -> loss: 0.474\n",
            "epoch: [23/30] -> loss: 0.472\n",
            "epoch: [24/30] -> loss: 0.472\n",
            "epoch: [25/30] -> loss: 0.471\n",
            "epoch: [26/30] -> loss: 0.469\n",
            "epoch: [27/30] -> loss: 0.466\n",
            "epoch: [28/30] -> loss: 0.469\n",
            "epoch: [29/30] -> loss: 0.466\n",
            "epoch: [30/30] -> loss: 0.466\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.466\n",
            "* Train accuracy: 83.87%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.724\n",
            "epoch: [2/10] -> loss: 1.250\n",
            "epoch: [3/10] -> loss: 1.204\n",
            "epoch: [4/10] -> loss: 1.233\n",
            "epoch: [5/10] -> loss: 1.219\n",
            "epoch: [6/10] -> loss: 1.219\n",
            "epoch: [7/10] -> loss: 1.189\n",
            "epoch: [8/10] -> loss: 1.278\n",
            "epoch: [9/10] -> loss: 1.192\n",
            "epoch: [10/10] -> loss: 1.233\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.233\n",
            "* Train accuracy: 61.51%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.265\n",
            "epoch: [2/10] -> loss: 0.848\n",
            "epoch: [3/10] -> loss: 0.875\n",
            "epoch: [4/10] -> loss: 0.862\n",
            "epoch: [5/10] -> loss: 0.920\n",
            "epoch: [6/10] -> loss: 0.880\n",
            "epoch: [7/10] -> loss: 0.833\n",
            "epoch: [8/10] -> loss: 0.853\n",
            "epoch: [9/10] -> loss: 0.862\n",
            "epoch: [10/10] -> loss: 0.863\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.863\n",
            "* Train accuracy: 72.18%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.886\n",
            "epoch: [2/10] -> loss: 0.648\n",
            "epoch: [3/10] -> loss: 0.598\n",
            "epoch: [4/10] -> loss: 0.568\n",
            "epoch: [5/10] -> loss: 0.627\n",
            "epoch: [6/10] -> loss: 0.559\n",
            "epoch: [7/10] -> loss: 0.535\n",
            "epoch: [8/10] -> loss: 0.564\n",
            "epoch: [9/10] -> loss: 0.567\n",
            "epoch: [10/10] -> loss: 0.534\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.534\n",
            "* Train accuracy: 77.53%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.573\n",
            "epoch: [2/10] -> loss: 1.171\n",
            "epoch: [3/10] -> loss: 1.144\n",
            "epoch: [4/10] -> loss: 1.129\n",
            "epoch: [5/10] -> loss: 1.132\n",
            "epoch: [6/10] -> loss: 1.139\n",
            "epoch: [7/10] -> loss: 1.125\n",
            "epoch: [8/10] -> loss: 1.149\n",
            "epoch: [9/10] -> loss: 1.144\n",
            "epoch: [10/10] -> loss: 1.129\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.129\n",
            "* Train accuracy: 60.63%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.952\n",
            "epoch: [2/10] -> loss: 0.811\n",
            "epoch: [3/10] -> loss: 0.826\n",
            "epoch: [4/10] -> loss: 0.811\n",
            "epoch: [5/10] -> loss: 0.821\n",
            "epoch: [6/10] -> loss: 0.807\n",
            "epoch: [7/10] -> loss: 0.791\n",
            "epoch: [8/10] -> loss: 0.799\n",
            "epoch: [9/10] -> loss: 0.821\n",
            "epoch: [10/10] -> loss: 0.810\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.810\n",
            "* Train accuracy: 76.21%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.695\n",
            "epoch: [2/10] -> loss: 0.523\n",
            "epoch: [3/10] -> loss: 0.507\n",
            "epoch: [4/10] -> loss: 0.519\n",
            "epoch: [5/10] -> loss: 0.515\n",
            "epoch: [6/10] -> loss: 0.539\n",
            "epoch: [7/10] -> loss: 0.564\n",
            "epoch: [8/10] -> loss: 0.508\n",
            "epoch: [9/10] -> loss: 0.514\n",
            "epoch: [10/10] -> loss: 0.500\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.500\n",
            "* Train accuracy: 84.50%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.809\n",
            "epoch: [2/10] -> loss: 1.114\n",
            "epoch: [3/10] -> loss: 1.057\n",
            "epoch: [4/10] -> loss: 1.057\n",
            "epoch: [5/10] -> loss: 1.058\n",
            "epoch: [6/10] -> loss: 1.058\n",
            "epoch: [7/10] -> loss: 1.052\n",
            "epoch: [8/10] -> loss: 1.051\n",
            "epoch: [9/10] -> loss: 1.061\n",
            "epoch: [10/10] -> loss: 1.053\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.053\n",
            "* Train accuracy: 61.61%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.928\n",
            "epoch: [2/10] -> loss: 0.779\n",
            "epoch: [3/10] -> loss: 0.755\n",
            "epoch: [4/10] -> loss: 0.757\n",
            "epoch: [5/10] -> loss: 0.758\n",
            "epoch: [6/10] -> loss: 0.752\n",
            "epoch: [7/10] -> loss: 0.749\n",
            "epoch: [8/10] -> loss: 0.755\n",
            "epoch: [9/10] -> loss: 0.764\n",
            "epoch: [10/10] -> loss: 0.760\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.760\n",
            "* Train accuracy: 79.81%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.655\n",
            "epoch: [2/10] -> loss: 0.541\n",
            "epoch: [3/10] -> loss: 0.512\n",
            "epoch: [4/10] -> loss: 0.496\n",
            "epoch: [5/10] -> loss: 0.485\n",
            "epoch: [6/10] -> loss: 0.479\n",
            "epoch: [7/10] -> loss: 0.476\n",
            "epoch: [8/10] -> loss: 0.483\n",
            "epoch: [9/10] -> loss: 0.476\n",
            "epoch: [10/10] -> loss: 0.474\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.474\n",
            "* Train accuracy: 84.31%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 2.214\n",
            "epoch: [2/10] -> loss: 1.141\n",
            "epoch: [3/10] -> loss: 1.051\n",
            "epoch: [4/10] -> loss: 1.041\n",
            "epoch: [5/10] -> loss: 1.042\n",
            "epoch: [6/10] -> loss: 1.042\n",
            "epoch: [7/10] -> loss: 1.042\n",
            "epoch: [8/10] -> loss: 1.041\n",
            "epoch: [9/10] -> loss: 1.043\n",
            "epoch: [10/10] -> loss: 1.041\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.041\n",
            "* Train accuracy: 60.31%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.999\n",
            "epoch: [2/10] -> loss: 0.824\n",
            "epoch: [3/10] -> loss: 0.770\n",
            "epoch: [4/10] -> loss: 0.755\n",
            "epoch: [5/10] -> loss: 0.746\n",
            "epoch: [6/10] -> loss: 0.751\n",
            "epoch: [7/10] -> loss: 0.750\n",
            "epoch: [8/10] -> loss: 0.747\n",
            "epoch: [9/10] -> loss: 0.747\n",
            "epoch: [10/10] -> loss: 0.748\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.748\n",
            "* Train accuracy: 79.47%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.730\n",
            "epoch: [2/10] -> loss: 0.592\n",
            "epoch: [3/10] -> loss: 0.540\n",
            "epoch: [4/10] -> loss: 0.515\n",
            "epoch: [5/10] -> loss: 0.502\n",
            "epoch: [6/10] -> loss: 0.502\n",
            "epoch: [7/10] -> loss: 0.489\n",
            "epoch: [8/10] -> loss: 0.487\n",
            "epoch: [9/10] -> loss: 0.486\n",
            "epoch: [10/10] -> loss: 0.484\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.484\n",
            "* Train accuracy: 83.38%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/10] -> loss: 3.434\n",
            "epoch: [2/10] -> loss: 2.773\n",
            "epoch: [3/10] -> loss: 2.089\n",
            "epoch: [4/10] -> loss: 1.504\n",
            "epoch: [5/10] -> loss: 1.130\n",
            "epoch: [6/10] -> loss: 1.040\n",
            "epoch: [7/10] -> loss: 1.032\n",
            "epoch: [8/10] -> loss: 1.031\n",
            "epoch: [9/10] -> loss: 1.031\n",
            "epoch: [10/10] -> loss: 1.032\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.032\n",
            "* Train accuracy: 50.20%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/10] -> loss: 1.176\n",
            "epoch: [2/10] -> loss: 1.061\n",
            "epoch: [3/10] -> loss: 0.980\n",
            "epoch: [4/10] -> loss: 0.923\n",
            "epoch: [5/10] -> loss: 0.882\n",
            "epoch: [6/10] -> loss: 0.852\n",
            "epoch: [7/10] -> loss: 0.827\n",
            "epoch: [8/10] -> loss: 0.811\n",
            "epoch: [9/10] -> loss: 0.792\n",
            "epoch: [10/10] -> loss: 0.778\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.778\n",
            "* Train accuracy: 78.43%\n",
            "Start training SVM model with [epoch: 10, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/10] -> loss: 0.933\n",
            "epoch: [2/10] -> loss: 0.820\n",
            "epoch: [3/10] -> loss: 0.744\n",
            "epoch: [4/10] -> loss: 0.690\n",
            "epoch: [5/10] -> loss: 0.647\n",
            "epoch: [6/10] -> loss: 0.622\n",
            "epoch: [7/10] -> loss: 0.599\n",
            "epoch: [8/10] -> loss: 0.582\n",
            "epoch: [9/10] -> loss: 0.571\n",
            "epoch: [10/10] -> loss: 0.557\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.557\n",
            "* Train accuracy: 79.96%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.721\n",
            "epoch: [2/20] -> loss: 1.266\n",
            "epoch: [3/20] -> loss: 1.236\n",
            "epoch: [4/20] -> loss: 1.218\n",
            "epoch: [5/20] -> loss: 1.272\n",
            "epoch: [6/20] -> loss: 1.231\n",
            "epoch: [7/20] -> loss: 1.241\n",
            "epoch: [8/20] -> loss: 1.204\n",
            "epoch: [9/20] -> loss: 1.261\n",
            "epoch: [10/20] -> loss: 1.249\n",
            "epoch: [11/20] -> loss: 1.187\n",
            "epoch: [12/20] -> loss: 1.187\n",
            "epoch: [13/20] -> loss: 1.190\n",
            "epoch: [14/20] -> loss: 1.221\n",
            "epoch: [15/20] -> loss: 1.191\n",
            "epoch: [16/20] -> loss: 1.197\n",
            "epoch: [17/20] -> loss: 1.220\n",
            "epoch: [18/20] -> loss: 1.210\n",
            "epoch: [19/20] -> loss: 1.184\n",
            "epoch: [20/20] -> loss: 1.259\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.259\n",
            "* Train accuracy: 63.73%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.076\n",
            "epoch: [2/20] -> loss: 0.901\n",
            "epoch: [3/20] -> loss: 0.920\n",
            "epoch: [4/20] -> loss: 0.858\n",
            "epoch: [5/20] -> loss: 0.871\n",
            "epoch: [6/20] -> loss: 1.002\n",
            "epoch: [7/20] -> loss: 0.877\n",
            "epoch: [8/20] -> loss: 0.841\n",
            "epoch: [9/20] -> loss: 0.843\n",
            "epoch: [10/20] -> loss: 0.882\n",
            "epoch: [11/20] -> loss: 0.833\n",
            "epoch: [12/20] -> loss: 0.977\n",
            "epoch: [13/20] -> loss: 0.907\n",
            "epoch: [14/20] -> loss: 0.853\n",
            "epoch: [15/20] -> loss: 0.832\n",
            "epoch: [16/20] -> loss: 0.923\n",
            "epoch: [17/20] -> loss: 0.851\n",
            "epoch: [18/20] -> loss: 0.846\n",
            "epoch: [19/20] -> loss: 0.839\n",
            "epoch: [20/20] -> loss: 0.877\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.877\n",
            "* Train accuracy: 73.80%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.810\n",
            "epoch: [2/20] -> loss: 0.567\n",
            "epoch: [3/20] -> loss: 0.544\n",
            "epoch: [4/20] -> loss: 0.546\n",
            "epoch: [5/20] -> loss: 0.541\n",
            "epoch: [6/20] -> loss: 0.528\n",
            "epoch: [7/20] -> loss: 0.549\n",
            "epoch: [8/20] -> loss: 0.549\n",
            "epoch: [9/20] -> loss: 0.662\n",
            "epoch: [10/20] -> loss: 0.607\n",
            "epoch: [11/20] -> loss: 0.562\n",
            "epoch: [12/20] -> loss: 0.572\n",
            "epoch: [13/20] -> loss: 0.559\n",
            "epoch: [14/20] -> loss: 0.591\n",
            "epoch: [15/20] -> loss: 0.561\n",
            "epoch: [16/20] -> loss: 0.536\n",
            "epoch: [17/20] -> loss: 0.543\n",
            "epoch: [18/20] -> loss: 0.554\n",
            "epoch: [19/20] -> loss: 0.553\n",
            "epoch: [20/20] -> loss: 0.543\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.543\n",
            "* Train accuracy: 83.59%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.524\n",
            "epoch: [2/20] -> loss: 1.167\n",
            "epoch: [3/20] -> loss: 1.133\n",
            "epoch: [4/20] -> loss: 1.155\n",
            "epoch: [5/20] -> loss: 1.140\n",
            "epoch: [6/20] -> loss: 1.149\n",
            "epoch: [7/20] -> loss: 1.155\n",
            "epoch: [8/20] -> loss: 1.128\n",
            "epoch: [9/20] -> loss: 1.120\n",
            "epoch: [10/20] -> loss: 1.143\n",
            "epoch: [11/20] -> loss: 1.127\n",
            "epoch: [12/20] -> loss: 1.157\n",
            "epoch: [13/20] -> loss: 1.159\n",
            "epoch: [14/20] -> loss: 1.134\n",
            "epoch: [15/20] -> loss: 1.149\n",
            "epoch: [16/20] -> loss: 1.138\n",
            "epoch: [17/20] -> loss: 1.145\n",
            "epoch: [18/20] -> loss: 1.156\n",
            "epoch: [19/20] -> loss: 1.137\n",
            "epoch: [20/20] -> loss: 1.155\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.155\n",
            "* Train accuracy: 58.88%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.954\n",
            "epoch: [2/20] -> loss: 0.802\n",
            "epoch: [3/20] -> loss: 0.803\n",
            "epoch: [4/20] -> loss: 0.831\n",
            "epoch: [5/20] -> loss: 0.819\n",
            "epoch: [6/20] -> loss: 0.792\n",
            "epoch: [7/20] -> loss: 0.791\n",
            "epoch: [8/20] -> loss: 0.800\n",
            "epoch: [9/20] -> loss: 0.827\n",
            "epoch: [10/20] -> loss: 0.824\n",
            "epoch: [11/20] -> loss: 0.798\n",
            "epoch: [12/20] -> loss: 0.795\n",
            "epoch: [13/20] -> loss: 0.837\n",
            "epoch: [14/20] -> loss: 0.822\n",
            "epoch: [15/20] -> loss: 0.805\n",
            "epoch: [16/20] -> loss: 0.788\n",
            "epoch: [17/20] -> loss: 0.799\n",
            "epoch: [18/20] -> loss: 0.813\n",
            "epoch: [19/20] -> loss: 0.822\n",
            "epoch: [20/20] -> loss: 0.808\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.808\n",
            "* Train accuracy: 77.08%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.705\n",
            "epoch: [2/20] -> loss: 0.526\n",
            "epoch: [3/20] -> loss: 0.527\n",
            "epoch: [4/20] -> loss: 0.511\n",
            "epoch: [5/20] -> loss: 0.511\n",
            "epoch: [6/20] -> loss: 0.499\n",
            "epoch: [7/20] -> loss: 0.524\n",
            "epoch: [8/20] -> loss: 0.488\n",
            "epoch: [9/20] -> loss: 0.497\n",
            "epoch: [10/20] -> loss: 0.489\n",
            "epoch: [11/20] -> loss: 0.504\n",
            "epoch: [12/20] -> loss: 0.509\n",
            "epoch: [13/20] -> loss: 0.522\n",
            "epoch: [14/20] -> loss: 0.527\n",
            "epoch: [15/20] -> loss: 0.503\n",
            "epoch: [16/20] -> loss: 0.492\n",
            "epoch: [17/20] -> loss: 0.509\n",
            "epoch: [18/20] -> loss: 0.498\n",
            "epoch: [19/20] -> loss: 0.492\n",
            "epoch: [20/20] -> loss: 0.506\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.506\n",
            "* Train accuracy: 83.72%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.783\n",
            "epoch: [2/20] -> loss: 1.112\n",
            "epoch: [3/20] -> loss: 1.065\n",
            "epoch: [4/20] -> loss: 1.055\n",
            "epoch: [5/20] -> loss: 1.056\n",
            "epoch: [6/20] -> loss: 1.056\n",
            "epoch: [7/20] -> loss: 1.051\n",
            "epoch: [8/20] -> loss: 1.053\n",
            "epoch: [9/20] -> loss: 1.051\n",
            "epoch: [10/20] -> loss: 1.055\n",
            "epoch: [11/20] -> loss: 1.062\n",
            "epoch: [12/20] -> loss: 1.057\n",
            "epoch: [13/20] -> loss: 1.055\n",
            "epoch: [14/20] -> loss: 1.054\n",
            "epoch: [15/20] -> loss: 1.056\n",
            "epoch: [16/20] -> loss: 1.056\n",
            "epoch: [17/20] -> loss: 1.053\n",
            "epoch: [18/20] -> loss: 1.060\n",
            "epoch: [19/20] -> loss: 1.056\n",
            "epoch: [20/20] -> loss: 1.052\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.052\n",
            "* Train accuracy: 55.52%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.935\n",
            "epoch: [2/20] -> loss: 0.782\n",
            "epoch: [3/20] -> loss: 0.758\n",
            "epoch: [4/20] -> loss: 0.754\n",
            "epoch: [5/20] -> loss: 0.755\n",
            "epoch: [6/20] -> loss: 0.750\n",
            "epoch: [7/20] -> loss: 0.750\n",
            "epoch: [8/20] -> loss: 0.749\n",
            "epoch: [9/20] -> loss: 0.753\n",
            "epoch: [10/20] -> loss: 0.753\n",
            "epoch: [11/20] -> loss: 0.756\n",
            "epoch: [12/20] -> loss: 0.751\n",
            "epoch: [13/20] -> loss: 0.764\n",
            "epoch: [14/20] -> loss: 0.758\n",
            "epoch: [15/20] -> loss: 0.758\n",
            "epoch: [16/20] -> loss: 0.752\n",
            "epoch: [17/20] -> loss: 0.747\n",
            "epoch: [18/20] -> loss: 0.752\n",
            "epoch: [19/20] -> loss: 0.759\n",
            "epoch: [20/20] -> loss: 0.755\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.755\n",
            "* Train accuracy: 78.01%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.693\n",
            "epoch: [2/20] -> loss: 0.537\n",
            "epoch: [3/20] -> loss: 0.511\n",
            "epoch: [4/20] -> loss: 0.495\n",
            "epoch: [5/20] -> loss: 0.492\n",
            "epoch: [6/20] -> loss: 0.479\n",
            "epoch: [7/20] -> loss: 0.474\n",
            "epoch: [8/20] -> loss: 0.475\n",
            "epoch: [9/20] -> loss: 0.479\n",
            "epoch: [10/20] -> loss: 0.469\n",
            "epoch: [11/20] -> loss: 0.471\n",
            "epoch: [12/20] -> loss: 0.468\n",
            "epoch: [13/20] -> loss: 0.477\n",
            "epoch: [14/20] -> loss: 0.470\n",
            "epoch: [15/20] -> loss: 0.471\n",
            "epoch: [16/20] -> loss: 0.464\n",
            "epoch: [17/20] -> loss: 0.461\n",
            "epoch: [18/20] -> loss: 0.460\n",
            "epoch: [19/20] -> loss: 0.458\n",
            "epoch: [20/20] -> loss: 0.470\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.470\n",
            "* Train accuracy: 85.60%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 2.235\n",
            "epoch: [2/20] -> loss: 1.144\n",
            "epoch: [3/20] -> loss: 1.053\n",
            "epoch: [4/20] -> loss: 1.042\n",
            "epoch: [5/20] -> loss: 1.043\n",
            "epoch: [6/20] -> loss: 1.045\n",
            "epoch: [7/20] -> loss: 1.044\n",
            "epoch: [8/20] -> loss: 1.043\n",
            "epoch: [9/20] -> loss: 1.041\n",
            "epoch: [10/20] -> loss: 1.045\n",
            "epoch: [11/20] -> loss: 1.042\n",
            "epoch: [12/20] -> loss: 1.041\n",
            "epoch: [13/20] -> loss: 1.043\n",
            "epoch: [14/20] -> loss: 1.044\n",
            "epoch: [15/20] -> loss: 1.044\n",
            "epoch: [16/20] -> loss: 1.042\n",
            "epoch: [17/20] -> loss: 1.040\n",
            "epoch: [18/20] -> loss: 1.042\n",
            "epoch: [19/20] -> loss: 1.047\n",
            "epoch: [20/20] -> loss: 1.040\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.040\n",
            "* Train accuracy: 61.62%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.979\n",
            "epoch: [2/20] -> loss: 0.823\n",
            "epoch: [3/20] -> loss: 0.768\n",
            "epoch: [4/20] -> loss: 0.751\n",
            "epoch: [5/20] -> loss: 0.743\n",
            "epoch: [6/20] -> loss: 0.745\n",
            "epoch: [7/20] -> loss: 0.745\n",
            "epoch: [8/20] -> loss: 0.748\n",
            "epoch: [9/20] -> loss: 0.753\n",
            "epoch: [10/20] -> loss: 0.748\n",
            "epoch: [11/20] -> loss: 0.749\n",
            "epoch: [12/20] -> loss: 0.750\n",
            "epoch: [13/20] -> loss: 0.747\n",
            "epoch: [14/20] -> loss: 0.749\n",
            "epoch: [15/20] -> loss: 0.746\n",
            "epoch: [16/20] -> loss: 0.749\n",
            "epoch: [17/20] -> loss: 0.747\n",
            "epoch: [18/20] -> loss: 0.744\n",
            "epoch: [19/20] -> loss: 0.747\n",
            "epoch: [20/20] -> loss: 0.748\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.748\n",
            "* Train accuracy: 79.37%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.762\n",
            "epoch: [2/20] -> loss: 0.595\n",
            "epoch: [3/20] -> loss: 0.548\n",
            "epoch: [4/20] -> loss: 0.524\n",
            "epoch: [5/20] -> loss: 0.506\n",
            "epoch: [6/20] -> loss: 0.501\n",
            "epoch: [7/20] -> loss: 0.493\n",
            "epoch: [8/20] -> loss: 0.489\n",
            "epoch: [9/20] -> loss: 0.482\n",
            "epoch: [10/20] -> loss: 0.483\n",
            "epoch: [11/20] -> loss: 0.478\n",
            "epoch: [12/20] -> loss: 0.474\n",
            "epoch: [13/20] -> loss: 0.472\n",
            "epoch: [14/20] -> loss: 0.471\n",
            "epoch: [15/20] -> loss: 0.471\n",
            "epoch: [16/20] -> loss: 0.467\n",
            "epoch: [17/20] -> loss: 0.465\n",
            "epoch: [18/20] -> loss: 0.462\n",
            "epoch: [19/20] -> loss: 0.463\n",
            "epoch: [20/20] -> loss: 0.465\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.465\n",
            "* Train accuracy: 84.84%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/20] -> loss: 3.469\n",
            "epoch: [2/20] -> loss: 2.801\n",
            "epoch: [3/20] -> loss: 2.101\n",
            "epoch: [4/20] -> loss: 1.516\n",
            "epoch: [5/20] -> loss: 1.128\n",
            "epoch: [6/20] -> loss: 1.042\n",
            "epoch: [7/20] -> loss: 1.032\n",
            "epoch: [8/20] -> loss: 1.032\n",
            "epoch: [9/20] -> loss: 1.032\n",
            "epoch: [10/20] -> loss: 1.032\n",
            "epoch: [11/20] -> loss: 1.031\n",
            "epoch: [12/20] -> loss: 1.032\n",
            "epoch: [13/20] -> loss: 1.031\n",
            "epoch: [14/20] -> loss: 1.032\n",
            "epoch: [15/20] -> loss: 1.031\n",
            "epoch: [16/20] -> loss: 1.031\n",
            "epoch: [17/20] -> loss: 1.031\n",
            "epoch: [18/20] -> loss: 1.031\n",
            "epoch: [19/20] -> loss: 1.031\n",
            "epoch: [20/20] -> loss: 1.032\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.032\n",
            "* Train accuracy: 61.51%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/20] -> loss: 1.167\n",
            "epoch: [2/20] -> loss: 1.061\n",
            "epoch: [3/20] -> loss: 0.975\n",
            "epoch: [4/20] -> loss: 0.920\n",
            "epoch: [5/20] -> loss: 0.876\n",
            "epoch: [6/20] -> loss: 0.847\n",
            "epoch: [7/20] -> loss: 0.822\n",
            "epoch: [8/20] -> loss: 0.805\n",
            "epoch: [9/20] -> loss: 0.789\n",
            "epoch: [10/20] -> loss: 0.781\n",
            "epoch: [11/20] -> loss: 0.774\n",
            "epoch: [12/20] -> loss: 0.763\n",
            "epoch: [13/20] -> loss: 0.760\n",
            "epoch: [14/20] -> loss: 0.756\n",
            "epoch: [15/20] -> loss: 0.754\n",
            "epoch: [16/20] -> loss: 0.746\n",
            "epoch: [17/20] -> loss: 0.742\n",
            "epoch: [18/20] -> loss: 0.743\n",
            "epoch: [19/20] -> loss: 0.744\n",
            "epoch: [20/20] -> loss: 0.742\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.742\n",
            "* Train accuracy: 78.91%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.888\n",
            "epoch: [2/20] -> loss: 0.805\n",
            "epoch: [3/20] -> loss: 0.730\n",
            "epoch: [4/20] -> loss: 0.681\n",
            "epoch: [5/20] -> loss: 0.640\n",
            "epoch: [6/20] -> loss: 0.619\n",
            "epoch: [7/20] -> loss: 0.601\n",
            "epoch: [8/20] -> loss: 0.582\n",
            "epoch: [9/20] -> loss: 0.569\n",
            "epoch: [10/20] -> loss: 0.558\n",
            "epoch: [11/20] -> loss: 0.547\n",
            "epoch: [12/20] -> loss: 0.542\n",
            "epoch: [13/20] -> loss: 0.532\n",
            "epoch: [14/20] -> loss: 0.529\n",
            "epoch: [15/20] -> loss: 0.526\n",
            "epoch: [16/20] -> loss: 0.518\n",
            "epoch: [17/20] -> loss: 0.519\n",
            "epoch: [18/20] -> loss: 0.509\n",
            "epoch: [19/20] -> loss: 0.508\n",
            "epoch: [20/20] -> loss: 0.504\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.504\n",
            "* Train accuracy: 82.07%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.774\n",
            "epoch: [2/30] -> loss: 1.294\n",
            "epoch: [3/30] -> loss: 1.230\n",
            "epoch: [4/30] -> loss: 1.198\n",
            "epoch: [5/30] -> loss: 1.206\n",
            "epoch: [6/30] -> loss: 1.229\n",
            "epoch: [7/30] -> loss: 1.204\n",
            "epoch: [8/30] -> loss: 1.226\n",
            "epoch: [9/30] -> loss: 1.230\n",
            "epoch: [10/30] -> loss: 1.260\n",
            "epoch: [11/30] -> loss: 1.215\n",
            "epoch: [12/30] -> loss: 1.220\n",
            "epoch: [13/30] -> loss: 1.190\n",
            "epoch: [14/30] -> loss: 1.238\n",
            "epoch: [15/30] -> loss: 1.232\n",
            "epoch: [16/30] -> loss: 1.226\n",
            "epoch: [17/30] -> loss: 1.267\n",
            "epoch: [18/30] -> loss: 1.214\n",
            "epoch: [19/30] -> loss: 1.185\n",
            "epoch: [20/30] -> loss: 1.216\n",
            "epoch: [21/30] -> loss: 1.253\n",
            "epoch: [22/30] -> loss: 1.225\n",
            "epoch: [23/30] -> loss: 1.197\n",
            "epoch: [24/30] -> loss: 1.192\n",
            "epoch: [25/30] -> loss: 1.199\n",
            "epoch: [26/30] -> loss: 1.199\n",
            "epoch: [27/30] -> loss: 1.199\n",
            "epoch: [28/30] -> loss: 1.304\n",
            "epoch: [29/30] -> loss: 1.180\n",
            "epoch: [30/30] -> loss: 1.192\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.192\n",
            "* Train accuracy: 61.08%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.103\n",
            "epoch: [2/30] -> loss: 0.874\n",
            "epoch: [3/30] -> loss: 0.844\n",
            "epoch: [4/30] -> loss: 0.868\n",
            "epoch: [5/30] -> loss: 0.882\n",
            "epoch: [6/30] -> loss: 0.878\n",
            "epoch: [7/30] -> loss: 0.909\n",
            "epoch: [8/30] -> loss: 0.881\n",
            "epoch: [9/30] -> loss: 0.838\n",
            "epoch: [10/30] -> loss: 0.942\n",
            "epoch: [11/30] -> loss: 0.844\n",
            "epoch: [12/30] -> loss: 0.876\n",
            "epoch: [13/30] -> loss: 0.843\n",
            "epoch: [14/30] -> loss: 0.890\n",
            "epoch: [15/30] -> loss: 0.876\n",
            "epoch: [16/30] -> loss: 0.858\n",
            "epoch: [17/30] -> loss: 0.867\n",
            "epoch: [18/30] -> loss: 0.820\n",
            "epoch: [19/30] -> loss: 0.845\n",
            "epoch: [20/30] -> loss: 0.863\n",
            "epoch: [21/30] -> loss: 0.880\n",
            "epoch: [22/30] -> loss: 0.937\n",
            "epoch: [23/30] -> loss: 0.843\n",
            "epoch: [24/30] -> loss: 0.860\n",
            "epoch: [25/30] -> loss: 0.859\n",
            "epoch: [26/30] -> loss: 0.826\n",
            "epoch: [27/30] -> loss: 0.859\n",
            "epoch: [28/30] -> loss: 0.821\n",
            "epoch: [29/30] -> loss: 0.857\n",
            "epoch: [30/30] -> loss: 0.882\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.882\n",
            "* Train accuracy: 75.14%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.01, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.808\n",
            "epoch: [2/30] -> loss: 0.546\n",
            "epoch: [3/30] -> loss: 0.532\n",
            "epoch: [4/30] -> loss: 0.533\n",
            "epoch: [5/30] -> loss: 0.574\n",
            "epoch: [6/30] -> loss: 0.530\n",
            "epoch: [7/30] -> loss: 0.575\n",
            "epoch: [8/30] -> loss: 0.546\n",
            "epoch: [9/30] -> loss: 0.561\n",
            "epoch: [10/30] -> loss: 0.553\n",
            "epoch: [11/30] -> loss: 0.558\n",
            "epoch: [12/30] -> loss: 0.557\n",
            "epoch: [13/30] -> loss: 0.579\n",
            "epoch: [14/30] -> loss: 0.580\n",
            "epoch: [15/30] -> loss: 0.591\n",
            "epoch: [16/30] -> loss: 0.575\n",
            "epoch: [17/30] -> loss: 0.574\n",
            "epoch: [18/30] -> loss: 0.574\n",
            "epoch: [19/30] -> loss: 0.567\n",
            "epoch: [20/30] -> loss: 0.550\n",
            "epoch: [21/30] -> loss: 0.553\n",
            "epoch: [22/30] -> loss: 0.565\n",
            "epoch: [23/30] -> loss: 0.574\n",
            "epoch: [24/30] -> loss: 0.552\n",
            "epoch: [25/30] -> loss: 0.582\n",
            "epoch: [26/30] -> loss: 0.563\n",
            "epoch: [27/30] -> loss: 0.600\n",
            "epoch: [28/30] -> loss: 0.546\n",
            "epoch: [29/30] -> loss: 0.552\n",
            "epoch: [30/30] -> loss: 0.548\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.548\n",
            "* Train accuracy: 78.02%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.524\n",
            "epoch: [2/30] -> loss: 1.162\n",
            "epoch: [3/30] -> loss: 1.156\n",
            "epoch: [4/30] -> loss: 1.141\n",
            "epoch: [5/30] -> loss: 1.122\n",
            "epoch: [6/30] -> loss: 1.168\n",
            "epoch: [7/30] -> loss: 1.154\n",
            "epoch: [8/30] -> loss: 1.189\n",
            "epoch: [9/30] -> loss: 1.148\n",
            "epoch: [10/30] -> loss: 1.133\n",
            "epoch: [11/30] -> loss: 1.134\n",
            "epoch: [12/30] -> loss: 1.133\n",
            "epoch: [13/30] -> loss: 1.146\n",
            "epoch: [14/30] -> loss: 1.184\n",
            "epoch: [15/30] -> loss: 1.152\n",
            "epoch: [16/30] -> loss: 1.126\n",
            "epoch: [17/30] -> loss: 1.125\n",
            "epoch: [18/30] -> loss: 1.143\n",
            "epoch: [19/30] -> loss: 1.141\n",
            "epoch: [20/30] -> loss: 1.133\n",
            "epoch: [21/30] -> loss: 1.132\n",
            "epoch: [22/30] -> loss: 1.152\n",
            "epoch: [23/30] -> loss: 1.114\n",
            "epoch: [24/30] -> loss: 1.140\n",
            "epoch: [25/30] -> loss: 1.132\n",
            "epoch: [26/30] -> loss: 1.140\n",
            "epoch: [27/30] -> loss: 1.138\n",
            "epoch: [28/30] -> loss: 1.143\n",
            "epoch: [29/30] -> loss: 1.131\n",
            "epoch: [30/30] -> loss: 1.151\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.151\n",
            "* Train accuracy: 60.27%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.936\n",
            "epoch: [2/30] -> loss: 0.818\n",
            "epoch: [3/30] -> loss: 0.818\n",
            "epoch: [4/30] -> loss: 0.791\n",
            "epoch: [5/30] -> loss: 0.802\n",
            "epoch: [6/30] -> loss: 0.803\n",
            "epoch: [7/30] -> loss: 0.822\n",
            "epoch: [8/30] -> loss: 0.791\n",
            "epoch: [9/30] -> loss: 0.820\n",
            "epoch: [10/30] -> loss: 0.796\n",
            "epoch: [11/30] -> loss: 0.796\n",
            "epoch: [12/30] -> loss: 0.802\n",
            "epoch: [13/30] -> loss: 0.802\n",
            "epoch: [14/30] -> loss: 0.785\n",
            "epoch: [15/30] -> loss: 0.823\n",
            "epoch: [16/30] -> loss: 0.796\n",
            "epoch: [17/30] -> loss: 0.837\n",
            "epoch: [18/30] -> loss: 0.805\n",
            "epoch: [19/30] -> loss: 0.799\n",
            "epoch: [20/30] -> loss: 0.811\n",
            "epoch: [21/30] -> loss: 0.860\n",
            "epoch: [22/30] -> loss: 0.805\n",
            "epoch: [23/30] -> loss: 0.815\n",
            "epoch: [24/30] -> loss: 0.804\n",
            "epoch: [25/30] -> loss: 0.796\n",
            "epoch: [26/30] -> loss: 0.808\n",
            "epoch: [27/30] -> loss: 0.813\n",
            "epoch: [28/30] -> loss: 0.810\n",
            "epoch: [29/30] -> loss: 0.811\n",
            "epoch: [30/30] -> loss: 0.813\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.813\n",
            "* Train accuracy: 72.53%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.664\n",
            "epoch: [2/30] -> loss: 0.527\n",
            "epoch: [3/30] -> loss: 0.515\n",
            "epoch: [4/30] -> loss: 0.514\n",
            "epoch: [5/30] -> loss: 0.534\n",
            "epoch: [6/30] -> loss: 0.532\n",
            "epoch: [7/30] -> loss: 0.531\n",
            "epoch: [8/30] -> loss: 0.508\n",
            "epoch: [9/30] -> loss: 0.491\n",
            "epoch: [10/30] -> loss: 0.492\n",
            "epoch: [11/30] -> loss: 0.524\n",
            "epoch: [12/30] -> loss: 0.512\n",
            "epoch: [13/30] -> loss: 0.512\n",
            "epoch: [14/30] -> loss: 0.508\n",
            "epoch: [15/30] -> loss: 0.512\n",
            "epoch: [16/30] -> loss: 0.497\n",
            "epoch: [17/30] -> loss: 0.529\n",
            "epoch: [18/30] -> loss: 0.503\n",
            "epoch: [19/30] -> loss: 0.520\n",
            "epoch: [20/30] -> loss: 0.523\n",
            "epoch: [21/30] -> loss: 0.493\n",
            "epoch: [22/30] -> loss: 0.534\n",
            "epoch: [23/30] -> loss: 0.504\n",
            "epoch: [24/30] -> loss: 0.506\n",
            "epoch: [25/30] -> loss: 0.522\n",
            "epoch: [26/30] -> loss: 0.507\n",
            "epoch: [27/30] -> loss: 0.548\n",
            "epoch: [28/30] -> loss: 0.497\n",
            "epoch: [29/30] -> loss: 0.504\n",
            "epoch: [30/30] -> loss: 0.509\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.509\n",
            "* Train accuracy: 80.36%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.778\n",
            "epoch: [2/30] -> loss: 1.109\n",
            "epoch: [3/30] -> loss: 1.061\n",
            "epoch: [4/30] -> loss: 1.058\n",
            "epoch: [5/30] -> loss: 1.056\n",
            "epoch: [6/30] -> loss: 1.056\n",
            "epoch: [7/30] -> loss: 1.057\n",
            "epoch: [8/30] -> loss: 1.065\n",
            "epoch: [9/30] -> loss: 1.068\n",
            "epoch: [10/30] -> loss: 1.053\n",
            "epoch: [11/30] -> loss: 1.055\n",
            "epoch: [12/30] -> loss: 1.053\n",
            "epoch: [13/30] -> loss: 1.064\n",
            "epoch: [14/30] -> loss: 1.063\n",
            "epoch: [15/30] -> loss: 1.060\n",
            "epoch: [16/30] -> loss: 1.053\n",
            "epoch: [17/30] -> loss: 1.058\n",
            "epoch: [18/30] -> loss: 1.056\n",
            "epoch: [19/30] -> loss: 1.058\n",
            "epoch: [20/30] -> loss: 1.057\n",
            "epoch: [21/30] -> loss: 1.057\n",
            "epoch: [22/30] -> loss: 1.059\n",
            "epoch: [23/30] -> loss: 1.058\n",
            "epoch: [24/30] -> loss: 1.056\n",
            "epoch: [25/30] -> loss: 1.055\n",
            "epoch: [26/30] -> loss: 1.062\n",
            "epoch: [27/30] -> loss: 1.056\n",
            "epoch: [28/30] -> loss: 1.057\n",
            "epoch: [29/30] -> loss: 1.058\n",
            "epoch: [30/30] -> loss: 1.054\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.054\n",
            "* Train accuracy: 62.28%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.909\n",
            "epoch: [2/30] -> loss: 0.780\n",
            "epoch: [3/30] -> loss: 0.762\n",
            "epoch: [4/30] -> loss: 0.754\n",
            "epoch: [5/30] -> loss: 0.753\n",
            "epoch: [6/30] -> loss: 0.752\n",
            "epoch: [7/30] -> loss: 0.748\n",
            "epoch: [8/30] -> loss: 0.752\n",
            "epoch: [9/30] -> loss: 0.754\n",
            "epoch: [10/30] -> loss: 0.752\n",
            "epoch: [11/30] -> loss: 0.754\n",
            "epoch: [12/30] -> loss: 0.766\n",
            "epoch: [13/30] -> loss: 0.761\n",
            "epoch: [14/30] -> loss: 0.756\n",
            "epoch: [15/30] -> loss: 0.769\n",
            "epoch: [16/30] -> loss: 0.749\n",
            "epoch: [17/30] -> loss: 0.756\n",
            "epoch: [18/30] -> loss: 0.755\n",
            "epoch: [19/30] -> loss: 0.753\n",
            "epoch: [20/30] -> loss: 0.754\n",
            "epoch: [21/30] -> loss: 0.752\n",
            "epoch: [22/30] -> loss: 0.749\n",
            "epoch: [23/30] -> loss: 0.752\n",
            "epoch: [24/30] -> loss: 0.758\n",
            "epoch: [25/30] -> loss: 0.753\n",
            "epoch: [26/30] -> loss: 0.761\n",
            "epoch: [27/30] -> loss: 0.754\n",
            "epoch: [28/30] -> loss: 0.755\n",
            "epoch: [29/30] -> loss: 0.751\n",
            "epoch: [30/30] -> loss: 0.757\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.757\n",
            "* Train accuracy: 79.51%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.663\n",
            "epoch: [2/30] -> loss: 0.552\n",
            "epoch: [3/30] -> loss: 0.515\n",
            "epoch: [4/30] -> loss: 0.502\n",
            "epoch: [5/30] -> loss: 0.490\n",
            "epoch: [6/30] -> loss: 0.481\n",
            "epoch: [7/30] -> loss: 0.484\n",
            "epoch: [8/30] -> loss: 0.478\n",
            "epoch: [9/30] -> loss: 0.469\n",
            "epoch: [10/30] -> loss: 0.466\n",
            "epoch: [11/30] -> loss: 0.471\n",
            "epoch: [12/30] -> loss: 0.467\n",
            "epoch: [13/30] -> loss: 0.471\n",
            "epoch: [14/30] -> loss: 0.470\n",
            "epoch: [15/30] -> loss: 0.466\n",
            "epoch: [16/30] -> loss: 0.470\n",
            "epoch: [17/30] -> loss: 0.462\n",
            "epoch: [18/30] -> loss: 0.463\n",
            "epoch: [19/30] -> loss: 0.459\n",
            "epoch: [20/30] -> loss: 0.458\n",
            "epoch: [21/30] -> loss: 0.462\n",
            "epoch: [22/30] -> loss: 0.462\n",
            "epoch: [23/30] -> loss: 0.455\n",
            "epoch: [24/30] -> loss: 0.453\n",
            "epoch: [25/30] -> loss: 0.459\n",
            "epoch: [26/30] -> loss: 0.454\n",
            "epoch: [27/30] -> loss: 0.460\n",
            "epoch: [28/30] -> loss: 0.459\n",
            "epoch: [29/30] -> loss: 0.458\n",
            "epoch: [30/30] -> loss: 0.461\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.461\n",
            "* Train accuracy: 85.29%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 2.217\n",
            "epoch: [2/30] -> loss: 1.139\n",
            "epoch: [3/30] -> loss: 1.050\n",
            "epoch: [4/30] -> loss: 1.048\n",
            "epoch: [5/30] -> loss: 1.046\n",
            "epoch: [6/30] -> loss: 1.045\n",
            "epoch: [7/30] -> loss: 1.043\n",
            "epoch: [8/30] -> loss: 1.041\n",
            "epoch: [9/30] -> loss: 1.044\n",
            "epoch: [10/30] -> loss: 1.041\n",
            "epoch: [11/30] -> loss: 1.039\n",
            "epoch: [12/30] -> loss: 1.046\n",
            "epoch: [13/30] -> loss: 1.044\n",
            "epoch: [14/30] -> loss: 1.044\n",
            "epoch: [15/30] -> loss: 1.042\n",
            "epoch: [16/30] -> loss: 1.051\n",
            "epoch: [17/30] -> loss: 1.042\n",
            "epoch: [18/30] -> loss: 1.042\n",
            "epoch: [19/30] -> loss: 1.044\n",
            "epoch: [20/30] -> loss: 1.043\n",
            "epoch: [21/30] -> loss: 1.042\n",
            "epoch: [22/30] -> loss: 1.040\n",
            "epoch: [23/30] -> loss: 1.042\n",
            "epoch: [24/30] -> loss: 1.043\n",
            "epoch: [25/30] -> loss: 1.042\n",
            "epoch: [26/30] -> loss: 1.043\n",
            "epoch: [27/30] -> loss: 1.044\n",
            "epoch: [28/30] -> loss: 1.040\n",
            "epoch: [29/30] -> loss: 1.040\n",
            "epoch: [30/30] -> loss: 1.041\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.041\n",
            "* Train accuracy: 58.86%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.975\n",
            "epoch: [2/30] -> loss: 0.823\n",
            "epoch: [3/30] -> loss: 0.771\n",
            "epoch: [4/30] -> loss: 0.755\n",
            "epoch: [5/30] -> loss: 0.746\n",
            "epoch: [6/30] -> loss: 0.750\n",
            "epoch: [7/30] -> loss: 0.746\n",
            "epoch: [8/30] -> loss: 0.750\n",
            "epoch: [9/30] -> loss: 0.750\n",
            "epoch: [10/30] -> loss: 0.747\n",
            "epoch: [11/30] -> loss: 0.746\n",
            "epoch: [12/30] -> loss: 0.746\n",
            "epoch: [13/30] -> loss: 0.747\n",
            "epoch: [14/30] -> loss: 0.748\n",
            "epoch: [15/30] -> loss: 0.745\n",
            "epoch: [16/30] -> loss: 0.749\n",
            "epoch: [17/30] -> loss: 0.748\n",
            "epoch: [18/30] -> loss: 0.750\n",
            "epoch: [19/30] -> loss: 0.744\n",
            "epoch: [20/30] -> loss: 0.743\n",
            "epoch: [21/30] -> loss: 0.746\n",
            "epoch: [22/30] -> loss: 0.750\n",
            "epoch: [23/30] -> loss: 0.745\n",
            "epoch: [24/30] -> loss: 0.747\n",
            "epoch: [25/30] -> loss: 0.746\n",
            "epoch: [26/30] -> loss: 0.745\n",
            "epoch: [27/30] -> loss: 0.747\n",
            "epoch: [28/30] -> loss: 0.746\n",
            "epoch: [29/30] -> loss: 0.746\n",
            "epoch: [30/30] -> loss: 0.747\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.747\n",
            "* Train accuracy: 80.16%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.751\n",
            "epoch: [2/30] -> loss: 0.593\n",
            "epoch: [3/30] -> loss: 0.541\n",
            "epoch: [4/30] -> loss: 0.521\n",
            "epoch: [5/30] -> loss: 0.507\n",
            "epoch: [6/30] -> loss: 0.498\n",
            "epoch: [7/30] -> loss: 0.496\n",
            "epoch: [8/30] -> loss: 0.488\n",
            "epoch: [9/30] -> loss: 0.485\n",
            "epoch: [10/30] -> loss: 0.477\n",
            "epoch: [11/30] -> loss: 0.472\n",
            "epoch: [12/30] -> loss: 0.475\n",
            "epoch: [13/30] -> loss: 0.473\n",
            "epoch: [14/30] -> loss: 0.473\n",
            "epoch: [15/30] -> loss: 0.468\n",
            "epoch: [16/30] -> loss: 0.472\n",
            "epoch: [17/30] -> loss: 0.466\n",
            "epoch: [18/30] -> loss: 0.462\n",
            "epoch: [19/30] -> loss: 0.462\n",
            "epoch: [20/30] -> loss: 0.467\n",
            "epoch: [21/30] -> loss: 0.461\n",
            "epoch: [22/30] -> loss: 0.458\n",
            "epoch: [23/30] -> loss: 0.460\n",
            "epoch: [24/30] -> loss: 0.458\n",
            "epoch: [25/30] -> loss: 0.456\n",
            "epoch: [26/30] -> loss: 0.465\n",
            "epoch: [27/30] -> loss: 0.456\n",
            "epoch: [28/30] -> loss: 0.458\n",
            "epoch: [29/30] -> loss: 0.459\n",
            "epoch: [30/30] -> loss: 0.459\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.459\n",
            "* Train accuracy: 85.29%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 0.1]\n",
            "\n",
            "epoch: [1/30] -> loss: 3.464\n",
            "epoch: [2/30] -> loss: 2.793\n",
            "epoch: [3/30] -> loss: 2.098\n",
            "epoch: [4/30] -> loss: 1.510\n",
            "epoch: [5/30] -> loss: 1.127\n",
            "epoch: [6/30] -> loss: 1.042\n",
            "epoch: [7/30] -> loss: 1.033\n",
            "epoch: [8/30] -> loss: 1.032\n",
            "epoch: [9/30] -> loss: 1.032\n",
            "epoch: [10/30] -> loss: 1.032\n",
            "epoch: [11/30] -> loss: 1.031\n",
            "epoch: [12/30] -> loss: 1.031\n",
            "epoch: [13/30] -> loss: 1.032\n",
            "epoch: [14/30] -> loss: 1.032\n",
            "epoch: [15/30] -> loss: 1.032\n",
            "epoch: [16/30] -> loss: 1.033\n",
            "epoch: [17/30] -> loss: 1.031\n",
            "epoch: [18/30] -> loss: 1.032\n",
            "epoch: [19/30] -> loss: 1.032\n",
            "epoch: [20/30] -> loss: 1.031\n",
            "epoch: [21/30] -> loss: 1.031\n",
            "epoch: [22/30] -> loss: 1.031\n",
            "epoch: [23/30] -> loss: 1.032\n",
            "epoch: [24/30] -> loss: 1.031\n",
            "epoch: [25/30] -> loss: 1.031\n",
            "epoch: [26/30] -> loss: 1.031\n",
            "epoch: [27/30] -> loss: 1.031\n",
            "epoch: [28/30] -> loss: 1.031\n",
            "epoch: [29/30] -> loss: 1.031\n",
            "epoch: [30/30] -> loss: 1.031\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 1.031\n",
            "* Train accuracy: 56.37%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 1]\n",
            "\n",
            "epoch: [1/30] -> loss: 1.172\n",
            "epoch: [2/30] -> loss: 1.053\n",
            "epoch: [3/30] -> loss: 0.973\n",
            "epoch: [4/30] -> loss: 0.919\n",
            "epoch: [5/30] -> loss: 0.883\n",
            "epoch: [6/30] -> loss: 0.850\n",
            "epoch: [7/30] -> loss: 0.823\n",
            "epoch: [8/30] -> loss: 0.806\n",
            "epoch: [9/30] -> loss: 0.794\n",
            "epoch: [10/30] -> loss: 0.784\n",
            "epoch: [11/30] -> loss: 0.772\n",
            "epoch: [12/30] -> loss: 0.764\n",
            "epoch: [13/30] -> loss: 0.761\n",
            "epoch: [14/30] -> loss: 0.751\n",
            "epoch: [15/30] -> loss: 0.753\n",
            "epoch: [16/30] -> loss: 0.750\n",
            "epoch: [17/30] -> loss: 0.744\n",
            "epoch: [18/30] -> loss: 0.746\n",
            "epoch: [19/30] -> loss: 0.746\n",
            "epoch: [20/30] -> loss: 0.745\n",
            "epoch: [21/30] -> loss: 0.740\n",
            "epoch: [22/30] -> loss: 0.745\n",
            "epoch: [23/30] -> loss: 0.738\n",
            "epoch: [24/30] -> loss: 0.742\n",
            "epoch: [25/30] -> loss: 0.742\n",
            "epoch: [26/30] -> loss: 0.737\n",
            "epoch: [27/30] -> loss: 0.742\n",
            "epoch: [28/30] -> loss: 0.736\n",
            "epoch: [29/30] -> loss: 0.740\n",
            "epoch: [30/30] -> loss: 0.741\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.741\n",
            "* Train accuracy: 79.30%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.915\n",
            "epoch: [2/30] -> loss: 0.803\n",
            "epoch: [3/30] -> loss: 0.733\n",
            "epoch: [4/30] -> loss: 0.681\n",
            "epoch: [5/30] -> loss: 0.645\n",
            "epoch: [6/30] -> loss: 0.618\n",
            "epoch: [7/30] -> loss: 0.596\n",
            "epoch: [8/30] -> loss: 0.581\n",
            "epoch: [9/30] -> loss: 0.570\n",
            "epoch: [10/30] -> loss: 0.562\n",
            "epoch: [11/30] -> loss: 0.552\n",
            "epoch: [12/30] -> loss: 0.540\n",
            "epoch: [13/30] -> loss: 0.535\n",
            "epoch: [14/30] -> loss: 0.533\n",
            "epoch: [15/30] -> loss: 0.525\n",
            "epoch: [16/30] -> loss: 0.521\n",
            "epoch: [17/30] -> loss: 0.520\n",
            "epoch: [18/30] -> loss: 0.508\n",
            "epoch: [19/30] -> loss: 0.511\n",
            "epoch: [20/30] -> loss: 0.512\n",
            "epoch: [21/30] -> loss: 0.507\n",
            "epoch: [22/30] -> loss: 0.501\n",
            "epoch: [23/30] -> loss: 0.501\n",
            "epoch: [24/30] -> loss: 0.500\n",
            "epoch: [25/30] -> loss: 0.494\n",
            "epoch: [26/30] -> loss: 0.490\n",
            "epoch: [27/30] -> loss: 0.489\n",
            "epoch: [28/30] -> loss: 0.492\n",
            "epoch: [29/30] -> loss: 0.486\n",
            "epoch: [30/30] -> loss: 0.485\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.485\n",
            "* Train accuracy: 82.99%\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter: epoch, batch size, learning rate, optimizer, (gamma for regulization)\n",
        "HPT_Visualize = {}\n",
        "train_loss_Visualize = {}\n",
        "\n",
        "optim_list = [\"SGD\", \"Adam\"]\n",
        "epoch_list = [10, 20, 30]\n",
        "batch_list = [32, 64, 128, 256]\n",
        "lr_list = [0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
        "gamma_list = [0.1, 1, 10]\n",
        "\n",
        "for op in optim_list:\n",
        "    for batch in batch_list:\n",
        "        normalized_train_dataloader, normalized_val_dataloader, normalized_test_dataloader = Select_Class(normalized_trainset, normalized_testset, [6, 7], batch=batch)\n",
        "        for epoch in epoch_list:\n",
        "            for lr in lr_list:\n",
        "                for gamma in gamma_list:\n",
        "                    svc = SVC()\n",
        "                    _, train_loss, train_acc = svc.fit(normalized_train_dataloader, op, lr, epoch, gamma)\n",
        "                    val_loss, val_acc = svc.predict(normalized_val_dataloader)\n",
        "                    key = op+\"_\"+str(epoch)+\"_\"+str(batch)+\"_\"+str(lr)+\"_\"+str(gamma)\n",
        "                    HPT_Visualize[key] = {\"train_loss\":train_loss[-1],\n",
        "                                          \"train_acc\":train_acc,\n",
        "                                          \"val_loss\":val_loss,\n",
        "                                          \"val_acc\":val_acc}\n",
        "                    train_loss_Visualize[key] = train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lK9ugK71TkXX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "j3-pPoPfTkXb"
      },
      "outputs": [],
      "source": [
        "DF = HPT_Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cJFxkrMYTkXc",
        "outputId": "8e307c29-fb1d-42bd-d452-6e892cf1ca19"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>optimizer</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch size</th>\n",
              "      <th>learning rate</th>\n",
              "      <th>Gamma</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SGD_10_32_0.01_0.1</th>\n",
              "      <td>SGD</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.188030</td>\n",
              "      <td>63.766666</td>\n",
              "      <td>1.342973</td>\n",
              "      <td>61.299999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD_10_32_0.01_1</th>\n",
              "      <td>SGD</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.768563</td>\n",
              "      <td>74.433334</td>\n",
              "      <td>0.847913</td>\n",
              "      <td>71.800003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD_10_32_0.01_10</th>\n",
              "      <td>SGD</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.469072</td>\n",
              "      <td>84.333336</td>\n",
              "      <td>0.490246</td>\n",
              "      <td>82.099998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD_10_32_0.005_0.1</th>\n",
              "      <td>SGD</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.083605</td>\n",
              "      <td>58.055557</td>\n",
              "      <td>1.280964</td>\n",
              "      <td>57.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD_10_32_0.005_1</th>\n",
              "      <td>SGD</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.737112</td>\n",
              "      <td>79.933334</td>\n",
              "      <td>0.740328</td>\n",
              "      <td>78.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_256_0.0005_1</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747383</td>\n",
              "      <td>80.155556</td>\n",
              "      <td>0.685605</td>\n",
              "      <td>82.300003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_256_0.0005_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.459314</td>\n",
              "      <td>85.288887</td>\n",
              "      <td>0.486874</td>\n",
              "      <td>83.599998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_256_0.0001_0.1</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.031242</td>\n",
              "      <td>56.366665</td>\n",
              "      <td>1.002685</td>\n",
              "      <td>57.599998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_256_0.0001_1</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.741019</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>0.687231</td>\n",
              "      <td>81.800003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_256_0.0001_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.485355</td>\n",
              "      <td>82.988892</td>\n",
              "      <td>0.466248</td>\n",
              "      <td>83.800003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>360 rows  9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       optimizer  epochs  batch size  learning rate  Gamma   \n",
              "SGD_10_32_0.01_0.1           SGD      10          32         0.0100    0.1  \\\n",
              "SGD_10_32_0.01_1             SGD      10          32         0.0100    1.0   \n",
              "SGD_10_32_0.01_10            SGD      10          32         0.0100   10.0   \n",
              "SGD_10_32_0.005_0.1          SGD      10          32         0.0050    0.1   \n",
              "SGD_10_32_0.005_1            SGD      10          32         0.0050    1.0   \n",
              "...                          ...     ...         ...            ...    ...   \n",
              "Adam_30_256_0.0005_1        Adam      30         256         0.0005    1.0   \n",
              "Adam_30_256_0.0005_10       Adam      30         256         0.0005   10.0   \n",
              "Adam_30_256_0.0001_0.1      Adam      30         256         0.0001    0.1   \n",
              "Adam_30_256_0.0001_1        Adam      30         256         0.0001    1.0   \n",
              "Adam_30_256_0.0001_10       Adam      30         256         0.0001   10.0   \n",
              "\n",
              "                        train_loss  train_acc  val_loss    val_acc  \n",
              "SGD_10_32_0.01_0.1        1.188030  63.766666  1.342973  61.299999  \n",
              "SGD_10_32_0.01_1          0.768563  74.433334  0.847913  71.800003  \n",
              "SGD_10_32_0.01_10         0.469072  84.333336  0.490246  82.099998  \n",
              "SGD_10_32_0.005_0.1       1.083605  58.055557  1.280964  57.000000  \n",
              "SGD_10_32_0.005_1         0.737112  79.933334  0.740328  78.000000  \n",
              "...                            ...        ...       ...        ...  \n",
              "Adam_30_256_0.0005_1      0.747383  80.155556  0.685605  82.300003  \n",
              "Adam_30_256_0.0005_10     0.459314  85.288887  0.486874  83.599998  \n",
              "Adam_30_256_0.0001_0.1    1.031242  56.366665  1.002685  57.599998  \n",
              "Adam_30_256_0.0001_1      0.741019  79.300003  0.687231  81.800003  \n",
              "Adam_30_256_0.0001_10     0.485355  82.988892  0.466248  83.800003  \n",
              "\n",
              "[360 rows x 9 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data = {}\n",
        "for key, value in DF.items():\n",
        "    parts = key.split('_')\n",
        "    optimizer, epochs, batch_size, learning_rate, Gamma = parts[:5]\n",
        "    new_data[key] = {\n",
        "        \"optimizer\": optimizer,\n",
        "        \"epochs\": int(epochs),\n",
        "        \"batch size\": int(batch_size),\n",
        "        \"learning rate\": float(learning_rate),\n",
        "        \"Gamma\": float(Gamma),\n",
        "        \"train_loss\": value['train_loss'],\n",
        "        \"train_acc\": value['train_acc'],\n",
        "        \"val_loss\": float(value['val_loss']),\n",
        "        \"val_acc\": float(value['val_acc'])\n",
        "    }\n",
        "\n",
        "df = pd.DataFrame.from_dict(new_data, orient='index')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "uJ4EW7MCTkXc",
        "outputId": "511c0940-4f82-48a7-972f-8a3437809fff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>optimizer</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch size</th>\n",
              "      <th>learning rate</th>\n",
              "      <th>Gamma</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Adam_30_32_0.0005_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.457349</td>\n",
              "      <td>86.122223</td>\n",
              "      <td>0.494902</td>\n",
              "      <td>84.699997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_256_0.001_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.460588</td>\n",
              "      <td>85.288887</td>\n",
              "      <td>0.465659</td>\n",
              "      <td>84.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_128_0.0005_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.448505</td>\n",
              "      <td>85.744446</td>\n",
              "      <td>0.464985</td>\n",
              "      <td>84.400002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_32_0.0001_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.446705</td>\n",
              "      <td>85.144447</td>\n",
              "      <td>0.474819</td>\n",
              "      <td>84.400002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_128_0.0005_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.456162</td>\n",
              "      <td>85.311111</td>\n",
              "      <td>0.461548</td>\n",
              "      <td>84.199997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_32_0.0001_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.453965</td>\n",
              "      <td>84.511108</td>\n",
              "      <td>0.484507</td>\n",
              "      <td>84.199997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_256_0.0001_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.504064</td>\n",
              "      <td>82.066666</td>\n",
              "      <td>0.471817</td>\n",
              "      <td>84.199997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_256_0.001_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.469522</td>\n",
              "      <td>85.599998</td>\n",
              "      <td>0.464755</td>\n",
              "      <td>84.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_128_0.0001_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.466018</td>\n",
              "      <td>83.866669</td>\n",
              "      <td>0.469411</td>\n",
              "      <td>83.900002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_128_0.001_10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.458481</td>\n",
              "      <td>85.888885</td>\n",
              "      <td>0.471658</td>\n",
              "      <td>83.800003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      optimizer  epochs  batch size  learning rate  Gamma   \n",
              "Adam_30_32_0.0005_10       Adam      30          32         0.0005   10.0  \\\n",
              "Adam_30_256_0.001_10       Adam      30         256         0.0010   10.0   \n",
              "Adam_30_128_0.0005_10      Adam      30         128         0.0005   10.0   \n",
              "Adam_30_32_0.0001_10       Adam      30          32         0.0001   10.0   \n",
              "Adam_20_128_0.0005_10      Adam      20         128         0.0005   10.0   \n",
              "Adam_20_32_0.0001_10       Adam      20          32         0.0001   10.0   \n",
              "Adam_20_256_0.0001_10      Adam      20         256         0.0001   10.0   \n",
              "Adam_20_256_0.001_10       Adam      20         256         0.0010   10.0   \n",
              "Adam_30_128_0.0001_10      Adam      30         128         0.0001   10.0   \n",
              "Adam_30_128_0.001_10       Adam      30         128         0.0010   10.0   \n",
              "\n",
              "                       train_loss  train_acc  val_loss    val_acc  \n",
              "Adam_30_32_0.0005_10     0.457349  86.122223  0.494902  84.699997  \n",
              "Adam_30_256_0.001_10     0.460588  85.288887  0.465659  84.500000  \n",
              "Adam_30_128_0.0005_10    0.448505  85.744446  0.464985  84.400002  \n",
              "Adam_30_32_0.0001_10     0.446705  85.144447  0.474819  84.400002  \n",
              "Adam_20_128_0.0005_10    0.456162  85.311111  0.461548  84.199997  \n",
              "Adam_20_32_0.0001_10     0.453965  84.511108  0.484507  84.199997  \n",
              "Adam_20_256_0.0001_10    0.504064  82.066666  0.471817  84.199997  \n",
              "Adam_20_256_0.001_10     0.469522  85.599998  0.464755  84.000000  \n",
              "Adam_30_128_0.0001_10    0.466018  83.866669  0.469411  83.900002  \n",
              "Adam_30_128_0.001_10     0.458481  85.888885  0.471658  83.800003  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sorted = df.sort_values(by=['val_acc', 'train_acc'], ascending=False)\n",
        "df_sorted.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.589\n",
            "epoch: [2/30] -> loss: 0.505\n",
            "epoch: [3/30] -> loss: 0.489\n",
            "epoch: [4/30] -> loss: 0.484\n",
            "epoch: [5/30] -> loss: 0.475\n",
            "epoch: [6/30] -> loss: 0.467\n",
            "epoch: [7/30] -> loss: 0.465\n",
            "epoch: [8/30] -> loss: 0.467\n",
            "epoch: [9/30] -> loss: 0.464\n",
            "epoch: [10/30] -> loss: 0.463\n",
            "epoch: [11/30] -> loss: 0.470\n",
            "epoch: [12/30] -> loss: 0.465\n",
            "epoch: [13/30] -> loss: 0.462\n",
            "epoch: [14/30] -> loss: 0.458\n",
            "epoch: [15/30] -> loss: 0.463\n",
            "epoch: [16/30] -> loss: 0.461\n",
            "epoch: [17/30] -> loss: 0.458\n",
            "epoch: [18/30] -> loss: 0.463\n",
            "epoch: [19/30] -> loss: 0.461\n",
            "epoch: [20/30] -> loss: 0.458\n",
            "epoch: [21/30] -> loss: 0.462\n",
            "epoch: [22/30] -> loss: 0.459\n",
            "epoch: [23/30] -> loss: 0.461\n",
            "epoch: [24/30] -> loss: 0.459\n",
            "epoch: [25/30] -> loss: 0.460\n",
            "epoch: [26/30] -> loss: 0.456\n",
            "epoch: [27/30] -> loss: 0.459\n",
            "epoch: [28/30] -> loss: 0.457\n",
            "epoch: [29/30] -> loss: 0.456\n",
            "epoch: [30/30] -> loss: 0.461\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.461\n",
            "* Train accuracy: 85.90%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.598\n",
            "epoch: [2/30] -> loss: 0.505\n",
            "epoch: [3/30] -> loss: 0.489\n",
            "epoch: [4/30] -> loss: 0.483\n",
            "epoch: [5/30] -> loss: 0.476\n",
            "epoch: [6/30] -> loss: 0.473\n",
            "epoch: [7/30] -> loss: 0.470\n",
            "epoch: [8/30] -> loss: 0.467\n",
            "epoch: [9/30] -> loss: 0.464\n",
            "epoch: [10/30] -> loss: 0.461\n",
            "epoch: [11/30] -> loss: 0.461\n",
            "epoch: [12/30] -> loss: 0.461\n",
            "epoch: [13/30] -> loss: 0.459\n",
            "epoch: [14/30] -> loss: 0.460\n",
            "epoch: [15/30] -> loss: 0.460\n",
            "epoch: [16/30] -> loss: 0.458\n",
            "epoch: [17/30] -> loss: 0.457\n",
            "epoch: [18/30] -> loss: 0.458\n",
            "epoch: [19/30] -> loss: 0.456\n",
            "epoch: [20/30] -> loss: 0.461\n",
            "epoch: [21/30] -> loss: 0.461\n",
            "epoch: [22/30] -> loss: 0.460\n",
            "epoch: [23/30] -> loss: 0.457\n",
            "epoch: [24/30] -> loss: 0.459\n",
            "epoch: [25/30] -> loss: 0.458\n",
            "epoch: [26/30] -> loss: 0.460\n",
            "epoch: [27/30] -> loss: 0.458\n",
            "epoch: [28/30] -> loss: 0.457\n",
            "epoch: [29/30] -> loss: 0.456\n",
            "epoch: [30/30] -> loss: 0.462\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.462\n",
            "* Train accuracy: 85.24%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.592\n",
            "epoch: [2/30] -> loss: 0.501\n",
            "epoch: [3/30] -> loss: 0.482\n",
            "epoch: [4/30] -> loss: 0.476\n",
            "epoch: [5/30] -> loss: 0.473\n",
            "epoch: [6/30] -> loss: 0.468\n",
            "epoch: [7/30] -> loss: 0.466\n",
            "epoch: [8/30] -> loss: 0.464\n",
            "epoch: [9/30] -> loss: 0.461\n",
            "epoch: [10/30] -> loss: 0.465\n",
            "epoch: [11/30] -> loss: 0.460\n",
            "epoch: [12/30] -> loss: 0.466\n",
            "epoch: [13/30] -> loss: 0.456\n",
            "epoch: [14/30] -> loss: 0.461\n",
            "epoch: [15/30] -> loss: 0.461\n",
            "epoch: [16/30] -> loss: 0.458\n",
            "epoch: [17/30] -> loss: 0.458\n",
            "epoch: [18/30] -> loss: 0.456\n",
            "epoch: [19/30] -> loss: 0.460\n",
            "epoch: [20/30] -> loss: 0.459\n",
            "epoch: [21/30] -> loss: 0.457\n",
            "epoch: [22/30] -> loss: 0.457\n",
            "epoch: [23/30] -> loss: 0.457\n",
            "epoch: [24/30] -> loss: 0.461\n",
            "epoch: [25/30] -> loss: 0.457\n",
            "epoch: [26/30] -> loss: 0.458\n",
            "epoch: [27/30] -> loss: 0.458\n",
            "epoch: [28/30] -> loss: 0.456\n",
            "epoch: [29/30] -> loss: 0.458\n",
            "epoch: [30/30] -> loss: 0.459\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.459\n",
            "* Train accuracy: 85.42%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.600\n",
            "epoch: [2/30] -> loss: 0.506\n",
            "epoch: [3/30] -> loss: 0.484\n",
            "epoch: [4/30] -> loss: 0.477\n",
            "epoch: [5/30] -> loss: 0.476\n",
            "epoch: [6/30] -> loss: 0.471\n",
            "epoch: [7/30] -> loss: 0.469\n",
            "epoch: [8/30] -> loss: 0.463\n",
            "epoch: [9/30] -> loss: 0.463\n",
            "epoch: [10/30] -> loss: 0.462\n",
            "epoch: [11/30] -> loss: 0.462\n",
            "epoch: [12/30] -> loss: 0.460\n",
            "epoch: [13/30] -> loss: 0.460\n",
            "epoch: [14/30] -> loss: 0.460\n",
            "epoch: [15/30] -> loss: 0.459\n",
            "epoch: [16/30] -> loss: 0.462\n",
            "epoch: [17/30] -> loss: 0.457\n",
            "epoch: [18/30] -> loss: 0.459\n",
            "epoch: [19/30] -> loss: 0.457\n",
            "epoch: [20/30] -> loss: 0.463\n",
            "epoch: [21/30] -> loss: 0.461\n",
            "epoch: [22/30] -> loss: 0.456\n",
            "epoch: [23/30] -> loss: 0.462\n",
            "epoch: [24/30] -> loss: 0.458\n",
            "epoch: [25/30] -> loss: 0.457\n",
            "epoch: [26/30] -> loss: 0.456\n",
            "epoch: [27/30] -> loss: 0.460\n",
            "epoch: [28/30] -> loss: 0.460\n",
            "epoch: [29/30] -> loss: 0.462\n",
            "epoch: [30/30] -> loss: 0.459\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.459\n",
            "* Train accuracy: 85.27%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.602\n",
            "epoch: [2/30] -> loss: 0.505\n",
            "epoch: [3/30] -> loss: 0.487\n",
            "epoch: [4/30] -> loss: 0.481\n",
            "epoch: [5/30] -> loss: 0.471\n",
            "epoch: [6/30] -> loss: 0.471\n",
            "epoch: [7/30] -> loss: 0.470\n",
            "epoch: [8/30] -> loss: 0.469\n",
            "epoch: [9/30] -> loss: 0.465\n",
            "epoch: [10/30] -> loss: 0.460\n",
            "epoch: [11/30] -> loss: 0.459\n",
            "epoch: [12/30] -> loss: 0.462\n",
            "epoch: [13/30] -> loss: 0.460\n",
            "epoch: [14/30] -> loss: 0.462\n",
            "epoch: [15/30] -> loss: 0.460\n",
            "epoch: [16/30] -> loss: 0.461\n",
            "epoch: [17/30] -> loss: 0.459\n",
            "epoch: [18/30] -> loss: 0.460\n",
            "epoch: [19/30] -> loss: 0.457\n",
            "epoch: [20/30] -> loss: 0.461\n",
            "epoch: [21/30] -> loss: 0.458\n",
            "epoch: [22/30] -> loss: 0.454\n",
            "epoch: [23/30] -> loss: 0.457\n",
            "epoch: [24/30] -> loss: 0.458\n",
            "epoch: [25/30] -> loss: 0.458\n",
            "epoch: [26/30] -> loss: 0.456\n",
            "epoch: [27/30] -> loss: 0.461\n",
            "epoch: [28/30] -> loss: 0.457\n",
            "epoch: [29/30] -> loss: 0.456\n",
            "epoch: [30/30] -> loss: 0.462\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.462\n",
            "* Train accuracy: 85.96%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.700\n",
            "epoch: [2/30] -> loss: 0.549\n",
            "epoch: [3/30] -> loss: 0.510\n",
            "epoch: [4/30] -> loss: 0.501\n",
            "epoch: [5/30] -> loss: 0.494\n",
            "epoch: [6/30] -> loss: 0.479\n",
            "epoch: [7/30] -> loss: 0.481\n",
            "epoch: [8/30] -> loss: 0.482\n",
            "epoch: [9/30] -> loss: 0.473\n",
            "epoch: [10/30] -> loss: 0.461\n",
            "epoch: [11/30] -> loss: 0.469\n",
            "epoch: [12/30] -> loss: 0.469\n",
            "epoch: [13/30] -> loss: 0.470\n",
            "epoch: [14/30] -> loss: 0.469\n",
            "epoch: [15/30] -> loss: 0.461\n",
            "epoch: [16/30] -> loss: 0.463\n",
            "epoch: [17/30] -> loss: 0.466\n",
            "epoch: [18/30] -> loss: 0.467\n",
            "epoch: [19/30] -> loss: 0.461\n",
            "epoch: [20/30] -> loss: 0.465\n",
            "epoch: [21/30] -> loss: 0.470\n",
            "epoch: [22/30] -> loss: 0.458\n",
            "epoch: [23/30] -> loss: 0.467\n",
            "epoch: [24/30] -> loss: 0.457\n",
            "epoch: [25/30] -> loss: 0.466\n",
            "epoch: [26/30] -> loss: 0.453\n",
            "epoch: [27/30] -> loss: 0.458\n",
            "epoch: [28/30] -> loss: 0.456\n",
            "epoch: [29/30] -> loss: 0.457\n",
            "epoch: [30/30] -> loss: 0.457\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.457\n",
            "* Train accuracy: 85.48%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.669\n",
            "epoch: [2/30] -> loss: 0.541\n",
            "epoch: [3/30] -> loss: 0.504\n",
            "epoch: [4/30] -> loss: 0.494\n",
            "epoch: [5/30] -> loss: 0.482\n",
            "epoch: [6/30] -> loss: 0.486\n",
            "epoch: [7/30] -> loss: 0.482\n",
            "epoch: [8/30] -> loss: 0.477\n",
            "epoch: [9/30] -> loss: 0.469\n",
            "epoch: [10/30] -> loss: 0.469\n",
            "epoch: [11/30] -> loss: 0.474\n",
            "epoch: [12/30] -> loss: 0.466\n",
            "epoch: [13/30] -> loss: 0.468\n",
            "epoch: [14/30] -> loss: 0.463\n",
            "epoch: [15/30] -> loss: 0.461\n",
            "epoch: [16/30] -> loss: 0.464\n",
            "epoch: [17/30] -> loss: 0.469\n",
            "epoch: [18/30] -> loss: 0.461\n",
            "epoch: [19/30] -> loss: 0.464\n",
            "epoch: [20/30] -> loss: 0.468\n",
            "epoch: [21/30] -> loss: 0.456\n",
            "epoch: [22/30] -> loss: 0.473\n",
            "epoch: [23/30] -> loss: 0.460\n",
            "epoch: [24/30] -> loss: 0.474\n",
            "epoch: [25/30] -> loss: 0.458\n",
            "epoch: [26/30] -> loss: 0.459\n",
            "epoch: [27/30] -> loss: 0.461\n",
            "epoch: [28/30] -> loss: 0.461\n",
            "epoch: [29/30] -> loss: 0.456\n",
            "epoch: [30/30] -> loss: 0.458\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.458\n",
            "* Train accuracy: 86.26%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.653\n",
            "epoch: [2/30] -> loss: 0.530\n",
            "epoch: [3/30] -> loss: 0.505\n",
            "epoch: [4/30] -> loss: 0.493\n",
            "epoch: [5/30] -> loss: 0.480\n",
            "epoch: [6/30] -> loss: 0.485\n",
            "epoch: [7/30] -> loss: 0.476\n",
            "epoch: [8/30] -> loss: 0.475\n",
            "epoch: [9/30] -> loss: 0.472\n",
            "epoch: [10/30] -> loss: 0.475\n",
            "epoch: [11/30] -> loss: 0.472\n",
            "epoch: [12/30] -> loss: 0.472\n",
            "epoch: [13/30] -> loss: 0.466\n",
            "epoch: [14/30] -> loss: 0.468\n",
            "epoch: [15/30] -> loss: 0.472\n",
            "epoch: [16/30] -> loss: 0.467\n",
            "epoch: [17/30] -> loss: 0.467\n",
            "epoch: [18/30] -> loss: 0.464\n",
            "epoch: [19/30] -> loss: 0.458\n",
            "epoch: [20/30] -> loss: 0.464\n",
            "epoch: [21/30] -> loss: 0.466\n",
            "epoch: [22/30] -> loss: 0.460\n",
            "epoch: [23/30] -> loss: 0.463\n",
            "epoch: [24/30] -> loss: 0.457\n",
            "epoch: [25/30] -> loss: 0.464\n",
            "epoch: [26/30] -> loss: 0.453\n",
            "epoch: [27/30] -> loss: 0.458\n",
            "epoch: [28/30] -> loss: 0.455\n",
            "epoch: [29/30] -> loss: 0.456\n",
            "epoch: [30/30] -> loss: 0.460\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.460\n",
            "* Train accuracy: 85.52%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.674\n",
            "epoch: [2/30] -> loss: 0.540\n",
            "epoch: [3/30] -> loss: 0.508\n",
            "epoch: [4/30] -> loss: 0.501\n",
            "epoch: [5/30] -> loss: 0.488\n",
            "epoch: [6/30] -> loss: 0.478\n",
            "epoch: [7/30] -> loss: 0.479\n",
            "epoch: [8/30] -> loss: 0.474\n",
            "epoch: [9/30] -> loss: 0.474\n",
            "epoch: [10/30] -> loss: 0.469\n",
            "epoch: [11/30] -> loss: 0.473\n",
            "epoch: [12/30] -> loss: 0.471\n",
            "epoch: [13/30] -> loss: 0.467\n",
            "epoch: [14/30] -> loss: 0.465\n",
            "epoch: [15/30] -> loss: 0.461\n",
            "epoch: [16/30] -> loss: 0.466\n",
            "epoch: [17/30] -> loss: 0.463\n",
            "epoch: [18/30] -> loss: 0.458\n",
            "epoch: [19/30] -> loss: 0.466\n",
            "epoch: [20/30] -> loss: 0.461\n",
            "epoch: [21/30] -> loss: 0.479\n",
            "epoch: [22/30] -> loss: 0.461\n",
            "epoch: [23/30] -> loss: 0.454\n",
            "epoch: [24/30] -> loss: 0.463\n",
            "epoch: [25/30] -> loss: 0.457\n",
            "epoch: [26/30] -> loss: 0.455\n",
            "epoch: [27/30] -> loss: 0.464\n",
            "epoch: [28/30] -> loss: 0.455\n",
            "epoch: [29/30] -> loss: 0.455\n",
            "epoch: [30/30] -> loss: 0.459\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.459\n",
            "* Train accuracy: 84.81%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.658\n",
            "epoch: [2/30] -> loss: 0.533\n",
            "epoch: [3/30] -> loss: 0.506\n",
            "epoch: [4/30] -> loss: 0.494\n",
            "epoch: [5/30] -> loss: 0.488\n",
            "epoch: [6/30] -> loss: 0.481\n",
            "epoch: [7/30] -> loss: 0.473\n",
            "epoch: [8/30] -> loss: 0.473\n",
            "epoch: [9/30] -> loss: 0.471\n",
            "epoch: [10/30] -> loss: 0.471\n",
            "epoch: [11/30] -> loss: 0.466\n",
            "epoch: [12/30] -> loss: 0.470\n",
            "epoch: [13/30] -> loss: 0.468\n",
            "epoch: [14/30] -> loss: 0.466\n",
            "epoch: [15/30] -> loss: 0.463\n",
            "epoch: [16/30] -> loss: 0.466\n",
            "epoch: [17/30] -> loss: 0.465\n",
            "epoch: [18/30] -> loss: 0.461\n",
            "epoch: [19/30] -> loss: 0.471\n",
            "epoch: [20/30] -> loss: 0.473\n",
            "epoch: [21/30] -> loss: 0.464\n",
            "epoch: [22/30] -> loss: 0.459\n",
            "epoch: [23/30] -> loss: 0.464\n",
            "epoch: [24/30] -> loss: 0.460\n",
            "epoch: [25/30] -> loss: 0.460\n",
            "epoch: [26/30] -> loss: 0.473\n",
            "epoch: [27/30] -> loss: 0.460\n",
            "epoch: [28/30] -> loss: 0.459\n",
            "epoch: [29/30] -> loss: 0.457\n",
            "epoch: [30/30] -> loss: 0.457\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.457\n",
            "* Train accuracy: 85.57%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.673\n",
            "epoch: [2/30] -> loss: 0.538\n",
            "epoch: [3/30] -> loss: 0.510\n",
            "epoch: [4/30] -> loss: 0.491\n",
            "epoch: [5/30] -> loss: 0.483\n",
            "epoch: [6/30] -> loss: 0.477\n",
            "epoch: [7/30] -> loss: 0.472\n",
            "epoch: [8/30] -> loss: 0.471\n",
            "epoch: [9/30] -> loss: 0.466\n",
            "epoch: [10/30] -> loss: 0.465\n",
            "epoch: [11/30] -> loss: 0.465\n",
            "epoch: [12/30] -> loss: 0.463\n",
            "epoch: [13/30] -> loss: 0.461\n",
            "epoch: [14/30] -> loss: 0.458\n",
            "epoch: [15/30] -> loss: 0.462\n",
            "epoch: [16/30] -> loss: 0.459\n",
            "epoch: [17/30] -> loss: 0.457\n",
            "epoch: [18/30] -> loss: 0.454\n",
            "epoch: [19/30] -> loss: 0.453\n",
            "epoch: [20/30] -> loss: 0.455\n",
            "epoch: [21/30] -> loss: 0.454\n",
            "epoch: [22/30] -> loss: 0.451\n",
            "epoch: [23/30] -> loss: 0.453\n",
            "epoch: [24/30] -> loss: 0.450\n",
            "epoch: [25/30] -> loss: 0.450\n",
            "epoch: [26/30] -> loss: 0.452\n",
            "epoch: [27/30] -> loss: 0.449\n",
            "epoch: [28/30] -> loss: 0.451\n",
            "epoch: [29/30] -> loss: 0.448\n",
            "epoch: [30/30] -> loss: 0.448\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.448\n",
            "* Train accuracy: 85.48%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.670\n",
            "epoch: [2/30] -> loss: 0.536\n",
            "epoch: [3/30] -> loss: 0.503\n",
            "epoch: [4/30] -> loss: 0.492\n",
            "epoch: [5/30] -> loss: 0.481\n",
            "epoch: [6/30] -> loss: 0.478\n",
            "epoch: [7/30] -> loss: 0.472\n",
            "epoch: [8/30] -> loss: 0.468\n",
            "epoch: [9/30] -> loss: 0.467\n",
            "epoch: [10/30] -> loss: 0.465\n",
            "epoch: [11/30] -> loss: 0.465\n",
            "epoch: [12/30] -> loss: 0.462\n",
            "epoch: [13/30] -> loss: 0.465\n",
            "epoch: [14/30] -> loss: 0.458\n",
            "epoch: [15/30] -> loss: 0.460\n",
            "epoch: [16/30] -> loss: 0.456\n",
            "epoch: [17/30] -> loss: 0.459\n",
            "epoch: [18/30] -> loss: 0.459\n",
            "epoch: [19/30] -> loss: 0.455\n",
            "epoch: [20/30] -> loss: 0.455\n",
            "epoch: [21/30] -> loss: 0.451\n",
            "epoch: [22/30] -> loss: 0.452\n",
            "epoch: [23/30] -> loss: 0.452\n",
            "epoch: [24/30] -> loss: 0.454\n",
            "epoch: [25/30] -> loss: 0.453\n",
            "epoch: [26/30] -> loss: 0.449\n",
            "epoch: [27/30] -> loss: 0.453\n",
            "epoch: [28/30] -> loss: 0.452\n",
            "epoch: [29/30] -> loss: 0.451\n",
            "epoch: [30/30] -> loss: 0.448\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.448\n",
            "* Train accuracy: 85.67%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.668\n",
            "epoch: [2/30] -> loss: 0.535\n",
            "epoch: [3/30] -> loss: 0.500\n",
            "epoch: [4/30] -> loss: 0.489\n",
            "epoch: [5/30] -> loss: 0.485\n",
            "epoch: [6/30] -> loss: 0.473\n",
            "epoch: [7/30] -> loss: 0.474\n",
            "epoch: [8/30] -> loss: 0.468\n",
            "epoch: [9/30] -> loss: 0.470\n",
            "epoch: [10/30] -> loss: 0.464\n",
            "epoch: [11/30] -> loss: 0.462\n",
            "epoch: [12/30] -> loss: 0.461\n",
            "epoch: [13/30] -> loss: 0.456\n",
            "epoch: [14/30] -> loss: 0.458\n",
            "epoch: [15/30] -> loss: 0.455\n",
            "epoch: [16/30] -> loss: 0.453\n",
            "epoch: [17/30] -> loss: 0.453\n",
            "epoch: [18/30] -> loss: 0.457\n",
            "epoch: [19/30] -> loss: 0.458\n",
            "epoch: [20/30] -> loss: 0.452\n",
            "epoch: [21/30] -> loss: 0.454\n",
            "epoch: [22/30] -> loss: 0.452\n",
            "epoch: [23/30] -> loss: 0.453\n",
            "epoch: [24/30] -> loss: 0.452\n",
            "epoch: [25/30] -> loss: 0.454\n",
            "epoch: [26/30] -> loss: 0.453\n",
            "epoch: [27/30] -> loss: 0.450\n",
            "epoch: [28/30] -> loss: 0.447\n",
            "epoch: [29/30] -> loss: 0.449\n",
            "epoch: [30/30] -> loss: 0.448\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.448\n",
            "* Train accuracy: 85.56%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.672\n",
            "epoch: [2/30] -> loss: 0.539\n",
            "epoch: [3/30] -> loss: 0.506\n",
            "epoch: [4/30] -> loss: 0.489\n",
            "epoch: [5/30] -> loss: 0.485\n",
            "epoch: [6/30] -> loss: 0.475\n",
            "epoch: [7/30] -> loss: 0.471\n",
            "epoch: [8/30] -> loss: 0.469\n",
            "epoch: [9/30] -> loss: 0.463\n",
            "epoch: [10/30] -> loss: 0.466\n",
            "epoch: [11/30] -> loss: 0.461\n",
            "epoch: [12/30] -> loss: 0.461\n",
            "epoch: [13/30] -> loss: 0.456\n",
            "epoch: [14/30] -> loss: 0.459\n",
            "epoch: [15/30] -> loss: 0.458\n",
            "epoch: [16/30] -> loss: 0.458\n",
            "epoch: [17/30] -> loss: 0.454\n",
            "epoch: [18/30] -> loss: 0.452\n",
            "epoch: [19/30] -> loss: 0.456\n",
            "epoch: [20/30] -> loss: 0.453\n",
            "epoch: [21/30] -> loss: 0.456\n",
            "epoch: [22/30] -> loss: 0.453\n",
            "epoch: [23/30] -> loss: 0.453\n",
            "epoch: [24/30] -> loss: 0.454\n",
            "epoch: [25/30] -> loss: 0.454\n",
            "epoch: [26/30] -> loss: 0.448\n",
            "epoch: [27/30] -> loss: 0.450\n",
            "epoch: [28/30] -> loss: 0.452\n",
            "epoch: [29/30] -> loss: 0.450\n",
            "epoch: [30/30] -> loss: 0.448\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.448\n",
            "* Train accuracy: 84.97%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.687\n",
            "epoch: [2/30] -> loss: 0.544\n",
            "epoch: [3/30] -> loss: 0.512\n",
            "epoch: [4/30] -> loss: 0.494\n",
            "epoch: [5/30] -> loss: 0.485\n",
            "epoch: [6/30] -> loss: 0.478\n",
            "epoch: [7/30] -> loss: 0.472\n",
            "epoch: [8/30] -> loss: 0.469\n",
            "epoch: [9/30] -> loss: 0.469\n",
            "epoch: [10/30] -> loss: 0.467\n",
            "epoch: [11/30] -> loss: 0.466\n",
            "epoch: [12/30] -> loss: 0.462\n",
            "epoch: [13/30] -> loss: 0.458\n",
            "epoch: [14/30] -> loss: 0.460\n",
            "epoch: [15/30] -> loss: 0.462\n",
            "epoch: [16/30] -> loss: 0.457\n",
            "epoch: [17/30] -> loss: 0.456\n",
            "epoch: [18/30] -> loss: 0.455\n",
            "epoch: [19/30] -> loss: 0.453\n",
            "epoch: [20/30] -> loss: 0.451\n",
            "epoch: [21/30] -> loss: 0.456\n",
            "epoch: [22/30] -> loss: 0.452\n",
            "epoch: [23/30] -> loss: 0.451\n",
            "epoch: [24/30] -> loss: 0.451\n",
            "epoch: [25/30] -> loss: 0.456\n",
            "epoch: [26/30] -> loss: 0.450\n",
            "epoch: [27/30] -> loss: 0.449\n",
            "epoch: [28/30] -> loss: 0.449\n",
            "epoch: [29/30] -> loss: 0.449\n",
            "epoch: [30/30] -> loss: 0.449\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.449\n",
            "* Train accuracy: 85.90%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.734\n",
            "epoch: [2/30] -> loss: 0.585\n",
            "epoch: [3/30] -> loss: 0.539\n",
            "epoch: [4/30] -> loss: 0.518\n",
            "epoch: [5/30] -> loss: 0.504\n",
            "epoch: [6/30] -> loss: 0.495\n",
            "epoch: [7/30] -> loss: 0.485\n",
            "epoch: [8/30] -> loss: 0.479\n",
            "epoch: [9/30] -> loss: 0.474\n",
            "epoch: [10/30] -> loss: 0.471\n",
            "epoch: [11/30] -> loss: 0.466\n",
            "epoch: [12/30] -> loss: 0.465\n",
            "epoch: [13/30] -> loss: 0.463\n",
            "epoch: [14/30] -> loss: 0.459\n",
            "epoch: [15/30] -> loss: 0.459\n",
            "epoch: [16/30] -> loss: 0.458\n",
            "epoch: [17/30] -> loss: 0.455\n",
            "epoch: [18/30] -> loss: 0.453\n",
            "epoch: [19/30] -> loss: 0.453\n",
            "epoch: [20/30] -> loss: 0.453\n",
            "epoch: [21/30] -> loss: 0.453\n",
            "epoch: [22/30] -> loss: 0.451\n",
            "epoch: [23/30] -> loss: 0.448\n",
            "epoch: [24/30] -> loss: 0.448\n",
            "epoch: [25/30] -> loss: 0.448\n",
            "epoch: [26/30] -> loss: 0.447\n",
            "epoch: [27/30] -> loss: 0.446\n",
            "epoch: [28/30] -> loss: 0.445\n",
            "epoch: [29/30] -> loss: 0.444\n",
            "epoch: [30/30] -> loss: 0.444\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.444\n",
            "* Train accuracy: 85.30%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.738\n",
            "epoch: [2/30] -> loss: 0.588\n",
            "epoch: [3/30] -> loss: 0.540\n",
            "epoch: [4/30] -> loss: 0.517\n",
            "epoch: [5/30] -> loss: 0.501\n",
            "epoch: [6/30] -> loss: 0.493\n",
            "epoch: [7/30] -> loss: 0.485\n",
            "epoch: [8/30] -> loss: 0.480\n",
            "epoch: [9/30] -> loss: 0.475\n",
            "epoch: [10/30] -> loss: 0.472\n",
            "epoch: [11/30] -> loss: 0.469\n",
            "epoch: [12/30] -> loss: 0.465\n",
            "epoch: [13/30] -> loss: 0.461\n",
            "epoch: [14/30] -> loss: 0.460\n",
            "epoch: [15/30] -> loss: 0.459\n",
            "epoch: [16/30] -> loss: 0.457\n",
            "epoch: [17/30] -> loss: 0.456\n",
            "epoch: [18/30] -> loss: 0.455\n",
            "epoch: [19/30] -> loss: 0.454\n",
            "epoch: [20/30] -> loss: 0.453\n",
            "epoch: [21/30] -> loss: 0.452\n",
            "epoch: [22/30] -> loss: 0.450\n",
            "epoch: [23/30] -> loss: 0.451\n",
            "epoch: [24/30] -> loss: 0.449\n",
            "epoch: [25/30] -> loss: 0.450\n",
            "epoch: [26/30] -> loss: 0.447\n",
            "epoch: [27/30] -> loss: 0.447\n",
            "epoch: [28/30] -> loss: 0.446\n",
            "epoch: [29/30] -> loss: 0.445\n",
            "epoch: [30/30] -> loss: 0.445\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.445\n",
            "* Train accuracy: 84.97%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.723\n",
            "epoch: [2/30] -> loss: 0.581\n",
            "epoch: [3/30] -> loss: 0.539\n",
            "epoch: [4/30] -> loss: 0.518\n",
            "epoch: [5/30] -> loss: 0.501\n",
            "epoch: [6/30] -> loss: 0.492\n",
            "epoch: [7/30] -> loss: 0.485\n",
            "epoch: [8/30] -> loss: 0.477\n",
            "epoch: [9/30] -> loss: 0.474\n",
            "epoch: [10/30] -> loss: 0.470\n",
            "epoch: [11/30] -> loss: 0.467\n",
            "epoch: [12/30] -> loss: 0.466\n",
            "epoch: [13/30] -> loss: 0.462\n",
            "epoch: [14/30] -> loss: 0.459\n",
            "epoch: [15/30] -> loss: 0.458\n",
            "epoch: [16/30] -> loss: 0.456\n",
            "epoch: [17/30] -> loss: 0.455\n",
            "epoch: [18/30] -> loss: 0.453\n",
            "epoch: [19/30] -> loss: 0.454\n",
            "epoch: [20/30] -> loss: 0.454\n",
            "epoch: [21/30] -> loss: 0.450\n",
            "epoch: [22/30] -> loss: 0.450\n",
            "epoch: [23/30] -> loss: 0.449\n",
            "epoch: [24/30] -> loss: 0.449\n",
            "epoch: [25/30] -> loss: 0.447\n",
            "epoch: [26/30] -> loss: 0.447\n",
            "epoch: [27/30] -> loss: 0.447\n",
            "epoch: [28/30] -> loss: 0.446\n",
            "epoch: [29/30] -> loss: 0.444\n",
            "epoch: [30/30] -> loss: 0.444\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.444\n",
            "* Train accuracy: 85.27%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.708\n",
            "epoch: [2/30] -> loss: 0.579\n",
            "epoch: [3/30] -> loss: 0.535\n",
            "epoch: [4/30] -> loss: 0.513\n",
            "epoch: [5/30] -> loss: 0.501\n",
            "epoch: [6/30] -> loss: 0.491\n",
            "epoch: [7/30] -> loss: 0.485\n",
            "epoch: [8/30] -> loss: 0.478\n",
            "epoch: [9/30] -> loss: 0.473\n",
            "epoch: [10/30] -> loss: 0.471\n",
            "epoch: [11/30] -> loss: 0.467\n",
            "epoch: [12/30] -> loss: 0.465\n",
            "epoch: [13/30] -> loss: 0.464\n",
            "epoch: [14/30] -> loss: 0.460\n",
            "epoch: [15/30] -> loss: 0.460\n",
            "epoch: [16/30] -> loss: 0.456\n",
            "epoch: [17/30] -> loss: 0.456\n",
            "epoch: [18/30] -> loss: 0.455\n",
            "epoch: [19/30] -> loss: 0.451\n",
            "epoch: [20/30] -> loss: 0.452\n",
            "epoch: [21/30] -> loss: 0.451\n",
            "epoch: [22/30] -> loss: 0.450\n",
            "epoch: [23/30] -> loss: 0.448\n",
            "epoch: [24/30] -> loss: 0.448\n",
            "epoch: [25/30] -> loss: 0.448\n",
            "epoch: [26/30] -> loss: 0.446\n",
            "epoch: [27/30] -> loss: 0.446\n",
            "epoch: [28/30] -> loss: 0.446\n",
            "epoch: [29/30] -> loss: 0.444\n",
            "epoch: [30/30] -> loss: 0.445\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.445\n",
            "* Train accuracy: 85.09%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.727\n",
            "epoch: [2/30] -> loss: 0.585\n",
            "epoch: [3/30] -> loss: 0.540\n",
            "epoch: [4/30] -> loss: 0.516\n",
            "epoch: [5/30] -> loss: 0.501\n",
            "epoch: [6/30] -> loss: 0.492\n",
            "epoch: [7/30] -> loss: 0.485\n",
            "epoch: [8/30] -> loss: 0.480\n",
            "epoch: [9/30] -> loss: 0.475\n",
            "epoch: [10/30] -> loss: 0.471\n",
            "epoch: [11/30] -> loss: 0.466\n",
            "epoch: [12/30] -> loss: 0.464\n",
            "epoch: [13/30] -> loss: 0.462\n",
            "epoch: [14/30] -> loss: 0.462\n",
            "epoch: [15/30] -> loss: 0.459\n",
            "epoch: [16/30] -> loss: 0.456\n",
            "epoch: [17/30] -> loss: 0.455\n",
            "epoch: [18/30] -> loss: 0.454\n",
            "epoch: [19/30] -> loss: 0.452\n",
            "epoch: [20/30] -> loss: 0.453\n",
            "epoch: [21/30] -> loss: 0.450\n",
            "epoch: [22/30] -> loss: 0.450\n",
            "epoch: [23/30] -> loss: 0.449\n",
            "epoch: [24/30] -> loss: 0.447\n",
            "epoch: [25/30] -> loss: 0.447\n",
            "epoch: [26/30] -> loss: 0.448\n",
            "epoch: [27/30] -> loss: 0.445\n",
            "epoch: [28/30] -> loss: 0.445\n",
            "epoch: [29/30] -> loss: 0.446\n",
            "epoch: [30/30] -> loss: 0.446\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.446\n",
            "* Train accuracy: 84.99%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.674\n",
            "epoch: [2/20] -> loss: 0.536\n",
            "epoch: [3/20] -> loss: 0.506\n",
            "epoch: [4/20] -> loss: 0.491\n",
            "epoch: [5/20] -> loss: 0.481\n",
            "epoch: [6/20] -> loss: 0.475\n",
            "epoch: [7/20] -> loss: 0.471\n",
            "epoch: [8/20] -> loss: 0.466\n",
            "epoch: [9/20] -> loss: 0.465\n",
            "epoch: [10/20] -> loss: 0.463\n",
            "epoch: [11/20] -> loss: 0.462\n",
            "epoch: [12/20] -> loss: 0.460\n",
            "epoch: [13/20] -> loss: 0.459\n",
            "epoch: [14/20] -> loss: 0.458\n",
            "epoch: [15/20] -> loss: 0.458\n",
            "epoch: [16/20] -> loss: 0.455\n",
            "epoch: [17/20] -> loss: 0.453\n",
            "epoch: [18/20] -> loss: 0.452\n",
            "epoch: [19/20] -> loss: 0.453\n",
            "epoch: [20/20] -> loss: 0.455\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.455\n",
            "* Train accuracy: 84.64%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.678\n",
            "epoch: [2/20] -> loss: 0.540\n",
            "epoch: [3/20] -> loss: 0.508\n",
            "epoch: [4/20] -> loss: 0.490\n",
            "epoch: [5/20] -> loss: 0.480\n",
            "epoch: [6/20] -> loss: 0.480\n",
            "epoch: [7/20] -> loss: 0.472\n",
            "epoch: [8/20] -> loss: 0.471\n",
            "epoch: [9/20] -> loss: 0.469\n",
            "epoch: [10/20] -> loss: 0.469\n",
            "epoch: [11/20] -> loss: 0.459\n",
            "epoch: [12/20] -> loss: 0.461\n",
            "epoch: [13/20] -> loss: 0.460\n",
            "epoch: [14/20] -> loss: 0.458\n",
            "epoch: [15/20] -> loss: 0.454\n",
            "epoch: [16/20] -> loss: 0.456\n",
            "epoch: [17/20] -> loss: 0.458\n",
            "epoch: [18/20] -> loss: 0.454\n",
            "epoch: [19/20] -> loss: 0.455\n",
            "epoch: [20/20] -> loss: 0.453\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.453\n",
            "* Train accuracy: 84.96%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.684\n",
            "epoch: [2/20] -> loss: 0.541\n",
            "epoch: [3/20] -> loss: 0.507\n",
            "epoch: [4/20] -> loss: 0.493\n",
            "epoch: [5/20] -> loss: 0.483\n",
            "epoch: [6/20] -> loss: 0.477\n",
            "epoch: [7/20] -> loss: 0.470\n",
            "epoch: [8/20] -> loss: 0.468\n",
            "epoch: [9/20] -> loss: 0.465\n",
            "epoch: [10/20] -> loss: 0.461\n",
            "epoch: [11/20] -> loss: 0.462\n",
            "epoch: [12/20] -> loss: 0.461\n",
            "epoch: [13/20] -> loss: 0.462\n",
            "epoch: [14/20] -> loss: 0.455\n",
            "epoch: [15/20] -> loss: 0.457\n",
            "epoch: [16/20] -> loss: 0.459\n",
            "epoch: [17/20] -> loss: 0.455\n",
            "epoch: [18/20] -> loss: 0.454\n",
            "epoch: [19/20] -> loss: 0.454\n",
            "epoch: [20/20] -> loss: 0.453\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.453\n",
            "* Train accuracy: 85.14%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.695\n",
            "epoch: [2/20] -> loss: 0.539\n",
            "epoch: [3/20] -> loss: 0.509\n",
            "epoch: [4/20] -> loss: 0.492\n",
            "epoch: [5/20] -> loss: 0.482\n",
            "epoch: [6/20] -> loss: 0.475\n",
            "epoch: [7/20] -> loss: 0.475\n",
            "epoch: [8/20] -> loss: 0.467\n",
            "epoch: [9/20] -> loss: 0.467\n",
            "epoch: [10/20] -> loss: 0.464\n",
            "epoch: [11/20] -> loss: 0.460\n",
            "epoch: [12/20] -> loss: 0.461\n",
            "epoch: [13/20] -> loss: 0.459\n",
            "epoch: [14/20] -> loss: 0.456\n",
            "epoch: [15/20] -> loss: 0.453\n",
            "epoch: [16/20] -> loss: 0.455\n",
            "epoch: [17/20] -> loss: 0.455\n",
            "epoch: [18/20] -> loss: 0.454\n",
            "epoch: [19/20] -> loss: 0.456\n",
            "epoch: [20/20] -> loss: 0.452\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.452\n",
            "* Train accuracy: 85.40%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0005, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.658\n",
            "epoch: [2/20] -> loss: 0.536\n",
            "epoch: [3/20] -> loss: 0.504\n",
            "epoch: [4/20] -> loss: 0.491\n",
            "epoch: [5/20] -> loss: 0.479\n",
            "epoch: [6/20] -> loss: 0.477\n",
            "epoch: [7/20] -> loss: 0.469\n",
            "epoch: [8/20] -> loss: 0.467\n",
            "epoch: [9/20] -> loss: 0.464\n",
            "epoch: [10/20] -> loss: 0.464\n",
            "epoch: [11/20] -> loss: 0.459\n",
            "epoch: [12/20] -> loss: 0.460\n",
            "epoch: [13/20] -> loss: 0.460\n",
            "epoch: [14/20] -> loss: 0.460\n",
            "epoch: [15/20] -> loss: 0.459\n",
            "epoch: [16/20] -> loss: 0.454\n",
            "epoch: [17/20] -> loss: 0.453\n",
            "epoch: [18/20] -> loss: 0.455\n",
            "epoch: [19/20] -> loss: 0.455\n",
            "epoch: [20/20] -> loss: 0.453\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.453\n",
            "* Train accuracy: 84.66%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.734\n",
            "epoch: [2/20] -> loss: 0.589\n",
            "epoch: [3/20] -> loss: 0.544\n",
            "epoch: [4/20] -> loss: 0.521\n",
            "epoch: [5/20] -> loss: 0.505\n",
            "epoch: [6/20] -> loss: 0.497\n",
            "epoch: [7/20] -> loss: 0.488\n",
            "epoch: [8/20] -> loss: 0.482\n",
            "epoch: [9/20] -> loss: 0.477\n",
            "epoch: [10/20] -> loss: 0.473\n",
            "epoch: [11/20] -> loss: 0.469\n",
            "epoch: [12/20] -> loss: 0.469\n",
            "epoch: [13/20] -> loss: 0.465\n",
            "epoch: [14/20] -> loss: 0.464\n",
            "epoch: [15/20] -> loss: 0.461\n",
            "epoch: [16/20] -> loss: 0.460\n",
            "epoch: [17/20] -> loss: 0.459\n",
            "epoch: [18/20] -> loss: 0.457\n",
            "epoch: [19/20] -> loss: 0.456\n",
            "epoch: [20/20] -> loss: 0.455\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.455\n",
            "* Train accuracy: 84.31%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.734\n",
            "epoch: [2/20] -> loss: 0.585\n",
            "epoch: [3/20] -> loss: 0.541\n",
            "epoch: [4/20] -> loss: 0.519\n",
            "epoch: [5/20] -> loss: 0.505\n",
            "epoch: [6/20] -> loss: 0.495\n",
            "epoch: [7/20] -> loss: 0.487\n",
            "epoch: [8/20] -> loss: 0.483\n",
            "epoch: [9/20] -> loss: 0.476\n",
            "epoch: [10/20] -> loss: 0.474\n",
            "epoch: [11/20] -> loss: 0.471\n",
            "epoch: [12/20] -> loss: 0.468\n",
            "epoch: [13/20] -> loss: 0.467\n",
            "epoch: [14/20] -> loss: 0.463\n",
            "epoch: [15/20] -> loss: 0.463\n",
            "epoch: [16/20] -> loss: 0.460\n",
            "epoch: [17/20] -> loss: 0.459\n",
            "epoch: [18/20] -> loss: 0.456\n",
            "epoch: [19/20] -> loss: 0.458\n",
            "epoch: [20/20] -> loss: 0.454\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.454\n",
            "* Train accuracy: 84.33%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.734\n",
            "epoch: [2/20] -> loss: 0.586\n",
            "epoch: [3/20] -> loss: 0.541\n",
            "epoch: [4/20] -> loss: 0.518\n",
            "epoch: [5/20] -> loss: 0.504\n",
            "epoch: [6/20] -> loss: 0.494\n",
            "epoch: [7/20] -> loss: 0.488\n",
            "epoch: [8/20] -> loss: 0.483\n",
            "epoch: [9/20] -> loss: 0.478\n",
            "epoch: [10/20] -> loss: 0.475\n",
            "epoch: [11/20] -> loss: 0.469\n",
            "epoch: [12/20] -> loss: 0.469\n",
            "epoch: [13/20] -> loss: 0.465\n",
            "epoch: [14/20] -> loss: 0.464\n",
            "epoch: [15/20] -> loss: 0.462\n",
            "epoch: [16/20] -> loss: 0.461\n",
            "epoch: [17/20] -> loss: 0.460\n",
            "epoch: [18/20] -> loss: 0.456\n",
            "epoch: [19/20] -> loss: 0.456\n",
            "epoch: [20/20] -> loss: 0.454\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.454\n",
            "* Train accuracy: 84.28%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.732\n",
            "epoch: [2/20] -> loss: 0.588\n",
            "epoch: [3/20] -> loss: 0.543\n",
            "epoch: [4/20] -> loss: 0.521\n",
            "epoch: [5/20] -> loss: 0.506\n",
            "epoch: [6/20] -> loss: 0.495\n",
            "epoch: [7/20] -> loss: 0.488\n",
            "epoch: [8/20] -> loss: 0.483\n",
            "epoch: [9/20] -> loss: 0.478\n",
            "epoch: [10/20] -> loss: 0.473\n",
            "epoch: [11/20] -> loss: 0.471\n",
            "epoch: [12/20] -> loss: 0.469\n",
            "epoch: [13/20] -> loss: 0.468\n",
            "epoch: [14/20] -> loss: 0.463\n",
            "epoch: [15/20] -> loss: 0.463\n",
            "epoch: [16/20] -> loss: 0.460\n",
            "epoch: [17/20] -> loss: 0.461\n",
            "epoch: [18/20] -> loss: 0.458\n",
            "epoch: [19/20] -> loss: 0.456\n",
            "epoch: [20/20] -> loss: 0.457\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.457\n",
            "* Train accuracy: 84.27%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.750\n",
            "epoch: [2/20] -> loss: 0.591\n",
            "epoch: [3/20] -> loss: 0.545\n",
            "epoch: [4/20] -> loss: 0.520\n",
            "epoch: [5/20] -> loss: 0.505\n",
            "epoch: [6/20] -> loss: 0.497\n",
            "epoch: [7/20] -> loss: 0.489\n",
            "epoch: [8/20] -> loss: 0.483\n",
            "epoch: [9/20] -> loss: 0.479\n",
            "epoch: [10/20] -> loss: 0.474\n",
            "epoch: [11/20] -> loss: 0.471\n",
            "epoch: [12/20] -> loss: 0.467\n",
            "epoch: [13/20] -> loss: 0.467\n",
            "epoch: [14/20] -> loss: 0.465\n",
            "epoch: [15/20] -> loss: 0.462\n",
            "epoch: [16/20] -> loss: 0.461\n",
            "epoch: [17/20] -> loss: 0.458\n",
            "epoch: [18/20] -> loss: 0.457\n",
            "epoch: [19/20] -> loss: 0.456\n",
            "epoch: [20/20] -> loss: 0.454\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.454\n",
            "* Train accuracy: 84.29%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.895\n",
            "epoch: [2/20] -> loss: 0.801\n",
            "epoch: [3/20] -> loss: 0.724\n",
            "epoch: [4/20] -> loss: 0.675\n",
            "epoch: [5/20] -> loss: 0.644\n",
            "epoch: [6/20] -> loss: 0.614\n",
            "epoch: [7/20] -> loss: 0.589\n",
            "epoch: [8/20] -> loss: 0.579\n",
            "epoch: [9/20] -> loss: 0.563\n",
            "epoch: [10/20] -> loss: 0.552\n",
            "epoch: [11/20] -> loss: 0.546\n",
            "epoch: [12/20] -> loss: 0.540\n",
            "epoch: [13/20] -> loss: 0.529\n",
            "epoch: [14/20] -> loss: 0.528\n",
            "epoch: [15/20] -> loss: 0.521\n",
            "epoch: [16/20] -> loss: 0.511\n",
            "epoch: [17/20] -> loss: 0.511\n",
            "epoch: [18/20] -> loss: 0.511\n",
            "epoch: [19/20] -> loss: 0.511\n",
            "epoch: [20/20] -> loss: 0.505\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.505\n",
            "* Train accuracy: 82.16%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.887\n",
            "epoch: [2/20] -> loss: 0.792\n",
            "epoch: [3/20] -> loss: 0.721\n",
            "epoch: [4/20] -> loss: 0.671\n",
            "epoch: [5/20] -> loss: 0.636\n",
            "epoch: [6/20] -> loss: 0.609\n",
            "epoch: [7/20] -> loss: 0.588\n",
            "epoch: [8/20] -> loss: 0.579\n",
            "epoch: [9/20] -> loss: 0.561\n",
            "epoch: [10/20] -> loss: 0.552\n",
            "epoch: [11/20] -> loss: 0.547\n",
            "epoch: [12/20] -> loss: 0.539\n",
            "epoch: [13/20] -> loss: 0.531\n",
            "epoch: [14/20] -> loss: 0.525\n",
            "epoch: [15/20] -> loss: 0.520\n",
            "epoch: [16/20] -> loss: 0.520\n",
            "epoch: [17/20] -> loss: 0.515\n",
            "epoch: [18/20] -> loss: 0.512\n",
            "epoch: [19/20] -> loss: 0.508\n",
            "epoch: [20/20] -> loss: 0.510\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.510\n",
            "* Train accuracy: 82.19%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.905\n",
            "epoch: [2/20] -> loss: 0.802\n",
            "epoch: [3/20] -> loss: 0.732\n",
            "epoch: [4/20] -> loss: 0.679\n",
            "epoch: [5/20] -> loss: 0.641\n",
            "epoch: [6/20] -> loss: 0.618\n",
            "epoch: [7/20] -> loss: 0.599\n",
            "epoch: [8/20] -> loss: 0.580\n",
            "epoch: [9/20] -> loss: 0.573\n",
            "epoch: [10/20] -> loss: 0.558\n",
            "epoch: [11/20] -> loss: 0.547\n",
            "epoch: [12/20] -> loss: 0.543\n",
            "epoch: [13/20] -> loss: 0.534\n",
            "epoch: [14/20] -> loss: 0.529\n",
            "epoch: [15/20] -> loss: 0.526\n",
            "epoch: [16/20] -> loss: 0.519\n",
            "epoch: [17/20] -> loss: 0.517\n",
            "epoch: [18/20] -> loss: 0.517\n",
            "epoch: [19/20] -> loss: 0.513\n",
            "epoch: [20/20] -> loss: 0.507\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.507\n",
            "* Train accuracy: 82.12%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.856\n",
            "epoch: [2/20] -> loss: 0.772\n",
            "epoch: [3/20] -> loss: 0.706\n",
            "epoch: [4/20] -> loss: 0.661\n",
            "epoch: [5/20] -> loss: 0.628\n",
            "epoch: [6/20] -> loss: 0.602\n",
            "epoch: [7/20] -> loss: 0.587\n",
            "epoch: [8/20] -> loss: 0.576\n",
            "epoch: [9/20] -> loss: 0.559\n",
            "epoch: [10/20] -> loss: 0.553\n",
            "epoch: [11/20] -> loss: 0.547\n",
            "epoch: [12/20] -> loss: 0.534\n",
            "epoch: [13/20] -> loss: 0.529\n",
            "epoch: [14/20] -> loss: 0.524\n",
            "epoch: [15/20] -> loss: 0.519\n",
            "epoch: [16/20] -> loss: 0.517\n",
            "epoch: [17/20] -> loss: 0.517\n",
            "epoch: [18/20] -> loss: 0.510\n",
            "epoch: [19/20] -> loss: 0.506\n",
            "epoch: [20/20] -> loss: 0.501\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.501\n",
            "* Train accuracy: 82.28%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.898\n",
            "epoch: [2/20] -> loss: 0.795\n",
            "epoch: [3/20] -> loss: 0.726\n",
            "epoch: [4/20] -> loss: 0.674\n",
            "epoch: [5/20] -> loss: 0.638\n",
            "epoch: [6/20] -> loss: 0.607\n",
            "epoch: [7/20] -> loss: 0.590\n",
            "epoch: [8/20] -> loss: 0.572\n",
            "epoch: [9/20] -> loss: 0.562\n",
            "epoch: [10/20] -> loss: 0.552\n",
            "epoch: [11/20] -> loss: 0.547\n",
            "epoch: [12/20] -> loss: 0.536\n",
            "epoch: [13/20] -> loss: 0.533\n",
            "epoch: [14/20] -> loss: 0.529\n",
            "epoch: [15/20] -> loss: 0.525\n",
            "epoch: [16/20] -> loss: 0.518\n",
            "epoch: [17/20] -> loss: 0.513\n",
            "epoch: [18/20] -> loss: 0.514\n",
            "epoch: [19/20] -> loss: 0.509\n",
            "epoch: [20/20] -> loss: 0.502\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.502\n",
            "* Train accuracy: 82.42%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.694\n",
            "epoch: [2/20] -> loss: 0.545\n",
            "epoch: [3/20] -> loss: 0.507\n",
            "epoch: [4/20] -> loss: 0.500\n",
            "epoch: [5/20] -> loss: 0.490\n",
            "epoch: [6/20] -> loss: 0.481\n",
            "epoch: [7/20] -> loss: 0.476\n",
            "epoch: [8/20] -> loss: 0.477\n",
            "epoch: [9/20] -> loss: 0.473\n",
            "epoch: [10/20] -> loss: 0.477\n",
            "epoch: [11/20] -> loss: 0.473\n",
            "epoch: [12/20] -> loss: 0.475\n",
            "epoch: [13/20] -> loss: 0.468\n",
            "epoch: [14/20] -> loss: 0.465\n",
            "epoch: [15/20] -> loss: 0.470\n",
            "epoch: [16/20] -> loss: 0.468\n",
            "epoch: [17/20] -> loss: 0.464\n",
            "epoch: [18/20] -> loss: 0.473\n",
            "epoch: [19/20] -> loss: 0.479\n",
            "epoch: [20/20] -> loss: 0.468\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.468\n",
            "* Train accuracy: 85.54%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.676\n",
            "epoch: [2/20] -> loss: 0.537\n",
            "epoch: [3/20] -> loss: 0.511\n",
            "epoch: [4/20] -> loss: 0.492\n",
            "epoch: [5/20] -> loss: 0.484\n",
            "epoch: [6/20] -> loss: 0.482\n",
            "epoch: [7/20] -> loss: 0.477\n",
            "epoch: [8/20] -> loss: 0.477\n",
            "epoch: [9/20] -> loss: 0.485\n",
            "epoch: [10/20] -> loss: 0.469\n",
            "epoch: [11/20] -> loss: 0.468\n",
            "epoch: [12/20] -> loss: 0.465\n",
            "epoch: [13/20] -> loss: 0.463\n",
            "epoch: [14/20] -> loss: 0.460\n",
            "epoch: [15/20] -> loss: 0.462\n",
            "epoch: [16/20] -> loss: 0.461\n",
            "epoch: [17/20] -> loss: 0.465\n",
            "epoch: [18/20] -> loss: 0.461\n",
            "epoch: [19/20] -> loss: 0.461\n",
            "epoch: [20/20] -> loss: 0.463\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.463\n",
            "* Train accuracy: 85.29%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.668\n",
            "epoch: [2/20] -> loss: 0.537\n",
            "epoch: [3/20] -> loss: 0.503\n",
            "epoch: [4/20] -> loss: 0.493\n",
            "epoch: [5/20] -> loss: 0.488\n",
            "epoch: [6/20] -> loss: 0.479\n",
            "epoch: [7/20] -> loss: 0.480\n",
            "epoch: [8/20] -> loss: 0.485\n",
            "epoch: [9/20] -> loss: 0.476\n",
            "epoch: [10/20] -> loss: 0.479\n",
            "epoch: [11/20] -> loss: 0.471\n",
            "epoch: [12/20] -> loss: 0.470\n",
            "epoch: [13/20] -> loss: 0.462\n",
            "epoch: [14/20] -> loss: 0.470\n",
            "epoch: [15/20] -> loss: 0.463\n",
            "epoch: [16/20] -> loss: 0.465\n",
            "epoch: [17/20] -> loss: 0.469\n",
            "epoch: [18/20] -> loss: 0.475\n",
            "epoch: [19/20] -> loss: 0.460\n",
            "epoch: [20/20] -> loss: 0.457\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.457\n",
            "* Train accuracy: 85.47%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.704\n",
            "epoch: [2/20] -> loss: 0.557\n",
            "epoch: [3/20] -> loss: 0.511\n",
            "epoch: [4/20] -> loss: 0.503\n",
            "epoch: [5/20] -> loss: 0.489\n",
            "epoch: [6/20] -> loss: 0.485\n",
            "epoch: [7/20] -> loss: 0.478\n",
            "epoch: [8/20] -> loss: 0.483\n",
            "epoch: [9/20] -> loss: 0.475\n",
            "epoch: [10/20] -> loss: 0.474\n",
            "epoch: [11/20] -> loss: 0.466\n",
            "epoch: [12/20] -> loss: 0.468\n",
            "epoch: [13/20] -> loss: 0.468\n",
            "epoch: [14/20] -> loss: 0.466\n",
            "epoch: [15/20] -> loss: 0.467\n",
            "epoch: [16/20] -> loss: 0.468\n",
            "epoch: [17/20] -> loss: 0.466\n",
            "epoch: [18/20] -> loss: 0.462\n",
            "epoch: [19/20] -> loss: 0.466\n",
            "epoch: [20/20] -> loss: 0.465\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.465\n",
            "* Train accuracy: 85.08%\n",
            "Start training SVM model with [epoch: 20, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/20] -> loss: 0.670\n",
            "epoch: [2/20] -> loss: 0.535\n",
            "epoch: [3/20] -> loss: 0.503\n",
            "epoch: [4/20] -> loss: 0.490\n",
            "epoch: [5/20] -> loss: 0.488\n",
            "epoch: [6/20] -> loss: 0.481\n",
            "epoch: [7/20] -> loss: 0.474\n",
            "epoch: [8/20] -> loss: 0.482\n",
            "epoch: [9/20] -> loss: 0.476\n",
            "epoch: [10/20] -> loss: 0.478\n",
            "epoch: [11/20] -> loss: 0.465\n",
            "epoch: [12/20] -> loss: 0.468\n",
            "epoch: [13/20] -> loss: 0.461\n",
            "epoch: [14/20] -> loss: 0.465\n",
            "epoch: [15/20] -> loss: 0.470\n",
            "epoch: [16/20] -> loss: 0.461\n",
            "epoch: [17/20] -> loss: 0.465\n",
            "epoch: [18/20] -> loss: 0.464\n",
            "epoch: [19/20] -> loss: 0.461\n",
            "epoch: [20/20] -> loss: 0.460\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.460\n",
            "* Train accuracy: 85.31%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.806\n",
            "epoch: [2/30] -> loss: 0.692\n",
            "epoch: [3/30] -> loss: 0.627\n",
            "epoch: [4/30] -> loss: 0.591\n",
            "epoch: [5/30] -> loss: 0.567\n",
            "epoch: [6/30] -> loss: 0.548\n",
            "epoch: [7/30] -> loss: 0.538\n",
            "epoch: [8/30] -> loss: 0.526\n",
            "epoch: [9/30] -> loss: 0.517\n",
            "epoch: [10/30] -> loss: 0.511\n",
            "epoch: [11/30] -> loss: 0.506\n",
            "epoch: [12/30] -> loss: 0.501\n",
            "epoch: [13/30] -> loss: 0.498\n",
            "epoch: [14/30] -> loss: 0.493\n",
            "epoch: [15/30] -> loss: 0.490\n",
            "epoch: [16/30] -> loss: 0.487\n",
            "epoch: [17/30] -> loss: 0.485\n",
            "epoch: [18/30] -> loss: 0.484\n",
            "epoch: [19/30] -> loss: 0.482\n",
            "epoch: [20/30] -> loss: 0.480\n",
            "epoch: [21/30] -> loss: 0.477\n",
            "epoch: [22/30] -> loss: 0.475\n",
            "epoch: [23/30] -> loss: 0.474\n",
            "epoch: [24/30] -> loss: 0.472\n",
            "epoch: [25/30] -> loss: 0.472\n",
            "epoch: [26/30] -> loss: 0.468\n",
            "epoch: [27/30] -> loss: 0.469\n",
            "epoch: [28/30] -> loss: 0.468\n",
            "epoch: [29/30] -> loss: 0.466\n",
            "epoch: [30/30] -> loss: 0.466\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.466\n",
            "* Train accuracy: 83.83%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.834\n",
            "epoch: [2/30] -> loss: 0.704\n",
            "epoch: [3/30] -> loss: 0.634\n",
            "epoch: [4/30] -> loss: 0.594\n",
            "epoch: [5/30] -> loss: 0.568\n",
            "epoch: [6/30] -> loss: 0.548\n",
            "epoch: [7/30] -> loss: 0.537\n",
            "epoch: [8/30] -> loss: 0.527\n",
            "epoch: [9/30] -> loss: 0.518\n",
            "epoch: [10/30] -> loss: 0.511\n",
            "epoch: [11/30] -> loss: 0.507\n",
            "epoch: [12/30] -> loss: 0.504\n",
            "epoch: [13/30] -> loss: 0.498\n",
            "epoch: [14/30] -> loss: 0.493\n",
            "epoch: [15/30] -> loss: 0.491\n",
            "epoch: [16/30] -> loss: 0.488\n",
            "epoch: [17/30] -> loss: 0.486\n",
            "epoch: [18/30] -> loss: 0.483\n",
            "epoch: [19/30] -> loss: 0.481\n",
            "epoch: [20/30] -> loss: 0.479\n",
            "epoch: [21/30] -> loss: 0.477\n",
            "epoch: [22/30] -> loss: 0.477\n",
            "epoch: [23/30] -> loss: 0.475\n",
            "epoch: [24/30] -> loss: 0.473\n",
            "epoch: [25/30] -> loss: 0.470\n",
            "epoch: [26/30] -> loss: 0.470\n",
            "epoch: [27/30] -> loss: 0.470\n",
            "epoch: [28/30] -> loss: 0.469\n",
            "epoch: [29/30] -> loss: 0.468\n",
            "epoch: [30/30] -> loss: 0.469\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.469\n",
            "* Train accuracy: 83.86%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.866\n",
            "epoch: [2/30] -> loss: 0.712\n",
            "epoch: [3/30] -> loss: 0.642\n",
            "epoch: [4/30] -> loss: 0.603\n",
            "epoch: [5/30] -> loss: 0.576\n",
            "epoch: [6/30] -> loss: 0.557\n",
            "epoch: [7/30] -> loss: 0.543\n",
            "epoch: [8/30] -> loss: 0.530\n",
            "epoch: [9/30] -> loss: 0.523\n",
            "epoch: [10/30] -> loss: 0.515\n",
            "epoch: [11/30] -> loss: 0.510\n",
            "epoch: [12/30] -> loss: 0.507\n",
            "epoch: [13/30] -> loss: 0.501\n",
            "epoch: [14/30] -> loss: 0.496\n",
            "epoch: [15/30] -> loss: 0.492\n",
            "epoch: [16/30] -> loss: 0.490\n",
            "epoch: [17/30] -> loss: 0.486\n",
            "epoch: [18/30] -> loss: 0.486\n",
            "epoch: [19/30] -> loss: 0.482\n",
            "epoch: [20/30] -> loss: 0.482\n",
            "epoch: [21/30] -> loss: 0.480\n",
            "epoch: [22/30] -> loss: 0.478\n",
            "epoch: [23/30] -> loss: 0.477\n",
            "epoch: [24/30] -> loss: 0.474\n",
            "epoch: [25/30] -> loss: 0.473\n",
            "epoch: [26/30] -> loss: 0.474\n",
            "epoch: [27/30] -> loss: 0.472\n",
            "epoch: [28/30] -> loss: 0.471\n",
            "epoch: [29/30] -> loss: 0.469\n",
            "epoch: [30/30] -> loss: 0.468\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.468\n",
            "* Train accuracy: 83.70%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.861\n",
            "epoch: [2/30] -> loss: 0.723\n",
            "epoch: [3/30] -> loss: 0.647\n",
            "epoch: [4/30] -> loss: 0.602\n",
            "epoch: [5/30] -> loss: 0.576\n",
            "epoch: [6/30] -> loss: 0.557\n",
            "epoch: [7/30] -> loss: 0.542\n",
            "epoch: [8/30] -> loss: 0.530\n",
            "epoch: [9/30] -> loss: 0.524\n",
            "epoch: [10/30] -> loss: 0.517\n",
            "epoch: [11/30] -> loss: 0.509\n",
            "epoch: [12/30] -> loss: 0.505\n",
            "epoch: [13/30] -> loss: 0.502\n",
            "epoch: [14/30] -> loss: 0.495\n",
            "epoch: [15/30] -> loss: 0.493\n",
            "epoch: [16/30] -> loss: 0.491\n",
            "epoch: [17/30] -> loss: 0.488\n",
            "epoch: [18/30] -> loss: 0.483\n",
            "epoch: [19/30] -> loss: 0.481\n",
            "epoch: [20/30] -> loss: 0.483\n",
            "epoch: [21/30] -> loss: 0.480\n",
            "epoch: [22/30] -> loss: 0.478\n",
            "epoch: [23/30] -> loss: 0.476\n",
            "epoch: [24/30] -> loss: 0.476\n",
            "epoch: [25/30] -> loss: 0.473\n",
            "epoch: [26/30] -> loss: 0.475\n",
            "epoch: [27/30] -> loss: 0.472\n",
            "epoch: [28/30] -> loss: 0.470\n",
            "epoch: [29/30] -> loss: 0.466\n",
            "epoch: [30/30] -> loss: 0.467\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.467\n",
            "* Train accuracy: 83.76%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.0001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.829\n",
            "epoch: [2/30] -> loss: 0.701\n",
            "epoch: [3/30] -> loss: 0.633\n",
            "epoch: [4/30] -> loss: 0.595\n",
            "epoch: [5/30] -> loss: 0.568\n",
            "epoch: [6/30] -> loss: 0.551\n",
            "epoch: [7/30] -> loss: 0.538\n",
            "epoch: [8/30] -> loss: 0.527\n",
            "epoch: [9/30] -> loss: 0.518\n",
            "epoch: [10/30] -> loss: 0.512\n",
            "epoch: [11/30] -> loss: 0.507\n",
            "epoch: [12/30] -> loss: 0.501\n",
            "epoch: [13/30] -> loss: 0.497\n",
            "epoch: [14/30] -> loss: 0.494\n",
            "epoch: [15/30] -> loss: 0.492\n",
            "epoch: [16/30] -> loss: 0.490\n",
            "epoch: [17/30] -> loss: 0.488\n",
            "epoch: [18/30] -> loss: 0.484\n",
            "epoch: [19/30] -> loss: 0.481\n",
            "epoch: [20/30] -> loss: 0.481\n",
            "epoch: [21/30] -> loss: 0.478\n",
            "epoch: [22/30] -> loss: 0.476\n",
            "epoch: [23/30] -> loss: 0.476\n",
            "epoch: [24/30] -> loss: 0.475\n",
            "epoch: [25/30] -> loss: 0.473\n",
            "epoch: [26/30] -> loss: 0.471\n",
            "epoch: [27/30] -> loss: 0.469\n",
            "epoch: [28/30] -> loss: 0.469\n",
            "epoch: [29/30] -> loss: 0.469\n",
            "epoch: [30/30] -> loss: 0.468\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.468\n",
            "* Train accuracy: 83.59%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.625\n",
            "epoch: [2/30] -> loss: 0.515\n",
            "epoch: [3/30] -> loss: 0.488\n",
            "epoch: [4/30] -> loss: 0.477\n",
            "epoch: [5/30] -> loss: 0.476\n",
            "epoch: [6/30] -> loss: 0.472\n",
            "epoch: [7/30] -> loss: 0.472\n",
            "epoch: [8/30] -> loss: 0.464\n",
            "epoch: [9/30] -> loss: 0.470\n",
            "epoch: [10/30] -> loss: 0.465\n",
            "epoch: [11/30] -> loss: 0.466\n",
            "epoch: [12/30] -> loss: 0.456\n",
            "epoch: [13/30] -> loss: 0.465\n",
            "epoch: [14/30] -> loss: 0.457\n",
            "epoch: [15/30] -> loss: 0.464\n",
            "epoch: [16/30] -> loss: 0.457\n",
            "epoch: [17/30] -> loss: 0.460\n",
            "epoch: [18/30] -> loss: 0.460\n",
            "epoch: [19/30] -> loss: 0.457\n",
            "epoch: [20/30] -> loss: 0.454\n",
            "epoch: [21/30] -> loss: 0.455\n",
            "epoch: [22/30] -> loss: 0.460\n",
            "epoch: [23/30] -> loss: 0.456\n",
            "epoch: [24/30] -> loss: 0.456\n",
            "epoch: [25/30] -> loss: 0.467\n",
            "epoch: [26/30] -> loss: 0.455\n",
            "epoch: [27/30] -> loss: 0.453\n",
            "epoch: [28/30] -> loss: 0.455\n",
            "epoch: [29/30] -> loss: 0.458\n",
            "epoch: [30/30] -> loss: 0.453\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.453\n",
            "* Train accuracy: 85.86%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.630\n",
            "epoch: [2/30] -> loss: 0.512\n",
            "epoch: [3/30] -> loss: 0.489\n",
            "epoch: [4/30] -> loss: 0.476\n",
            "epoch: [5/30] -> loss: 0.473\n",
            "epoch: [6/30] -> loss: 0.472\n",
            "epoch: [7/30] -> loss: 0.466\n",
            "epoch: [8/30] -> loss: 0.461\n",
            "epoch: [9/30] -> loss: 0.469\n",
            "epoch: [10/30] -> loss: 0.459\n",
            "epoch: [11/30] -> loss: 0.460\n",
            "epoch: [12/30] -> loss: 0.465\n",
            "epoch: [13/30] -> loss: 0.459\n",
            "epoch: [14/30] -> loss: 0.457\n",
            "epoch: [15/30] -> loss: 0.459\n",
            "epoch: [16/30] -> loss: 0.463\n",
            "epoch: [17/30] -> loss: 0.454\n",
            "epoch: [18/30] -> loss: 0.460\n",
            "epoch: [19/30] -> loss: 0.458\n",
            "epoch: [20/30] -> loss: 0.458\n",
            "epoch: [21/30] -> loss: 0.461\n",
            "epoch: [22/30] -> loss: 0.473\n",
            "epoch: [23/30] -> loss: 0.459\n",
            "epoch: [24/30] -> loss: 0.453\n",
            "epoch: [25/30] -> loss: 0.455\n",
            "epoch: [26/30] -> loss: 0.454\n",
            "epoch: [27/30] -> loss: 0.454\n",
            "epoch: [28/30] -> loss: 0.457\n",
            "epoch: [29/30] -> loss: 0.458\n",
            "epoch: [30/30] -> loss: 0.459\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.459\n",
            "* Train accuracy: 85.94%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.616\n",
            "epoch: [2/30] -> loss: 0.510\n",
            "epoch: [3/30] -> loss: 0.485\n",
            "epoch: [4/30] -> loss: 0.485\n",
            "epoch: [5/30] -> loss: 0.475\n",
            "epoch: [6/30] -> loss: 0.468\n",
            "epoch: [7/30] -> loss: 0.470\n",
            "epoch: [8/30] -> loss: 0.463\n",
            "epoch: [9/30] -> loss: 0.457\n",
            "epoch: [10/30] -> loss: 0.464\n",
            "epoch: [11/30] -> loss: 0.460\n",
            "epoch: [12/30] -> loss: 0.460\n",
            "epoch: [13/30] -> loss: 0.459\n",
            "epoch: [14/30] -> loss: 0.462\n",
            "epoch: [15/30] -> loss: 0.469\n",
            "epoch: [16/30] -> loss: 0.457\n",
            "epoch: [17/30] -> loss: 0.467\n",
            "epoch: [18/30] -> loss: 0.451\n",
            "epoch: [19/30] -> loss: 0.458\n",
            "epoch: [20/30] -> loss: 0.457\n",
            "epoch: [21/30] -> loss: 0.457\n",
            "epoch: [22/30] -> loss: 0.452\n",
            "epoch: [23/30] -> loss: 0.455\n",
            "epoch: [24/30] -> loss: 0.457\n",
            "epoch: [25/30] -> loss: 0.459\n",
            "epoch: [26/30] -> loss: 0.458\n",
            "epoch: [27/30] -> loss: 0.453\n",
            "epoch: [28/30] -> loss: 0.461\n",
            "epoch: [29/30] -> loss: 0.462\n",
            "epoch: [30/30] -> loss: 0.461\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.461\n",
            "* Train accuracy: 83.97%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.609\n",
            "epoch: [2/30] -> loss: 0.503\n",
            "epoch: [3/30] -> loss: 0.494\n",
            "epoch: [4/30] -> loss: 0.481\n",
            "epoch: [5/30] -> loss: 0.473\n",
            "epoch: [6/30] -> loss: 0.469\n",
            "epoch: [7/30] -> loss: 0.467\n",
            "epoch: [8/30] -> loss: 0.464\n",
            "epoch: [9/30] -> loss: 0.459\n",
            "epoch: [10/30] -> loss: 0.461\n",
            "epoch: [11/30] -> loss: 0.460\n",
            "epoch: [12/30] -> loss: 0.466\n",
            "epoch: [13/30] -> loss: 0.462\n",
            "epoch: [14/30] -> loss: 0.457\n",
            "epoch: [15/30] -> loss: 0.462\n",
            "epoch: [16/30] -> loss: 0.458\n",
            "epoch: [17/30] -> loss: 0.454\n",
            "epoch: [18/30] -> loss: 0.458\n",
            "epoch: [19/30] -> loss: 0.455\n",
            "epoch: [20/30] -> loss: 0.454\n",
            "epoch: [21/30] -> loss: 0.456\n",
            "epoch: [22/30] -> loss: 0.458\n",
            "epoch: [23/30] -> loss: 0.458\n",
            "epoch: [24/30] -> loss: 0.468\n",
            "epoch: [25/30] -> loss: 0.456\n",
            "epoch: [26/30] -> loss: 0.454\n",
            "epoch: [27/30] -> loss: 0.457\n",
            "epoch: [28/30] -> loss: 0.452\n",
            "epoch: [29/30] -> loss: 0.458\n",
            "epoch: [30/30] -> loss: 0.458\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.458\n",
            "* Train accuracy: 85.81%\n",
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10.0]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.612\n",
            "epoch: [2/30] -> loss: 0.509\n",
            "epoch: [3/30] -> loss: 0.493\n",
            "epoch: [4/30] -> loss: 0.481\n",
            "epoch: [5/30] -> loss: 0.476\n",
            "epoch: [6/30] -> loss: 0.473\n",
            "epoch: [7/30] -> loss: 0.466\n",
            "epoch: [8/30] -> loss: 0.464\n",
            "epoch: [9/30] -> loss: 0.461\n",
            "epoch: [10/30] -> loss: 0.459\n",
            "epoch: [11/30] -> loss: 0.468\n",
            "epoch: [12/30] -> loss: 0.467\n",
            "epoch: [13/30] -> loss: 0.461\n",
            "epoch: [14/30] -> loss: 0.456\n",
            "epoch: [15/30] -> loss: 0.454\n",
            "epoch: [16/30] -> loss: 0.456\n",
            "epoch: [17/30] -> loss: 0.458\n",
            "epoch: [18/30] -> loss: 0.455\n",
            "epoch: [19/30] -> loss: 0.450\n",
            "epoch: [20/30] -> loss: 0.459\n",
            "epoch: [21/30] -> loss: 0.456\n",
            "epoch: [22/30] -> loss: 0.453\n",
            "epoch: [23/30] -> loss: 0.458\n",
            "epoch: [24/30] -> loss: 0.461\n",
            "epoch: [25/30] -> loss: 0.453\n",
            "epoch: [26/30] -> loss: 0.454\n",
            "epoch: [27/30] -> loss: 0.459\n",
            "epoch: [28/30] -> loss: 0.454\n",
            "epoch: [29/30] -> loss: 0.464\n",
            "epoch: [30/30] -> loss: 0.454\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.454\n",
            "* Train accuracy: 85.40%\n"
          ]
        }
      ],
      "source": [
        "normalized_trainset, normalized_testset = Normalize_dataset()\n",
        "\n",
        "HPT_Visualize_eval = {}\n",
        "train_loss_Visualize_eval = {}\n",
        "\n",
        "for orient in df_sorted.head(10).index:\n",
        "    tl, ta, vl, va = 0, 0, 0, 0\n",
        "    op, epoch, batch, lr, gamma = df_sorted.loc[orient][:5]\n",
        "    normalized_train_dataloader, normalized_val_dataloader, normalized_test_dataloader = Select_Class(normalized_trainset, normalized_testset, [6, 7], batch=int(batch))\n",
        "    for i in range(5):\n",
        "        svc = SVC()\n",
        "        _, train_loss, train_acc = svc.fit(normalized_train_dataloader, op, float(lr), int(epoch), float(gamma))\n",
        "        val_loss, val_acc = svc.predict(normalized_val_dataloader)\n",
        "        tl += train_loss[-1]\n",
        "        ta += train_acc\n",
        "        vl += val_loss\n",
        "        va += val_acc\n",
        "    key = op+\"_\"+str(epoch)+\"_\"+str(batch)+\"_\"+str(lr)+\"_\"+str(gamma)\n",
        "    HPT_Visualize_eval[key] = {\"train_loss\":tl/5,\n",
        "                            \"train_acc\":ta/5,\n",
        "                            \"val_loss\":vl/5,\n",
        "                            \"val_acc\":va/5}\n",
        "    train_loss_Visualize_eval[key] = train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>optimizer</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch size</th>\n",
              "      <th>learning rate</th>\n",
              "      <th>Gamma</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Adam_30_32_0.0005_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.460622</td>\n",
              "      <td>85.557780</td>\n",
              "      <td>0.499176</td>\n",
              "      <td>82.699997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_256_0.001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.458119</td>\n",
              "      <td>85.526666</td>\n",
              "      <td>0.484110</td>\n",
              "      <td>84.120003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_128_0.0005_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.448326</td>\n",
              "      <td>85.513333</td>\n",
              "      <td>0.483006</td>\n",
              "      <td>82.979996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_32_0.0001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.444680</td>\n",
              "      <td>85.122224</td>\n",
              "      <td>0.504102</td>\n",
              "      <td>82.220001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_128_0.0005_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.452922</td>\n",
              "      <td>84.960002</td>\n",
              "      <td>0.501429</td>\n",
              "      <td>82.419998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_32_0.0001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.454945</td>\n",
              "      <td>84.295557</td>\n",
              "      <td>0.475886</td>\n",
              "      <td>83.260002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_256_0.0001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.505283</td>\n",
              "      <td>82.233334</td>\n",
              "      <td>0.484881</td>\n",
              "      <td>83.699997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_256_0.001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.462562</td>\n",
              "      <td>85.337776</td>\n",
              "      <td>0.474592</td>\n",
              "      <td>83.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_128_0.0001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.467447</td>\n",
              "      <td>83.746666</td>\n",
              "      <td>0.461237</td>\n",
              "      <td>84.300003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_128_0.001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.457008</td>\n",
              "      <td>85.395555</td>\n",
              "      <td>0.519682</td>\n",
              "      <td>82.159996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        optimizer  epochs  batch size  learning rate  Gamma   \n",
              "Adam_30_32_0.0005_10.0       Adam      30          32         0.0005   10.0  \\\n",
              "Adam_30_256_0.001_10.0       Adam      30         256         0.0010   10.0   \n",
              "Adam_30_128_0.0005_10.0      Adam      30         128         0.0005   10.0   \n",
              "Adam_30_32_0.0001_10.0       Adam      30          32         0.0001   10.0   \n",
              "Adam_20_128_0.0005_10.0      Adam      20         128         0.0005   10.0   \n",
              "Adam_20_32_0.0001_10.0       Adam      20          32         0.0001   10.0   \n",
              "Adam_20_256_0.0001_10.0      Adam      20         256         0.0001   10.0   \n",
              "Adam_20_256_0.001_10.0       Adam      20         256         0.0010   10.0   \n",
              "Adam_30_128_0.0001_10.0      Adam      30         128         0.0001   10.0   \n",
              "Adam_30_128_0.001_10.0       Adam      30         128         0.0010   10.0   \n",
              "\n",
              "                         train_loss  train_acc  val_loss    val_acc  \n",
              "Adam_30_32_0.0005_10.0     0.460622  85.557780  0.499176  82.699997  \n",
              "Adam_30_256_0.001_10.0     0.458119  85.526666  0.484110  84.120003  \n",
              "Adam_30_128_0.0005_10.0    0.448326  85.513333  0.483006  82.979996  \n",
              "Adam_30_32_0.0001_10.0     0.444680  85.122224  0.504102  82.220001  \n",
              "Adam_20_128_0.0005_10.0    0.452922  84.960002  0.501429  82.419998  \n",
              "Adam_20_32_0.0001_10.0     0.454945  84.295557  0.475886  83.260002  \n",
              "Adam_20_256_0.0001_10.0    0.505283  82.233334  0.484881  83.699997  \n",
              "Adam_20_256_0.001_10.0     0.462562  85.337776  0.474592  83.540001  \n",
              "Adam_30_128_0.0001_10.0    0.467447  83.746666  0.461237  84.300003  \n",
              "Adam_30_128_0.001_10.0     0.457008  85.395555  0.519682  82.159996  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_data = {}\n",
        "for key, value in HPT_Visualize_eval.items():\n",
        "    parts = key.split('_')\n",
        "    optimizer, epochs, batch_size, learning_rate, Gamma = parts[:5]\n",
        "    final_data[key] = {\n",
        "        \"optimizer\": optimizer,\n",
        "        \"epochs\": int(epochs),\n",
        "        \"batch size\": int(batch_size),\n",
        "        \"learning rate\": float(learning_rate),\n",
        "        \"Gamma\": float(Gamma),\n",
        "        \"train_loss\": value['train_loss'],\n",
        "        \"train_acc\": value['train_acc'],\n",
        "        \"val_loss\": float(value['val_loss']),\n",
        "        \"val_acc\": float(value['val_acc'])\n",
        "    }\n",
        "\n",
        "final_df = pd.DataFrame.from_dict(final_data, orient='index')\n",
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>optimizer</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch size</th>\n",
              "      <th>learning rate</th>\n",
              "      <th>Gamma</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Adam_30_128_0.0001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.467447</td>\n",
              "      <td>83.746666</td>\n",
              "      <td>0.461237</td>\n",
              "      <td>84.300003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_256_0.001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.458119</td>\n",
              "      <td>85.526666</td>\n",
              "      <td>0.484110</td>\n",
              "      <td>84.120003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_256_0.0001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.505283</td>\n",
              "      <td>82.233334</td>\n",
              "      <td>0.484881</td>\n",
              "      <td>83.699997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_256_0.001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.462562</td>\n",
              "      <td>85.337776</td>\n",
              "      <td>0.474592</td>\n",
              "      <td>83.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_32_0.0001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.454945</td>\n",
              "      <td>84.295557</td>\n",
              "      <td>0.475886</td>\n",
              "      <td>83.260002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_128_0.0005_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.448326</td>\n",
              "      <td>85.513333</td>\n",
              "      <td>0.483006</td>\n",
              "      <td>82.979996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_32_0.0005_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.460622</td>\n",
              "      <td>85.557780</td>\n",
              "      <td>0.499176</td>\n",
              "      <td>82.699997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_20_128_0.0005_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>20</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.452922</td>\n",
              "      <td>84.960002</td>\n",
              "      <td>0.501429</td>\n",
              "      <td>82.419998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_32_0.0001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.444680</td>\n",
              "      <td>85.122224</td>\n",
              "      <td>0.504102</td>\n",
              "      <td>82.220001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam_30_128_0.001_10.0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>30</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.457008</td>\n",
              "      <td>85.395555</td>\n",
              "      <td>0.519682</td>\n",
              "      <td>82.159996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        optimizer  epochs  batch size  learning rate  Gamma   \n",
              "Adam_30_128_0.0001_10.0      Adam      30         128         0.0001   10.0  \\\n",
              "Adam_30_256_0.001_10.0       Adam      30         256         0.0010   10.0   \n",
              "Adam_20_256_0.0001_10.0      Adam      20         256         0.0001   10.0   \n",
              "Adam_20_256_0.001_10.0       Adam      20         256         0.0010   10.0   \n",
              "Adam_20_32_0.0001_10.0       Adam      20          32         0.0001   10.0   \n",
              "Adam_30_128_0.0005_10.0      Adam      30         128         0.0005   10.0   \n",
              "Adam_30_32_0.0005_10.0       Adam      30          32         0.0005   10.0   \n",
              "Adam_20_128_0.0005_10.0      Adam      20         128         0.0005   10.0   \n",
              "Adam_30_32_0.0001_10.0       Adam      30          32         0.0001   10.0   \n",
              "Adam_30_128_0.001_10.0       Adam      30         128         0.0010   10.0   \n",
              "\n",
              "                         train_loss  train_acc  val_loss    val_acc  \n",
              "Adam_30_128_0.0001_10.0    0.467447  83.746666  0.461237  84.300003  \n",
              "Adam_30_256_0.001_10.0     0.458119  85.526666  0.484110  84.120003  \n",
              "Adam_20_256_0.0001_10.0    0.505283  82.233334  0.484881  83.699997  \n",
              "Adam_20_256_0.001_10.0     0.462562  85.337776  0.474592  83.540001  \n",
              "Adam_20_32_0.0001_10.0     0.454945  84.295557  0.475886  83.260002  \n",
              "Adam_30_128_0.0005_10.0    0.448326  85.513333  0.483006  82.979996  \n",
              "Adam_30_32_0.0005_10.0     0.460622  85.557780  0.499176  82.699997  \n",
              "Adam_20_128_0.0005_10.0    0.452922  84.960002  0.501429  82.419998  \n",
              "Adam_30_32_0.0001_10.0     0.444680  85.122224  0.504102  82.220001  \n",
              "Adam_30_128_0.001_10.0     0.457008  85.395555  0.519682  82.159996  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_final_df = final_df.sort_values(by=['val_acc', 'train_acc'], ascending=False)\n",
        "sorted_final_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQr0xaj65q5i"
      },
      "source": [
        "##### j) What is the final test accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5n9j9bhy-59",
        "outputId": "2d5af808-aa05-4d7b-98b5-6fdb7ff79b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training SVM model with [epoch: 30, learning_rate: 0.001, optimizer: Adam, gamma: 10]\n",
            "\n",
            "epoch: [1/30] -> loss: 0.694\n",
            "epoch: [2/30] -> loss: 0.547\n",
            "epoch: [3/30] -> loss: 0.511\n",
            "epoch: [4/30] -> loss: 0.494\n",
            "epoch: [5/30] -> loss: 0.489\n",
            "epoch: [6/30] -> loss: 0.492\n",
            "epoch: [7/30] -> loss: 0.478\n",
            "epoch: [8/30] -> loss: 0.476\n",
            "epoch: [9/30] -> loss: 0.474\n",
            "epoch: [10/30] -> loss: 0.474\n",
            "epoch: [11/30] -> loss: 0.466\n",
            "epoch: [12/30] -> loss: 0.463\n",
            "epoch: [13/30] -> loss: 0.467\n",
            "epoch: [14/30] -> loss: 0.471\n",
            "epoch: [15/30] -> loss: 0.465\n",
            "epoch: [16/30] -> loss: 0.462\n",
            "epoch: [17/30] -> loss: 0.461\n",
            "epoch: [18/30] -> loss: 0.462\n",
            "epoch: [19/30] -> loss: 0.463\n",
            "epoch: [20/30] -> loss: 0.457\n",
            "epoch: [21/30] -> loss: 0.456\n",
            "epoch: [22/30] -> loss: 0.464\n",
            "epoch: [23/30] -> loss: 0.465\n",
            "epoch: [24/30] -> loss: 0.462\n",
            "epoch: [25/30] -> loss: 0.461\n",
            "epoch: [26/30] -> loss: 0.461\n",
            "epoch: [27/30] -> loss: 0.452\n",
            "epoch: [28/30] -> loss: 0.466\n",
            "epoch: [29/30] -> loss: 0.460\n",
            "epoch: [30/30] -> loss: 0.458\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "* Final loss: 0.458\n",
            "* Train accuracy: 85.60%\n",
            "\n",
            "Evaluate test dataset loss/accuracy\n",
            "* test loss: 0.472\n",
            "* test accuracy: 84.25%\n"
          ]
        }
      ],
      "source": [
        "normalized_trainset, normalized_testset = Normalize_dataset()\n",
        "\n",
        "normalized_train_dataloader, normalized_val_dataloader, normalized_test_dataloader = Select_Class(normalized_trainset, normalized_testset, [6, 7], batch=256)\n",
        "\n",
        "svc = SVC()\n",
        "\n",
        "epochs, losses, _ = svc.fit(normalized_train_dataloader, learning_rate=0.001, optimethod=\"Adam\", epochs=30, gamma=10)\n",
        "\n",
        "test_loss, test_acc = svc.predict(normalized_test_dataloader)\n",
        "\n",
        "print(\"\\nEvaluate test dataset loss/accuracy\")\n",
        "print(f'* test loss: {test_loss:.3f}\\n* test accuracy: {test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, losses, label='Loss per Epoch', color='red')\n",
        "    plt.title('Loss Graph Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
